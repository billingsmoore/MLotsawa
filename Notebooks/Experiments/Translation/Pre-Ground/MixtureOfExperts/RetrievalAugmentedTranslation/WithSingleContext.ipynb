{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "dataset = load_from_disk('rat-poc-ds-w-context')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Source': 'སྒོམ། སྤྱོད། འབྲས་ཀྱི་རྣམ་གཞག་ཅུང་ཟད་བརྗོད་ན། འཇུག་སྒོ་ནི། ཕྱི་ནང་སྒྲུབ་གསང་ཆུ་བོ་བཞི་རྫོགས་ཀྱི་དབང་སུམ་ཅུ་རྩ་དྲུག་གིས་རྒྱུད་སྨིན་ཅིང་། དམ་ཚིག་གཞུང་བཞིན་སྲུང་བའོ།། གཞི་ལྟ་བ་གཏན་ལ་འབེབས་ཚུལ་ནི། ཆོས་ཐམས་ཅད་ཀྱི་གཤིས་ལུགས་དཀྱིལ་འཁོར་གསུམ་དུ་གནས་པ་ཉིད་ཀྱི་ཆོས་ཅན་ཤེས་བྱའི་དོན་ལ་ཤེས་བྱེད་རིགས་པའི་གཏན་ཚིགས་རྣམས་ཀྱི་ཇི་ལྟ་བར་གཏན་ལ་ཕབ་སྟེ་རྟོགས་པའོ།། ལམ་སྒོམ་པས་ཉམས་སུ་ལེན་ཚུལ་ནི། ཆོས་ཉིད་སྙིང་པོ་ཇི་བཞིན་པའི་ངང་ལ་མཉམ་པར་འཇོག་པ་མཚན་མེད་རྣམ་པར་མི་རྟོག་པའི་ཏིང་ངེ་འཛིན་དང་། བསྐྱེད་སྔགས་བརྗོད་པ་ཙམ་གྱིས་རྟེན་དང་བརྟེན་པའི་འཁོར་ལོར་བསྒོམ་པ་མཚན་བཅས་ལྷའི་ཏིང་འཛིན་བསྒོམ་པ་གྲོལ་ལམ་དང་། ཐབས་ལམ་སྟེང་འོག་གི་སྒོ་ལ་བརྟེན་ནས་བདེ་སྟོང་གི་ཡེ་ཤེས་བསྐྱེད་པ་སྟེ་ལམ་གཉིས་ཀྱི་རྣལ་འབྱོར་བསྒོམ་པའོ།།',\n",
       " 'Target': 'Once again, let us say a little about its point of entry, view, meditation, conduct and results: i. Entry Point One’s mind is matured through the thirty-six empowerments in which the four rivers—outer, inner, accomplishing and secret—are complete, and one keeps the samayas as described in the texts. ii. View Through logical reasoning one determines that which is to be known, the fact that all phenomena are characterized as being the three mandalas in their fundamental nature, and realizes that this is so. iii. Meditation Meditation practice here consists of two paths. On the path of liberation one practises the non-conceptual samādhi of simply resting in a state that accords with the essence of reality itself, and the conceptual samādhi of deity practice, in which one visualizes the mandala of supporting palace and supported deities simply by reciting the mantra of generation. On the path of skilful means one generates the wisdom of bliss and emptiness through the practices of the upper and lower gateways.',\n",
       " 'File_Name': None,\n",
       " 'Machine Aligned': True,\n",
       " '__index_level_0__': 294714,\n",
       " 'Tag': {'Buddhist': True,\n",
       "  'LH labels': ['Longchen Nyingtik', 'Yumka Dechen Gyalmo'],\n",
       "  'Topic': 'Meditation'},\n",
       " 'context': ['འདི་དག་ལ་བརྟེན་ནས་བསམ་གཏན་གྱི་སེམས་བསྒྲུབ་པར་བྱའོ།། -> It is through these that the mind of meditation is attained.',\n",
       "  '1 ཞེས་སོགས་མང་དུ་བཤད་པ་ལྟར་རོ།། དེ་ལྟར་ན་སྐབས་འདིར་གཞན་དགེ་སྦྱོར་ཅི་རིགས་ཙམ་དང་། ཁྱད་པར་བླ་མའི་རྣལ་འབྱོར་གྱི་སྐབས་སུ་བླ་མ་ལ་ཆོས་སྐུའི་མོས་གུས་བསྐྱེད་ནས་སྣང་སྲིད་ཆོས་སྐུར་རྟོགས་པར་གསོལ་བ་དྲག་ཏུ་འདེབས་པ་སྔོན་དུ་འགྲོ་བས། སྔར་བཤད་པ་ལྟར་ངོ་བོའི་གཞག་ཐབས་ཀྱི་མཉམ་བཞག་རྩེ་གཅིག་ཏུ་བསྐྱངས་ཏེ་རིག་པ་དྭངས་སྙིགས་ཕྱེད་པར་བྱས་ལ། དེ་ནས་རིག་པ་མ་ཡེངས་ཤིང་འདི་སྒོམ་གྱི་གཏད་སོ་མེད་པར་སེམས་གུ་ཡངས་སང་ངེ་བའི་ངང་ནས། ཡིད་ལ་བདེ་དོག་ཆེར་མི་འབྱུང་བའི་རྣམ་རྟོག་ཕྲ་མོ་ཤར་བའམ་ཆེད་དུ་སྤྲོས་ཏེ། དེའི་རྣམ་པ་གསལ་བཞིན་པ་འི་ངོ་བོ་ལ་འཛིན་མེད་ཡེངས་མེད་དུ་ཅེ་རེ་བལྟ། དེ་བཞིན་དུ་ཡིད་ལ་དགའ་མི་དགའི་ཟུག་རྔུ་བསྐྱེད་པའི་རྣམ་རྟོག་རགས་པ་མངོན་ཚན་ཆེ་བ་ཤར་བའམ་ཆེད་དུ་སྤྲོས་ཏེ། ཕྲ་རགས་དེ་གཉིས་ཀྱི་ངོ་བོ་ལ་ཁྱད་པར་ཅི་འདུག་ཡང་ཡང་བལྟ། དེ་ལ་སྒྲོ་འདོགས་ཆོད་ན་དེ་དག་དང་སེམས་གནས་དུས་ཀྱི་ངོ་བོ་ལ་ཁྱད་པར་ཅི་འདུག་བལྟ། -> 1 There are many such statements. At this point, during whatever spiritual practices you do and particularly during guru yoga, begin by arousing the devotion in which you see your gurus as the dharmakāya. Make fervent supplications to realize all possible appearances are the dharmakāya. Next, as described before, cultivate one-pointed equipoise, which is the means for resting in the essence, and differentiate between brilliant states of mind and sullied ones. Then, in a spacious and vibrant state of mind—when your awareness is undistracted and your meditation is without reference point—there may arise a subtle thought that doesn’t create great mental pleasure or pain, or you should cause one to arise. Without clinging or wandering, look fixedly at its essence while its manifestation is vivid. Similarly, there may arise a clearly evident coarse thought, the kind that creates the miseries associated with mental joys and sorrows, or you should cause one to arise. Look again and again to see if there is any difference between the essence of a subtle thought and that of a coarse thought. When you sever misinterpretations regarding that, look to see if there is any difference between the essence of those thoughts and the essence of the still mind.',\n",
       "  'གཞི་ལྟ་བ་གཏན་ལ་འབེབས་ཚུལ་ནི། སེམས་ལས་འདས་པའི་རིག་པ་རྗེན་པ་འདི་ཀའི་ངོ་བོ་སྟོང་པ་ཆོས་ཀྱི་སྐུ། རང་བཞིན་གསལ་བ་ལོངས་སྐུ། ཐུགས་རྗེ་ཀུན་ཁྱབ་སྤྲུལ་སྐུ་སྟེ། སྐུ་གསུམ་དབྱེར་མེད་པའི་རང་བྱུང་གི་ཡེ་ཤེས་ཀྱི་རང་ཞལ་ལྟ་བའོ།། ལེ་ལོ་ཅན་འབད་མེད་དུ་གྲོལ་བ་ཀ་དག་ཁྲེགས་ཆོད་ཀྱི་ལམ་དང་། བརྩོན་འགྲུས་ཅན་འབད་བཅས་སུ་གྲོལ་བ་ལྷུན་གྲུབ་ཐོད་རྒལ་གྱི་ལམ་བསྒོམ་པའོ།། ཅིར་སྣང་ཐམས་ཅད་ཆོས་ཉིད་ཀྱི་རོལ་པར་ཤར་བས་སྤང་བླང་རེ་དོགས་དང་བྲལ་བར་སྤྱོད་པའོ།། འབྲས་བུ་ཇི་ལྟར་ཐོབ་ཚུལ་ནི། ལམ་གྱི་སྣང་བ་བཞི་མཐར་ཕྱིན་ཏེ། འཇའ་ལུས་འཕོ་བ་ཆེན་པོའི་སྐུ་མཆོག་བརྙེས་ནས་དཔལ་ཀུན་ཏུ་བཟང་པོའི་གོ་འཕང་ངམ་བཅུ་གསུམ་ཡེ་ཤེས་བླ་མའི་ས་ཐོབ་པའོ།། -> View The view is definitively established by looking directly into the naturally arising wisdom in which the three kāyas are inseparable: the empty essence of naked awareness beyond the ordinary mind is the dharmakāya, its cognizant nature is the sambhogakāya, and its all-pervasive compassionate energy is the nirmāṇakāya. Meditation The meditation consists of the approach of cutting through resistance to primordial purity (kadak trekchö), through which the lazy can reach liberation without effort, and the approach of the direct realization of spontaneous presence (lhundrup tögal), through which the diligent can reach liberation with exertion. Conduct The conduct is free from hope and fear and adopting and abandoning, because all that appears manifests as the display of reality itself. v. Results Perfecting the four visions of the path, one gains the supreme kāya, the rainbow body of great transference, and attains the level of glorious Samantabhadra, the thirteenth bhūmi known as ‘Unexcelled Wisdom’ (yeshe lama). ']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Source': 'འཇམ་དབལ་གྱིས་རྗེ་བླ་མར། ཟླ་བ་གྲགས་བ་ནི་སངས་རྒྱས་ཀྱི་ཞིང་ཁམས་ཤིག་ནས་ས་མཐོན་པོའི་བྱང་ཆུབ་སེམས་དཔའ་རྣམ་དཔྱོད་སྙིང་སྟོབས་ཅན་ཞིག་མགོན་བོ་ཀླུ་སྒྲུབ་ཀྱི་ཟབ་མོ་ལྟ་བའི་བསྟན་བ་སྤེལ་ཕྱིར་བསམ་བཞིན་བྱོན་པ་ཡིན་བས་དེའི་གཞུང་ལ་ནོར་འཁྲུལ་མེད་ཚུལ་གསུངས་བ་བཞིན།',\n",
       " 'Target': 'Mañjushrı told him that Chandrakırti was a courageous and discerning bodhisattva of high degree who had come here from a buddhafield with the intention of spreading Protector Nagarjuna’s teachings on the profound view, and that his writings were error free.',\n",
       " 'File_Name': 'TM0718',\n",
       " 'Machine Aligned': False,\n",
       " '__index_level_0__': 1102159,\n",
       " 'Tag': {'Buddhist': True,\n",
       "  'LH labels': ['Nyingma Mönlam'],\n",
       "  'Topic': 'Mahamudra'},\n",
       " 'context': ['འདི་དག་ལ་བརྟེན་ནས་བསམ་གཏན་གྱི་སེམས་བསྒྲུབ་པར་བྱའོ།། -> It is through these that the mind of meditation is attained.',\n",
       "  '1 ཞེས་སོགས་མང་དུ་བཤད་པ་ལྟར་རོ།། དེ་ལྟར་ན་སྐབས་འདིར་གཞན་དགེ་སྦྱོར་ཅི་རིགས་ཙམ་དང་། ཁྱད་པར་བླ་མའི་རྣལ་འབྱོར་གྱི་སྐབས་སུ་བླ་མ་ལ་ཆོས་སྐུའི་མོས་གུས་བསྐྱེད་ནས་སྣང་སྲིད་ཆོས་སྐུར་རྟོགས་པར་གསོལ་བ་དྲག་ཏུ་འདེབས་པ་སྔོན་དུ་འགྲོ་བས། སྔར་བཤད་པ་ལྟར་ངོ་བོའི་གཞག་ཐབས་ཀྱི་མཉམ་བཞག་རྩེ་གཅིག་ཏུ་བསྐྱངས་ཏེ་རིག་པ་དྭངས་སྙིགས་ཕྱེད་པར་བྱས་ལ། དེ་ནས་རིག་པ་མ་ཡེངས་ཤིང་འདི་སྒོམ་གྱི་གཏད་སོ་མེད་པར་སེམས་གུ་ཡངས་སང་ངེ་བའི་ངང་ནས། ཡིད་ལ་བདེ་དོག་ཆེར་མི་འབྱུང་བའི་རྣམ་རྟོག་ཕྲ་མོ་ཤར་བའམ་ཆེད་དུ་སྤྲོས་ཏེ། དེའི་རྣམ་པ་གསལ་བཞིན་པ་འི་ངོ་བོ་ལ་འཛིན་མེད་ཡེངས་མེད་དུ་ཅེ་རེ་བལྟ། དེ་བཞིན་དུ་ཡིད་ལ་དགའ་མི་དགའི་ཟུག་རྔུ་བསྐྱེད་པའི་རྣམ་རྟོག་རགས་པ་མངོན་ཚན་ཆེ་བ་ཤར་བའམ་ཆེད་དུ་སྤྲོས་ཏེ། ཕྲ་རགས་དེ་གཉིས་ཀྱི་ངོ་བོ་ལ་ཁྱད་པར་ཅི་འདུག་ཡང་ཡང་བལྟ། དེ་ལ་སྒྲོ་འདོགས་ཆོད་ན་དེ་དག་དང་སེམས་གནས་དུས་ཀྱི་ངོ་བོ་ལ་ཁྱད་པར་ཅི་འདུག་བལྟ། -> 1 There are many such statements. At this point, during whatever spiritual practices you do and particularly during guru yoga, begin by arousing the devotion in which you see your gurus as the dharmakāya. Make fervent supplications to realize all possible appearances are the dharmakāya. Next, as described before, cultivate one-pointed equipoise, which is the means for resting in the essence, and differentiate between brilliant states of mind and sullied ones. Then, in a spacious and vibrant state of mind—when your awareness is undistracted and your meditation is without reference point—there may arise a subtle thought that doesn’t create great mental pleasure or pain, or you should cause one to arise. Without clinging or wandering, look fixedly at its essence while its manifestation is vivid. Similarly, there may arise a clearly evident coarse thought, the kind that creates the miseries associated with mental joys and sorrows, or you should cause one to arise. Look again and again to see if there is any difference between the essence of a subtle thought and that of a coarse thought. When you sever misinterpretations regarding that, look to see if there is any difference between the essence of those thoughts and the essence of the still mind.',\n",
       "  'གཞི་ལྟ་བ་གཏན་ལ་འབེབས་ཚུལ་ནི། སེམས་ལས་འདས་པའི་རིག་པ་རྗེན་པ་འདི་ཀའི་ངོ་བོ་སྟོང་པ་ཆོས་ཀྱི་སྐུ། རང་བཞིན་གསལ་བ་ལོངས་སྐུ། ཐུགས་རྗེ་ཀུན་ཁྱབ་སྤྲུལ་སྐུ་སྟེ། སྐུ་གསུམ་དབྱེར་མེད་པའི་རང་བྱུང་གི་ཡེ་ཤེས་ཀྱི་རང་ཞལ་ལྟ་བའོ།། ལེ་ལོ་ཅན་འབད་མེད་དུ་གྲོལ་བ་ཀ་དག་ཁྲེགས་ཆོད་ཀྱི་ལམ་དང་། བརྩོན་འགྲུས་ཅན་འབད་བཅས་སུ་གྲོལ་བ་ལྷུན་གྲུབ་ཐོད་རྒལ་གྱི་ལམ་བསྒོམ་པའོ།། ཅིར་སྣང་ཐམས་ཅད་ཆོས་ཉིད་ཀྱི་རོལ་པར་ཤར་བས་སྤང་བླང་རེ་དོགས་དང་བྲལ་བར་སྤྱོད་པའོ།། འབྲས་བུ་ཇི་ལྟར་ཐོབ་ཚུལ་ནི། ལམ་གྱི་སྣང་བ་བཞི་མཐར་ཕྱིན་ཏེ། འཇའ་ལུས་འཕོ་བ་ཆེན་པོའི་སྐུ་མཆོག་བརྙེས་ནས་དཔལ་ཀུན་ཏུ་བཟང་པོའི་གོ་འཕང་ངམ་བཅུ་གསུམ་ཡེ་ཤེས་བླ་མའི་ས་ཐོབ་པའོ།། -> View The view is definitively established by looking directly into the naturally arising wisdom in which the three kāyas are inseparable: the empty essence of naked awareness beyond the ordinary mind is the dharmakāya, its cognizant nature is the sambhogakāya, and its all-pervasive compassionate energy is the nirmāṇakāya. Meditation The meditation consists of the approach of cutting through resistance to primordial purity (kadak trekchö), through which the lazy can reach liberation without effort, and the approach of the direct realization of spontaneous presence (lhundrup tögal), through which the diligent can reach liberation with exertion. Conduct The conduct is free from hope and fear and adopting and abandoning, because all that appears manifests as the display of reality itself. v. Results Perfecting the four visions of the path, one gains the supreme kāya, the rainbow body of great transference, and attains the level of glorious Samantabhadra, the thirteenth bhūmi known as ‘Unexcelled Wisdom’ (yeshe lama). ']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Tokenizer, Model, and Data Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/j/Documents/MLotsawa/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorForSeq2Seq, AutoModelForSeq2SeqLM\n",
    "\n",
    "checkpoint = \"google/switch-base-8\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint, device_map=\"cuda:0\")\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32355, 768)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a list of all Tibetan Unicode characters (U+0F00 to U+0FFF)\n",
    "tibetan_chars = [chr(codepoint) for codepoint in range(0x0F00, 0x0FFF)]\n",
    "\n",
    "# Add the Tibetan characters to the tokenizer's vocabulary\n",
    "new_tokens = [char for char in tibetan_chars if char not in tokenizer.get_vocab()]\n",
    "\n",
    "# Add new tokens to the tokenizer\n",
    "tokenizer.add_tokens(new_tokens)\n",
    "\n",
    "# Resize model embeddings to accommodate the new vocabulary size\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (659 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'སྒོམ།སྤྱོད།འབྲས་ཀྱི་རྣམ་གཞག་ཅུང་ཟད་བརྗོད་ན།འཇུག་སྒོ་ནི།ཕྱི་ནང་སྒྲུབ་གསང་ཆུ་བོ་བཞི་རྫོགས་ཀྱི་དབང་སུམ་ཅུ་རྩ་དྲུག་གིས་རྒྱུད་སྨིན་ཅིང་།དམ་ཚིག་གཞུང་བཞིན་སྲུང་བའོ།།གཞི་ལྟ་བ་གཏན་ལ་འབེབས་ཚུལ་ནི།ཆོས་ཐམས་ཅད་ཀྱི་གཤིས་ལུགས་དཀྱིལ་འཁོར་གསུམ་དུ་གནས་པ་ཉིད་ཀྱི་ཆོས་ཅན་ཤེས་བྱའི་དོན་ལ་ཤེས་བྱེད་རིགས་པའི་གཏན་ཚིགས་རྣམས་ཀྱི་ཇི་ལྟ་བར་གཏན་ལ་ཕབ་སྟེ་རྟོགས་པའོ།།ལམ་སྒོམ་པས་ཉམས་སུ་ལེན་ཚུལ་ནི།ཆོས་ཉིད་སྙིང་པོ་ཇི་བཞིན་པའི་ངང་ལ་མཉམ་པར་འཇོག་པ་མཚན་མེད་རྣམ་པར་མི་རྟོག་པའི་ཏིང་ངེ་འཛིན་དང་།བསྐྱེད་སྔགས་བརྗོད་པ་ཙམ་གྱིས་རྟེན་དང་བརྟེན་པའི་འཁོར་ལོར་བསྒོམ་པ་མཚན་བཅས་ལྷའི་ཏིང་འཛིན་བསྒོམ་པ་གྲོལ་ལམ་དང་།ཐབས་ལམ་སྟེང་འོག་གི་སྒོ་ལ་བརྟེན་ནས་བདེ་སྟོང་གི་ཡེ་ཤེས་བསྐྱེད་པ་སྟེ་ལམ་གཉིས་ཀྱི་རྣལ་འབྱོར་བསྒོམ་པའོ།།</s>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = tokenizer.encode(dataset['train'][0]['Source'])\n",
    "dec = tokenizer.decode(enc)\n",
    "dec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "\n",
    "The dataset can now be tokenized for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16bf067b3241417b89f9d22e77ec6820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/45000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672e55a34eb3446ca5c277234484aa1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_with_single_context(example):\n",
    "    # Use the first context if it exists, otherwise use a fallback\n",
    "    context = example['context'][0] if example['context'] and len(example['context']) > 0 else \"\"\n",
    "    # Create input text using the first context\n",
    "    input_text = f\"translate Tibetan to English: {example['Source']} Context: {context}\"\n",
    "    target_text = example['Target']\n",
    "\n",
    "    # Tokenize input and target\n",
    "    return {\n",
    "        \"input_ids\": tokenizer(input_text, padding=\"max_length\", truncation=True, max_length=512).input_ids,\n",
    "        \"labels\": tokenizer(target_text, padding=\"max_length\", truncation=True, max_length=512).input_ids,\n",
    "    }\n",
    "\n",
    "# Apply preprocessing\n",
    "dataset_with_contexts = dataset.map(\n",
    "    preprocess_with_single_context,\n",
    "    batched=False,  # Process one example at a time\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "# Load BLEU and CHRF metrics\n",
    "bleu_metric = evaluate.load(\"sacrebleu\")\n",
    "chrf_metric = evaluate.load(\"chrf\")\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    \n",
    "    # Decode predictions and labels\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Postprocess text\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    # Compute BLEU score\n",
    "    bleu_result = bleu_metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    bleu_score = bleu_result[\"score\"]\n",
    "\n",
    "    # Compute CHRF score\n",
    "    chrf_result = chrf_metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    chrf_score = chrf_result[\"score\"]\n",
    "\n",
    "    # Compute generation length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    avg_gen_len = np.mean(prediction_lens)\n",
    "\n",
    "    # Return rounded results\n",
    "    return {\n",
    "        \"bleu\": round(bleu_score, 4),\n",
    "        \"chrf\": round(chrf_score, 4),\n",
    "        \"gen_len\": round(avg_gen_len, 4),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, Adafactor\n",
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "\n",
    "optimizer = Adafactor(\n",
    "    model.parameters(), \n",
    "    scale_parameter=True, \n",
    "    relative_step=False, \n",
    "    warmup_init=False, \n",
    "    lr=3e-4\n",
    ")\n",
    "\n",
    "model, optimizer = accelerator.prepare(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT='moe-translation-experiments'\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_PROJECT='moe-translation-experiments'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbillingsmoore\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/j/Documents/MLotsawa/Notebooks/Models/MixtureOfExperts/RetrievalAugmentedTranslation/wandb/run-20250206_095519-m39u7oux</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/billingsmoore/%27moe-translation-experiments%27/runs/m39u7oux' target=\"_blank\">rat-single-context</a></strong> to <a href='https://wandb.ai/billingsmoore/%27moe-translation-experiments%27' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/billingsmoore/%27moe-translation-experiments%27' target=\"_blank\">https://wandb.ai/billingsmoore/%27moe-translation-experiments%27</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/billingsmoore/%27moe-translation-experiments%27/runs/m39u7oux' target=\"_blank\">https://wandb.ai/billingsmoore/%27moe-translation-experiments%27/runs/m39u7oux</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e909bf696f7f4f41917bf97c35657a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf521cf1f98418bbba5ecbcb6df0763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6957534faf94d76b00c9d0cc7e823cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2a33b7192814a4cae2cb9c6988c9f18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4286, 'grad_norm': 2.233125686645508, 'learning_rate': 0.00029666666666666665, 'epoch': 0.01}\n",
      "{'loss': 0.6321, 'grad_norm': 1.3200215101242065, 'learning_rate': 0.00029333333333333327, 'epoch': 0.02}\n",
      "{'loss': 0.5574, 'grad_norm': 0.8910771012306213, 'learning_rate': 0.00029, 'epoch': 0.03}\n",
      "{'loss': 0.6117, 'grad_norm': 5.800479888916016, 'learning_rate': 0.0002866666666666667, 'epoch': 0.04}\n",
      "{'loss': 0.5589, 'grad_norm': 3.0360019207000732, 'learning_rate': 0.0002833333333333333, 'epoch': 0.06}\n",
      "{'loss': 0.5397, 'grad_norm': 0.647966742515564, 'learning_rate': 0.00028, 'epoch': 0.07}\n",
      "{'loss': 0.5708, 'grad_norm': 1.0254303216934204, 'learning_rate': 0.00027666666666666665, 'epoch': 0.08}\n",
      "{'loss': 0.4989, 'grad_norm': 1.5309396982192993, 'learning_rate': 0.00027333333333333333, 'epoch': 0.09}\n",
      "{'loss': 0.5115, 'grad_norm': 1.2330511808395386, 'learning_rate': 0.00027, 'epoch': 0.1}\n",
      "{'loss': 0.5088, 'grad_norm': 1.0309982299804688, 'learning_rate': 0.0002666666666666666, 'epoch': 0.11}\n",
      "{'loss': 0.4857, 'grad_norm': 4.889522075653076, 'learning_rate': 0.0002633333333333333, 'epoch': 0.12}\n",
      "{'loss': 0.5046, 'grad_norm': 2.904121160507202, 'learning_rate': 0.00026, 'epoch': 0.13}\n",
      "{'loss': 0.4688, 'grad_norm': 2.2915616035461426, 'learning_rate': 0.00025666666666666665, 'epoch': 0.14}\n",
      "{'loss': 0.4859, 'grad_norm': 0.8790584802627563, 'learning_rate': 0.00025333333333333333, 'epoch': 0.16}\n",
      "{'loss': 0.5193, 'grad_norm': 1.5034233331680298, 'learning_rate': 0.00025, 'epoch': 0.17}\n",
      "{'loss': 0.5438, 'grad_norm': 1.001906156539917, 'learning_rate': 0.0002466666666666666, 'epoch': 0.18}\n",
      "{'loss': 0.4846, 'grad_norm': 1.631457805633545, 'learning_rate': 0.0002433333333333333, 'epoch': 0.19}\n",
      "{'loss': 0.4838, 'grad_norm': 3.8087944984436035, 'learning_rate': 0.00023999999999999998, 'epoch': 0.2}\n",
      "{'loss': 0.4499, 'grad_norm': 0.7753145098686218, 'learning_rate': 0.00023666666666666663, 'epoch': 0.21}\n",
      "{'loss': 0.5142, 'grad_norm': 1.0185433626174927, 'learning_rate': 0.0002333333333333333, 'epoch': 0.22}\n",
      "{'loss': 0.5835, 'grad_norm': 0.4935884177684784, 'learning_rate': 0.00023, 'epoch': 0.23}\n",
      "{'loss': 0.5454, 'grad_norm': 2.8201615810394287, 'learning_rate': 0.00022666666666666663, 'epoch': 0.24}\n",
      "{'loss': 0.4707, 'grad_norm': 2.0123724937438965, 'learning_rate': 0.00022333333333333333, 'epoch': 0.26}\n",
      "{'loss': 0.5041, 'grad_norm': 0.8179424405097961, 'learning_rate': 0.00021999999999999995, 'epoch': 0.27}\n",
      "{'loss': 0.4971, 'grad_norm': 0.744312584400177, 'learning_rate': 0.00021666666666666666, 'epoch': 0.28}\n",
      "{'loss': 0.5394, 'grad_norm': 0.3540908098220825, 'learning_rate': 0.00021333333333333333, 'epoch': 0.29}\n",
      "{'loss': 0.4819, 'grad_norm': 0.45902588963508606, 'learning_rate': 0.00020999999999999998, 'epoch': 0.3}\n",
      "{'loss': 0.4786, 'grad_norm': 3.938236713409424, 'learning_rate': 0.00020666666666666666, 'epoch': 0.31}\n",
      "{'loss': 0.4607, 'grad_norm': 3.8761401176452637, 'learning_rate': 0.00020333333333333333, 'epoch': 0.32}\n",
      "{'loss': 0.4975, 'grad_norm': 0.6975403428077698, 'learning_rate': 0.00019999999999999998, 'epoch': 0.33}\n",
      "{'loss': 0.5355, 'grad_norm': 0.33800339698791504, 'learning_rate': 0.00019666666666666666, 'epoch': 0.34}\n",
      "{'loss': 0.4945, 'grad_norm': 0.906649649143219, 'learning_rate': 0.00019333333333333333, 'epoch': 0.36}\n",
      "{'loss': 0.528, 'grad_norm': 0.6493905782699585, 'learning_rate': 0.00018999999999999998, 'epoch': 0.37}\n",
      "{'loss': 0.4764, 'grad_norm': 3.1008715629577637, 'learning_rate': 0.00018666666666666666, 'epoch': 0.38}\n",
      "{'loss': 0.4295, 'grad_norm': 3.4877395629882812, 'learning_rate': 0.00018333333333333334, 'epoch': 0.39}\n",
      "{'loss': 0.4971, 'grad_norm': 1.2256760597229004, 'learning_rate': 0.00017999999999999998, 'epoch': 0.4}\n",
      "{'loss': 0.5032, 'grad_norm': 1.2399888038635254, 'learning_rate': 0.00017666666666666666, 'epoch': 0.41}\n",
      "{'loss': 0.5005, 'grad_norm': 2.1141159534454346, 'learning_rate': 0.0001733333333333333, 'epoch': 0.42}\n",
      "{'loss': 0.4699, 'grad_norm': 1.0958269834518433, 'learning_rate': 0.00016999999999999999, 'epoch': 0.43}\n",
      "{'loss': 0.5032, 'grad_norm': 0.8280215859413147, 'learning_rate': 0.00016666666666666666, 'epoch': 0.44}\n",
      "{'loss': 0.4739, 'grad_norm': 0.28086239099502563, 'learning_rate': 0.0001633333333333333, 'epoch': 0.46}\n",
      "{'loss': 0.5315, 'grad_norm': 0.8524913787841797, 'learning_rate': 0.00015999999999999999, 'epoch': 0.47}\n",
      "{'loss': 0.4792, 'grad_norm': 0.4076267182826996, 'learning_rate': 0.00015666666666666666, 'epoch': 0.48}\n",
      "{'loss': 0.4494, 'grad_norm': 0.6065563559532166, 'learning_rate': 0.0001533333333333333, 'epoch': 0.49}\n",
      "{'loss': 0.457, 'grad_norm': 0.49125128984451294, 'learning_rate': 0.00015, 'epoch': 0.5}\n",
      "{'loss': 0.424, 'grad_norm': 1.1070095300674438, 'learning_rate': 0.00014666666666666664, 'epoch': 0.51}\n",
      "{'loss': 0.4484, 'grad_norm': 0.7774616479873657, 'learning_rate': 0.00014333333333333334, 'epoch': 0.52}\n",
      "{'loss': 0.4695, 'grad_norm': 0.39215153455734253, 'learning_rate': 0.00014, 'epoch': 0.53}\n",
      "{'loss': 0.4768, 'grad_norm': 0.947104275226593, 'learning_rate': 0.00013666666666666666, 'epoch': 0.54}\n",
      "{'loss': 0.4876, 'grad_norm': 1.1097593307495117, 'learning_rate': 0.0001333333333333333, 'epoch': 0.56}\n",
      "{'loss': 0.4845, 'grad_norm': 0.3977464735507965, 'learning_rate': 0.00013, 'epoch': 0.57}\n",
      "{'loss': 0.5089, 'grad_norm': 1.2215744256973267, 'learning_rate': 0.00012666666666666666, 'epoch': 0.58}\n",
      "{'loss': 0.5254, 'grad_norm': 0.5518038272857666, 'learning_rate': 0.0001233333333333333, 'epoch': 0.59}\n",
      "{'loss': 0.4458, 'grad_norm': 2.392087459564209, 'learning_rate': 0.00011999999999999999, 'epoch': 0.6}\n",
      "{'loss': 0.4787, 'grad_norm': 1.1322206258773804, 'learning_rate': 0.00011666666666666665, 'epoch': 0.61}\n",
      "{'loss': 0.4584, 'grad_norm': 1.0193103551864624, 'learning_rate': 0.00011333333333333331, 'epoch': 0.62}\n",
      "{'loss': 0.4948, 'grad_norm': 0.2698921263217926, 'learning_rate': 0.00010999999999999998, 'epoch': 0.63}\n",
      "{'loss': 0.4423, 'grad_norm': 3.2273218631744385, 'learning_rate': 0.00010666666666666667, 'epoch': 0.64}\n",
      "{'loss': 0.5107, 'grad_norm': 1.2199885845184326, 'learning_rate': 0.00010333333333333333, 'epoch': 0.66}\n",
      "{'loss': 0.4682, 'grad_norm': 0.4061329662799835, 'learning_rate': 9.999999999999999e-05, 'epoch': 0.67}\n",
      "{'loss': 0.4579, 'grad_norm': 2.821676015853882, 'learning_rate': 9.666666666666667e-05, 'epoch': 0.68}\n",
      "{'loss': 0.4531, 'grad_norm': 2.282726287841797, 'learning_rate': 9.333333333333333e-05, 'epoch': 0.69}\n",
      "{'loss': 0.4543, 'grad_norm': 2.4773435592651367, 'learning_rate': 8.999999999999999e-05, 'epoch': 0.7}\n",
      "{'loss': 0.4816, 'grad_norm': 1.4548152685165405, 'learning_rate': 8.666666666666665e-05, 'epoch': 0.71}\n",
      "{'loss': 0.4608, 'grad_norm': 3.3987247943878174, 'learning_rate': 8.333333333333333e-05, 'epoch': 0.72}\n",
      "{'loss': 0.4611, 'grad_norm': 1.2550582885742188, 'learning_rate': 7.999999999999999e-05, 'epoch': 0.73}\n",
      "{'loss': 0.4789, 'grad_norm': 0.853590190410614, 'learning_rate': 7.666666666666666e-05, 'epoch': 0.74}\n",
      "{'loss': 0.4814, 'grad_norm': 0.5511671304702759, 'learning_rate': 7.333333333333332e-05, 'epoch': 0.76}\n",
      "{'loss': 0.4191, 'grad_norm': 2.1112263202667236, 'learning_rate': 7e-05, 'epoch': 0.77}\n",
      "{'loss': 0.4477, 'grad_norm': 0.6131255030632019, 'learning_rate': 6.666666666666666e-05, 'epoch': 0.78}\n",
      "{'loss': 0.4687, 'grad_norm': 2.974245071411133, 'learning_rate': 6.333333333333333e-05, 'epoch': 0.79}\n",
      "{'loss': 0.4333, 'grad_norm': 0.35836759209632874, 'learning_rate': 5.9999999999999995e-05, 'epoch': 0.8}\n",
      "{'loss': 0.4889, 'grad_norm': 0.7579911351203918, 'learning_rate': 5.666666666666666e-05, 'epoch': 0.81}\n",
      "{'loss': 0.4671, 'grad_norm': 1.210325002670288, 'learning_rate': 5.333333333333333e-05, 'epoch': 0.82}\n",
      "{'loss': 0.4527, 'grad_norm': 1.9332242012023926, 'learning_rate': 4.9999999999999996e-05, 'epoch': 0.83}\n",
      "{'loss': 0.5121, 'grad_norm': 1.1252079010009766, 'learning_rate': 4.6666666666666665e-05, 'epoch': 0.84}\n",
      "{'loss': 0.4307, 'grad_norm': 0.851426362991333, 'learning_rate': 4.333333333333333e-05, 'epoch': 0.86}\n",
      "{'loss': 0.4483, 'grad_norm': 1.2138580083847046, 'learning_rate': 3.9999999999999996e-05, 'epoch': 0.87}\n",
      "{'loss': 0.4916, 'grad_norm': 0.9427465200424194, 'learning_rate': 3.666666666666666e-05, 'epoch': 0.88}\n",
      "{'loss': 0.4862, 'grad_norm': 0.8415171504020691, 'learning_rate': 3.333333333333333e-05, 'epoch': 0.89}\n",
      "{'loss': 0.4502, 'grad_norm': 3.409148693084717, 'learning_rate': 2.9999999999999997e-05, 'epoch': 0.9}\n",
      "{'loss': 0.5028, 'grad_norm': 0.4958963096141815, 'learning_rate': 2.6666666666666667e-05, 'epoch': 0.91}\n",
      "{'loss': 0.4414, 'grad_norm': 1.2976480722427368, 'learning_rate': 2.3333333333333332e-05, 'epoch': 0.92}\n",
      "{'loss': 0.4491, 'grad_norm': 0.813232958316803, 'learning_rate': 1.9999999999999998e-05, 'epoch': 0.93}\n",
      "{'loss': 0.4352, 'grad_norm': 0.983601987361908, 'learning_rate': 1.6666666666666664e-05, 'epoch': 0.94}\n",
      "{'loss': 0.48, 'grad_norm': 0.9971492886543274, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.96}\n",
      "{'loss': 0.4056, 'grad_norm': 0.6460140347480774, 'learning_rate': 9.999999999999999e-06, 'epoch': 0.97}\n",
      "{'loss': 0.4733, 'grad_norm': 0.4830600917339325, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.98}\n",
      "{'loss': 0.4958, 'grad_norm': 0.806296706199646, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.99}\n",
      "{'loss': 0.4379, 'grad_norm': 0.7120779156684875, 'learning_rate': 0.0, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/j/Documents/MLotsawa/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3da26a7a4708466786dc4944dace3c36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.44616544246673584, 'eval_bleu': 0.025, 'eval_chrf': 5.9012, 'eval_gen_len': 17.5048, 'eval_runtime': 633.0052, 'eval_samples_per_second': 7.899, 'eval_steps_per_second': 0.987, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 20905.1306, 'train_samples_per_second': 2.153, 'train_steps_per_second': 2.153, 'train_loss': 0.507969499376085, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=45000, training_loss=0.507969499376085, metrics={'train_runtime': 20905.1306, 'train_samples_per_second': 2.153, 'train_steps_per_second': 2.153, 'total_flos': 8.220634251264e+16, 'train_loss': 0.507969499376085, 'epoch': 1.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"rat-single-context\",\n",
    "    auto_find_batch_size=True,\n",
    "    predict_with_generate=True,\n",
    "    fp16=False, #check this\n",
    "    push_to_hub=False,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    num_train_epochs=1\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_with_contexts['train'],\n",
    "    eval_dataset=dataset_with_contexts['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    optimizers=(optimizer, None),\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
