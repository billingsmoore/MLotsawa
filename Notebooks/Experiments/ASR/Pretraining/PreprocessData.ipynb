{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "75b58048-7d14-4fc6-8085-1fc08c81b4a6",
      "metadata": {
        "id": "75b58048-7d14-4fc6-8085-1fc08c81b4a6"
      },
      "source": [
        "# Fine-Tune Whisper\n",
        "\n",
        "Adapted from guide here: https://huggingface.co/blog/fine-tune-whisper"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b219c9dd-39b6-4a95-b2a1-3f547a1e7bc0",
      "metadata": {
        "id": "b219c9dd-39b6-4a95-b2a1-3f547a1e7bc0"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a2787582-554f-44ce-9f38-4180a5ed6b44",
      "metadata": {
        "id": "a2787582-554f-44ce-9f38-4180a5ed6b44"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/j/Documents/MLotsawa/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['file_name', 'uni', 'wylie', 'url', 'dept', 'grade', 'char_len', 'audio_len'],\n",
              "        num_rows: 379522\n",
              "    })\n",
              "    dev: Dataset({\n",
              "        features: ['file_name', 'uni', 'wylie', 'url', 'dept', 'grade', 'char_len', 'audio_len'],\n",
              "        num_rows: 22324\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['file_name', 'uni', 'wylie', 'url', 'dept', 'grade', 'char_len', 'audio_len'],\n",
              "        num_rows: 44649\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import load_from_disk\n",
        "\n",
        "dataset = load_from_disk('tt-asr-ds')\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d63b2d2-f68a-4d74-b7f1-5127f6d16605",
      "metadata": {
        "id": "2d63b2d2-f68a-4d74-b7f1-5127f6d16605"
      },
      "source": [
        "## Prepare Feature Extractor, Tokenizer and Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bc77d7bb-f9e2-47f5-b663-30f7a4321ce5",
      "metadata": {
        "id": "bc77d7bb-f9e2-47f5-b663-30f7a4321ce5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-03 18:12:57.386889: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-06-03 18:12:57.489640: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1748988777.530377    5067 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1748988777.543333    5067 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1748988777.627615    5067 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1748988777.627639    5067 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1748988777.627640    5067 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1748988777.627642    5067 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-06-03 18:12:57.638884: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "from transformers import WhisperFeatureExtractor, WhisperTokenizer, WhisperProcessor\n",
        "\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-tiny\")\n",
        "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-tiny\", language=\"bo\", task=\"transcribe\")\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\", language=\"bo\", task=\"transcribe\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "381acd09-0b0f-4d04-9eb3-f028ac0e5f2c",
      "metadata": {
        "id": "381acd09-0b0f-4d04-9eb3-f028ac0e5f2c"
      },
      "source": [
        "### Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6525c478-8962-4394-a1c4-103c54cce170",
      "metadata": {
        "id": "6525c478-8962-4394-a1c4-103c54cce170"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import requests\n",
        "import tempfile\n",
        "\n",
        "def prepare_dataset(batch):\n",
        "    # Download audio from URL\n",
        "    response = requests.get(batch[\"url\"])\n",
        "    response.raise_for_status()\n",
        "\n",
        "    # Save to temporary WAV file\n",
        "    with tempfile.NamedTemporaryFile(suffix=\".wav\") as tmp:\n",
        "        tmp.write(response.content)\n",
        "        tmp.flush()\n",
        "\n",
        "        # Load and resample audio using librosa\n",
        "        waveform, sr = librosa.load(tmp.name, sr=16000)\n",
        "\n",
        "    # Feature extraction\n",
        "    batch[\"input_features\"] = feature_extractor(\n",
        "        waveform, sampling_rate=16000\n",
        "    ).input_features[0]\n",
        "\n",
        "    # Tokenize transcription\n",
        "    batch[\"labels\"] = tokenizer(\n",
        "        batch[\"uni\"], max_length=448, truncation=True\n",
        "    ).input_ids\n",
        "\n",
        "    return batch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b73ab39-ffaf-4b9e-86e5-782963c6134b",
      "metadata": {
        "id": "7b73ab39-ffaf-4b9e-86e5-782963c6134b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map (num_proc=4):   6%|â–Œ         | 20996/379522 [11:36<10:01:26,  9.94 examples/s]"
          ]
        }
      ],
      "source": [
        "dataset = dataset.map(prepare_dataset, remove_columns=dataset.column_names[\"train\"], num_proc=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00607692",
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset.save_to_disk('processed-ds')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
