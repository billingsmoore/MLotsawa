{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('billingsmoore/tibetan-to-english-translation-dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset['train'].train_test_split(.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tibetan': 'ལྷན་ཅིག་བྲག་ཕུག་མཱ་ར་ཏི་ཀར་བྱོན༔',\n",
       " 'phonetic': 'lhenchik drakpuk ma ra tikar jön',\n",
       " 'english': 'And together with Padmākara you left for Māratika Cave.'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Unfinetuned Tokenizer, Model, and Data Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorForSeq2Seq, AutoModelForSeq2SeqLM\n",
    "\n",
    "checkpoint = \"billingsmoore/tibetan-to-english-translation\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint, device_map=\"cuda:0\")\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "\n",
    "The dataset can now be tokenized for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translation_preprocess_function(examples):\n",
    "\n",
    "    # Prepare translation inputs and targets\n",
    "    translation_inputs = ['Translate Tibetan to English: ' + example for example in examples['tibetan']]\n",
    "    translation_targets = [example for example in examples['english']]\n",
    "    \n",
    "    # Tokenize translation inputs and targets\n",
    "    translation_model_inputs = tokenizer(translation_inputs, text_target=translation_targets, \n",
    "                                         max_length=300, truncation=True, padding=\"max_length\")\n",
    "    \n",
    "    \n",
    "    return translation_model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transliteration_preprocess_function(examples):\n",
    "    # Prepare transliteration inputs and targets\n",
    "    transliteration_inputs = ['Transliterate: ' + example for example in examples['tibetan']]\n",
    "    transliteration_targets = [example for example in examples['phonetic']]\n",
    "    \n",
    "    # Tokenize transliteration inputs and targets\n",
    "    transliteration_model_inputs = tokenizer(transliteration_inputs, text_target=transliteration_targets, \n",
    "                                             max_length=300, truncation=True, padding=\"max_length\")\n",
    "    \n",
    "    return transliteration_model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e59c788ea8d4efeab4ed746191aef99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/69042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d83a584a12eb4a17b6b8c7761c9c7001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12184 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "translation_tokenized_dataset = dataset.map(translation_preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2270a5d68f34d59a0bad3589c29df3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/69042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d17e68d76ee748859a358f2cfde92886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12184 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transliteration_tokenized_dataset = dataset.map(transliteration_preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n",
    "Finally, we can train the model. Note that the optimizer used is Adafactor. This is the optimizer that is preferred for translation tasks and for the T5 model in general. The transformers api includes a built in version of Adafactor, but I define it separately here so that we can optimize it with the 'accelerate' library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, Adafactor\n",
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "\n",
    "optimizer = Adafactor(\n",
    "    model.parameters(), \n",
    "    scale_parameter=True, \n",
    "    relative_step=False, \n",
    "    warmup_init=False, \n",
    "    lr=3e-4\n",
    ")\n",
    "\n",
    "model, optimizer = accelerator.prepare(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbillingsmoore\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "early_stop = EarlyStoppingCallback(early_stopping_patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35aa3f802e434da293a089ca3779cb07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/86310 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c9dc3cc0dc64aba98664ba64ce67e01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/172610 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c7ebed05ef47b78eb519bf579f69f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/345210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1257, 'grad_norm': 0.5513824224472046, 'learning_rate': 0.00029956548188059436, 'epoch': 0.01}\n",
      "{'loss': 0.0731, 'grad_norm': 0.2667251527309418, 'learning_rate': 0.00029913096376118885, 'epoch': 0.03}\n",
      "{'loss': 0.0571, 'grad_norm': 0.5558445453643799, 'learning_rate': 0.00029869644564178323, 'epoch': 0.04}\n",
      "{'loss': 0.0398, 'grad_norm': 0.4607163071632385, 'learning_rate': 0.00029826192752237767, 'epoch': 0.06}\n",
      "{'loss': 0.0394, 'grad_norm': 0.6821025609970093, 'learning_rate': 0.0002978274094029721, 'epoch': 0.07}\n",
      "{'loss': 0.0332, 'grad_norm': 0.19666744768619537, 'learning_rate': 0.0002973928912835665, 'epoch': 0.09}\n",
      "{'loss': 0.0305, 'grad_norm': 0.20285020768642426, 'learning_rate': 0.0002969583731641609, 'epoch': 0.1}\n",
      "{'loss': 0.0264, 'grad_norm': 0.20725837349891663, 'learning_rate': 0.00029652385504475536, 'epoch': 0.12}\n",
      "{'loss': 0.0285, 'grad_norm': 0.16038674116134644, 'learning_rate': 0.00029608933692534974, 'epoch': 0.13}\n",
      "{'loss': 0.0291, 'grad_norm': 1.1200592517852783, 'learning_rate': 0.0002956548188059442, 'epoch': 0.14}\n",
      "{'loss': 0.0206, 'grad_norm': 0.12564624845981598, 'learning_rate': 0.0002952203006865386, 'epoch': 0.16}\n",
      "{'loss': 0.0241, 'grad_norm': 0.17746995389461517, 'learning_rate': 0.000294785782567133, 'epoch': 0.17}\n",
      "{'loss': 0.0168, 'grad_norm': 0.03984368219971657, 'learning_rate': 0.00029435126444772743, 'epoch': 0.19}\n",
      "{'loss': 0.0163, 'grad_norm': 0.07350917160511017, 'learning_rate': 0.00029391674632832187, 'epoch': 0.2}\n",
      "{'loss': 0.0248, 'grad_norm': 0.16493266820907593, 'learning_rate': 0.00029348222820891625, 'epoch': 0.22}\n",
      "{'loss': 0.0187, 'grad_norm': 0.2368856966495514, 'learning_rate': 0.00029304771008951074, 'epoch': 0.23}\n",
      "{'loss': 0.0164, 'grad_norm': 0.14885607361793518, 'learning_rate': 0.0002926131919701051, 'epoch': 0.25}\n",
      "{'loss': 0.0167, 'grad_norm': 0.028629472479224205, 'learning_rate': 0.00029217867385069956, 'epoch': 0.26}\n",
      "{'loss': 0.0123, 'grad_norm': 0.17153479158878326, 'learning_rate': 0.000291744155731294, 'epoch': 0.28}\n",
      "{'loss': 0.0178, 'grad_norm': 0.08064968138933182, 'learning_rate': 0.0002913096376118884, 'epoch': 0.29}\n",
      "{'loss': 0.0173, 'grad_norm': 1.78281831741333, 'learning_rate': 0.0002908751194924828, 'epoch': 0.3}\n",
      "{'loss': 0.0139, 'grad_norm': 0.2222623974084854, 'learning_rate': 0.00029044060137307725, 'epoch': 0.32}\n",
      "{'loss': 0.0123, 'grad_norm': 0.017824048176407814, 'learning_rate': 0.00029000608325367163, 'epoch': 0.33}\n",
      "{'loss': 0.0139, 'grad_norm': 0.14624258875846863, 'learning_rate': 0.00028957156513426607, 'epoch': 0.35}\n",
      "{'loss': 0.0166, 'grad_norm': 0.0514930784702301, 'learning_rate': 0.0002891370470148605, 'epoch': 0.36}\n",
      "{'loss': 0.0114, 'grad_norm': 0.05368685722351074, 'learning_rate': 0.0002887025288954549, 'epoch': 0.38}\n",
      "{'loss': 0.0134, 'grad_norm': 0.050237856805324554, 'learning_rate': 0.0002882680107760493, 'epoch': 0.39}\n",
      "{'loss': 0.0149, 'grad_norm': 0.12801112234592438, 'learning_rate': 0.00028783349265664376, 'epoch': 0.41}\n",
      "{'loss': 0.0157, 'grad_norm': 0.16701403260231018, 'learning_rate': 0.0002873989745372382, 'epoch': 0.42}\n",
      "{'loss': 0.0133, 'grad_norm': 0.03066764771938324, 'learning_rate': 0.0002869644564178326, 'epoch': 0.43}\n",
      "{'loss': 0.0094, 'grad_norm': 0.06702698022127151, 'learning_rate': 0.000286529938298427, 'epoch': 0.45}\n",
      "{'loss': 0.0159, 'grad_norm': 0.11592750996351242, 'learning_rate': 0.00028609542017902145, 'epoch': 0.46}\n",
      "{'loss': 0.014, 'grad_norm': 0.02927318401634693, 'learning_rate': 0.00028566090205961583, 'epoch': 0.48}\n",
      "{'loss': 0.0174, 'grad_norm': 0.35786184668540955, 'learning_rate': 0.00028522638394021027, 'epoch': 0.49}\n",
      "{'loss': 0.0108, 'grad_norm': 0.06478556245565414, 'learning_rate': 0.0002847918658208047, 'epoch': 0.51}\n",
      "{'loss': 0.0126, 'grad_norm': 0.10741078853607178, 'learning_rate': 0.00028435734770139914, 'epoch': 0.52}\n",
      "{'loss': 0.0193, 'grad_norm': 0.07116858661174774, 'learning_rate': 0.0002839228295819936, 'epoch': 0.54}\n",
      "{'loss': 0.0121, 'grad_norm': 0.16343989968299866, 'learning_rate': 0.00028348831146258796, 'epoch': 0.55}\n",
      "{'loss': 0.0127, 'grad_norm': 0.1195828765630722, 'learning_rate': 0.0002830537933431824, 'epoch': 0.56}\n",
      "{'loss': 0.0116, 'grad_norm': 0.06767131388187408, 'learning_rate': 0.00028261927522377683, 'epoch': 0.58}\n",
      "{'loss': 0.0157, 'grad_norm': 0.1521524041891098, 'learning_rate': 0.0002821847571043712, 'epoch': 0.59}\n",
      "{'loss': 0.0132, 'grad_norm': 0.18433772027492523, 'learning_rate': 0.00028175023898496565, 'epoch': 0.61}\n",
      "{'loss': 0.011, 'grad_norm': 0.08346530050039291, 'learning_rate': 0.0002813157208655601, 'epoch': 0.62}\n",
      "{'loss': 0.0083, 'grad_norm': 0.17872756719589233, 'learning_rate': 0.00028088120274615447, 'epoch': 0.64}\n",
      "{'loss': 0.012, 'grad_norm': 0.029810607433319092, 'learning_rate': 0.0002804466846267489, 'epoch': 0.65}\n",
      "{'loss': 0.0108, 'grad_norm': 0.32080549001693726, 'learning_rate': 0.00028001216650734334, 'epoch': 0.67}\n",
      "{'loss': 0.0141, 'grad_norm': 0.23678305745124817, 'learning_rate': 0.0002795776483879377, 'epoch': 0.68}\n",
      "{'loss': 0.015, 'grad_norm': 0.13166543841362, 'learning_rate': 0.0002791431302685322, 'epoch': 0.7}\n",
      "{'loss': 0.0106, 'grad_norm': 0.058492958545684814, 'learning_rate': 0.0002787086121491266, 'epoch': 0.71}\n",
      "{'loss': 0.0115, 'grad_norm': 0.08622149378061295, 'learning_rate': 0.000278274094029721, 'epoch': 0.72}\n",
      "{'loss': 0.012, 'grad_norm': 0.19379326701164246, 'learning_rate': 0.00027783957591031547, 'epoch': 0.74}\n",
      "{'loss': 0.0147, 'grad_norm': 0.21976850926876068, 'learning_rate': 0.00027740505779090985, 'epoch': 0.75}\n",
      "{'loss': 0.0132, 'grad_norm': 0.12550564110279083, 'learning_rate': 0.0002769705396715043, 'epoch': 0.77}\n",
      "{'loss': 0.0079, 'grad_norm': 0.19505685567855835, 'learning_rate': 0.0002765360215520987, 'epoch': 0.78}\n",
      "{'loss': 0.009, 'grad_norm': 0.17748546600341797, 'learning_rate': 0.0002761015034326931, 'epoch': 0.8}\n",
      "{'loss': 0.0131, 'grad_norm': 1.572062611579895, 'learning_rate': 0.00027566698531328754, 'epoch': 0.81}\n",
      "{'loss': 0.0111, 'grad_norm': 0.059157468378543854, 'learning_rate': 0.000275232467193882, 'epoch': 0.83}\n",
      "{'loss': 0.0098, 'grad_norm': 0.04384060204029083, 'learning_rate': 0.00027479794907447636, 'epoch': 0.84}\n",
      "{'loss': 0.0119, 'grad_norm': 0.012962381355464458, 'learning_rate': 0.0002743634309550708, 'epoch': 0.85}\n",
      "{'loss': 0.0131, 'grad_norm': 0.06884931772947311, 'learning_rate': 0.00027392891283566524, 'epoch': 0.87}\n",
      "{'loss': 0.0066, 'grad_norm': 0.14968883991241455, 'learning_rate': 0.0002734943947162596, 'epoch': 0.88}\n",
      "{'loss': 0.0086, 'grad_norm': 0.01455608382821083, 'learning_rate': 0.00027305987659685405, 'epoch': 0.9}\n",
      "{'loss': 0.0079, 'grad_norm': 0.40580859780311584, 'learning_rate': 0.0002726253584774485, 'epoch': 0.91}\n",
      "{'loss': 0.0087, 'grad_norm': 0.2271566390991211, 'learning_rate': 0.00027219084035804287, 'epoch': 0.93}\n",
      "{'loss': 0.0072, 'grad_norm': 0.013274137862026691, 'learning_rate': 0.00027175632223863736, 'epoch': 0.94}\n",
      "{'loss': 0.0077, 'grad_norm': 0.0389116145670414, 'learning_rate': 0.00027132180411923174, 'epoch': 0.96}\n",
      "{'loss': 0.0069, 'grad_norm': 0.06703609973192215, 'learning_rate': 0.0002708872859998261, 'epoch': 0.97}\n",
      "{'loss': 0.0113, 'grad_norm': 0.20441995561122894, 'learning_rate': 0.0002704527678804206, 'epoch': 0.98}\n",
      "{'loss': 0.0082, 'grad_norm': 0.08228243887424469, 'learning_rate': 0.000270018249761015, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/j/Desktop/MLotsawa/.venv/lib/python3.10/site-packages/transformers/generation/utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4baa55d19e3f4a058b92409d8c2bf875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1523 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "early stopping required metric_for_best_model, but did not find eval_loss so early stopping is disabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_translation_loss': 0.3829881548881531, 'eval_translation_bleu': 0.0181, 'eval_translation_gen_len': 17.6803, 'eval_translation_runtime': 1849.7193, 'eval_translation_samples_per_second': 6.587, 'eval_translation_steps_per_second': 0.823, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a6a719982c04da9b4d221e75f0b3ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1523 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "early stopping required metric_for_best_model, but did not find eval_loss so early stopping is disabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_transliteration_loss': 0.007150018122047186, 'eval_transliteration_bleu': 67.3028, 'eval_transliteration_gen_len': 17.6705, 'eval_transliteration_runtime': 1852.5929, 'eval_transliteration_samples_per_second': 6.577, 'eval_transliteration_steps_per_second': 0.822, 'epoch': 1.0}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"The `metric_for_best_model` training argument is set to 'eval_loss', which is not found in the evaluation metrics. The available evaluation metrics are: ['eval_translation_loss', 'eval_translation_bleu', 'eval_translation_gen_len', 'eval_translation_runtime', 'eval_translation_samples_per_second', 'eval_translation_steps_per_second', 'epoch', 'eval_transliteration_loss', 'eval_transliteration_bleu', 'eval_transliteration_gen_len', 'eval_transliteration_runtime', 'eval_transliteration_samples_per_second', 'eval_transliteration_steps_per_second']. Consider changing the `metric_for_best_model` via the TrainingArguments.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/MLotsawa/.venv/lib/python3.10/site-packages/transformers/trainer.py:3022\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   3021\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3022\u001b[0m     metric_value \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetric_to_check\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   3023\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'eval_loss'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 25\u001b[0m\n\u001b[1;32m      1\u001b[0m training_args \u001b[38;5;241m=\u001b[39m Seq2SeqTrainingArguments(\n\u001b[1;32m      2\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdual-task-add\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     auto_find_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m     14\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     15\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[early_stop]\n\u001b[1;32m     23\u001b[0m )\n\u001b[0;32m---> 25\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/MLotsawa/.venv/lib/python3.10/site-packages/transformers/trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/MLotsawa/.venv/lib/python3.10/site-packages/accelerate/utils/memory.py:157\u001b[0m, in \u001b[0;36mfind_executable_batch_size.<locals>.decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo executable batch size found, reached zero.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_reduce_batch_size(e):\n",
      "File \u001b[0;32m~/Desktop/MLotsawa/.venv/lib/python3.10/site-packages/transformers/trainer.py:2487\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2484\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2487\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[1;32m   2490\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_xla_available():\n\u001b[1;32m   2491\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/MLotsawa/.venv/lib/python3.10/site-packages/transformers/trainer.py:2918\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2915\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate(trial, ignore_keys_for_eval)\n\u001b[1;32m   2917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 2918\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2919\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_save(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/Desktop/MLotsawa/.venv/lib/python3.10/site-packages/transformers/trainer.py:3024\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   3022\u001b[0m     metric_value \u001b[38;5;241m=\u001b[39m metrics[metric_to_check]\n\u001b[1;32m   3023\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m-> 3024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m   3025\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `metric_for_best_model` training argument is set to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_to_check\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, which is not found in the evaluation metrics. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3026\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe available evaluation metrics are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(metrics\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Consider changing the `metric_for_best_model` via the TrainingArguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3027\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m   3029\u001b[0m operator \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mgreater \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgreater_is_better \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mless\n\u001b[1;32m   3030\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3031\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mbest_metric \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3032\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mbest_model_checkpoint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3033\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m operator(metric_value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mbest_metric)\n\u001b[1;32m   3034\u001b[0m ):\n",
      "\u001b[0;31mKeyError\u001b[0m: \"The `metric_for_best_model` training argument is set to 'eval_loss', which is not found in the evaluation metrics. The available evaluation metrics are: ['eval_translation_loss', 'eval_translation_bleu', 'eval_translation_gen_len', 'eval_translation_runtime', 'eval_translation_samples_per_second', 'eval_translation_steps_per_second', 'epoch', 'eval_transliteration_loss', 'eval_transliteration_bleu', 'eval_transliteration_gen_len', 'eval_transliteration_runtime', 'eval_transliteration_samples_per_second', 'eval_transliteration_steps_per_second']. Consider changing the `metric_for_best_model` via the TrainingArguments.\""
     ]
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"dual-task-add\",\n",
    "    auto_find_batch_size=True,\n",
    "    predict_with_generate=True,\n",
    "    fp16=False, #check this\n",
    "    push_to_hub=False,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    num_train_epochs=10,\n",
    "    metric_for_best_model='eval_transliteration_loss'\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=transliteration_tokenized_dataset['train'],\n",
    "    eval_dataset={'translation':translation_tokenized_dataset['test'], 'transliteration':transliteration_tokenized_dataset['test']},\n",
    "    tokenizer=tokenizer,\n",
    "    optimizers=(optimizer, None),\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
