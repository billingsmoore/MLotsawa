{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('billingsmoore/tibetan-to-english-translation-dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset['train'].train_test_split(.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tibetan': 'སྒྲིབ་དག་བྱིན་རླབས་དབང་བསྐུར་ཐོབ།།',\n",
       " 'phonetic': 'drib dak jinlab wangkur tob',\n",
       " 'english': 'Purify obscurations confer blessings and empowerment'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Unfinetuned Tokenizer, Model, and Data Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorForSeq2Seq, AutoModelForSeq2SeqLM\n",
    "\n",
    "checkpoint = \"billingsmoore/tibetan-to-english-translation\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint, device_map=\"cuda:0\")\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "\n",
    "The dataset can now be tokenized for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translation_preprocess_function(examples):\n",
    "\n",
    "    # Prepare translation inputs and targets\n",
    "    translation_inputs = ['Translate Tibetan to English: ' + example for example in examples['tibetan']]\n",
    "    translation_targets = [example for example in examples['english']]\n",
    "    \n",
    "    # Tokenize translation inputs and targets\n",
    "    translation_model_inputs = tokenizer(translation_inputs, text_target=translation_targets, \n",
    "                                         max_length=300, truncation=True, padding=\"max_length\")\n",
    "    \n",
    "    \n",
    "    return translation_model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transliteration_preprocess_function(examples):\n",
    "    # Prepare transliteration inputs and targets\n",
    "    transliteration_inputs = ['Transliterate: ' + example for example in examples['tibetan']]\n",
    "    transliteration_targets = [example for example in examples['phonetic']]\n",
    "    \n",
    "    # Tokenize transliteration inputs and targets\n",
    "    transliteration_model_inputs = tokenizer(transliteration_inputs, text_target=transliteration_targets, \n",
    "                                             max_length=300, truncation=True, padding=\"max_length\")\n",
    "    \n",
    "    return transliteration_model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "910474a955bf450592c18e8a40b237ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/69042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb1f1a66d62d410bb5bcb879e0bfc4cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12184 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "translation_tokenized_dataset = dataset.map(translation_preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e050519deca48c6b3e525d9a848e210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/69042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd01e6f426774b3fbe8e90dda831c378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12184 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transliteration_tokenized_dataset = dataset.map(transliteration_preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "tokenized_dataset = {}\n",
    "\n",
    "tokenized_dataset['train'] = concatenate_datasets([translation_tokenized_dataset['train'], transliteration_tokenized_dataset['train']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n",
    "Finally, we can train the model. Note that the optimizer used is Adafactor. This is the optimizer that is preferred for translation tasks and for the T5 model in general. The transformers api includes a built in version of Adafactor, but I define it separately here so that we can optimize it with the 'accelerate' library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, Adafactor\n",
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "\n",
    "optimizer = Adafactor(\n",
    "    model.parameters(), \n",
    "    scale_parameter=True, \n",
    "    relative_step=False, \n",
    "    warmup_init=False, \n",
    "    lr=3e-4\n",
    ")\n",
    "\n",
    "model, optimizer = accelerator.prepare(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbillingsmoore\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/j/Desktop/MLotsawa/Notebooks/Models/DualTaskTibetanToEnglish/wandb/run-20241015_114057-s3x9utgy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/billingsmoore/huggingface/runs/s3x9utgy' target=\"_blank\">dual-task-add-both</a></strong> to <a href='https://wandb.ai/billingsmoore/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/billingsmoore/huggingface' target=\"_blank\">https://wandb.ai/billingsmoore/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/billingsmoore/huggingface/runs/s3x9utgy' target=\"_blank\">https://wandb.ai/billingsmoore/huggingface/runs/s3x9utgy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b89e088a5a41458aadfdf8bb37a91a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3696f857f034fb8be0ad1c31d9f4bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34521 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c513a897024435b0ae6def27e5d4fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69042 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1273, 'grad_norm': 0.19353359937667847, 'learning_rate': 0.0002978274094029721, 'epoch': 0.01}\n",
      "{'loss': 0.0756, 'grad_norm': 0.5356396436691284, 'learning_rate': 0.0002956548188059442, 'epoch': 0.01}\n",
      "{'loss': 0.0577, 'grad_norm': 0.29399168491363525, 'learning_rate': 0.00029348222820891625, 'epoch': 0.02}\n",
      "{'loss': 0.0457, 'grad_norm': 0.4854101836681366, 'learning_rate': 0.0002913096376118884, 'epoch': 0.03}\n",
      "{'loss': 0.0448, 'grad_norm': 0.27622082829475403, 'learning_rate': 0.0002891370470148605, 'epoch': 0.04}\n",
      "{'loss': 0.0373, 'grad_norm': 0.509633481502533, 'learning_rate': 0.0002869644564178326, 'epoch': 0.04}\n",
      "{'loss': 0.0443, 'grad_norm': 0.3819696605205536, 'learning_rate': 0.0002847918658208047, 'epoch': 0.05}\n",
      "{'loss': 0.0354, 'grad_norm': 0.24780891835689545, 'learning_rate': 0.00028261927522377683, 'epoch': 0.06}\n",
      "{'loss': 0.0349, 'grad_norm': 0.7833503484725952, 'learning_rate': 0.0002804466846267489, 'epoch': 0.07}\n",
      "{'loss': 0.0326, 'grad_norm': 0.1322004646062851, 'learning_rate': 0.000278274094029721, 'epoch': 0.07}\n",
      "{'loss': 0.0319, 'grad_norm': 0.16236314177513123, 'learning_rate': 0.0002761015034326931, 'epoch': 0.08}\n",
      "{'loss': 0.0286, 'grad_norm': 0.2572244107723236, 'learning_rate': 0.00027392891283566524, 'epoch': 0.09}\n",
      "{'loss': 0.029, 'grad_norm': 0.8751989603042603, 'learning_rate': 0.00027175632223863736, 'epoch': 0.09}\n",
      "{'loss': 0.0269, 'grad_norm': 0.25555309653282166, 'learning_rate': 0.00026958373164160944, 'epoch': 0.1}\n",
      "{'loss': 0.0252, 'grad_norm': 0.2654252350330353, 'learning_rate': 0.0002674111410445815, 'epoch': 0.11}\n",
      "{'loss': 0.0246, 'grad_norm': 0.46243005990982056, 'learning_rate': 0.00026523855044755364, 'epoch': 0.12}\n",
      "{'loss': 0.0341, 'grad_norm': 0.03393151983618736, 'learning_rate': 0.00026306595985052577, 'epoch': 0.12}\n",
      "{'loss': 0.0236, 'grad_norm': 0.6470674276351929, 'learning_rate': 0.00026089336925349784, 'epoch': 0.13}\n",
      "{'loss': 0.0266, 'grad_norm': 0.23110337555408478, 'learning_rate': 0.00025872077865646997, 'epoch': 0.14}\n",
      "{'loss': 0.0295, 'grad_norm': 0.24387824535369873, 'learning_rate': 0.0002565481880594421, 'epoch': 0.14}\n",
      "{'loss': 0.0238, 'grad_norm': 0.6119394898414612, 'learning_rate': 0.00025437559746241417, 'epoch': 0.15}\n",
      "{'loss': 0.0246, 'grad_norm': 0.32365474104881287, 'learning_rate': 0.00025220300686538624, 'epoch': 0.16}\n",
      "{'loss': 0.0242, 'grad_norm': 0.16415196657180786, 'learning_rate': 0.00025003041626835837, 'epoch': 0.17}\n",
      "{'loss': 0.021, 'grad_norm': 0.11245685815811157, 'learning_rate': 0.0002478578256713305, 'epoch': 0.17}\n",
      "{'loss': 0.022, 'grad_norm': 0.20673006772994995, 'learning_rate': 0.00024568523507430257, 'epoch': 0.18}\n",
      "{'loss': 0.0265, 'grad_norm': 0.32598331570625305, 'learning_rate': 0.00024351264447727467, 'epoch': 0.19}\n",
      "{'loss': 0.0254, 'grad_norm': 0.2066226750612259, 'learning_rate': 0.00024134005388024677, 'epoch': 0.2}\n",
      "{'loss': 0.024, 'grad_norm': 0.46810832619667053, 'learning_rate': 0.0002391674632832189, 'epoch': 0.2}\n",
      "{'loss': 0.0223, 'grad_norm': 0.09191402047872543, 'learning_rate': 0.000236994872686191, 'epoch': 0.21}\n",
      "{'loss': 0.0237, 'grad_norm': 0.40543845295906067, 'learning_rate': 0.0002348222820891631, 'epoch': 0.22}\n",
      "{'loss': 0.0218, 'grad_norm': 0.23017853498458862, 'learning_rate': 0.00023264969149213523, 'epoch': 0.22}\n",
      "{'loss': 0.0225, 'grad_norm': 0.1993221938610077, 'learning_rate': 0.0002304771008951073, 'epoch': 0.23}\n",
      "{'loss': 0.0235, 'grad_norm': 0.2951313853263855, 'learning_rate': 0.0002283045102980794, 'epoch': 0.24}\n",
      "{'loss': 0.0246, 'grad_norm': 0.13085827231407166, 'learning_rate': 0.0002261319197010515, 'epoch': 0.25}\n",
      "{'loss': 0.0218, 'grad_norm': 0.19967569410800934, 'learning_rate': 0.00022395932910402363, 'epoch': 0.25}\n",
      "{'loss': 0.0255, 'grad_norm': 0.17386530339717865, 'learning_rate': 0.00022178673850699573, 'epoch': 0.26}\n",
      "{'loss': 0.0208, 'grad_norm': 0.1913604438304901, 'learning_rate': 0.00021961414790996783, 'epoch': 0.27}\n",
      "{'loss': 0.0215, 'grad_norm': 0.1649082750082016, 'learning_rate': 0.0002174415573129399, 'epoch': 0.28}\n",
      "{'loss': 0.0191, 'grad_norm': 0.0486704483628273, 'learning_rate': 0.00021526896671591203, 'epoch': 0.28}\n",
      "{'loss': 0.024, 'grad_norm': 0.2953955829143524, 'learning_rate': 0.00021309637611888413, 'epoch': 0.29}\n",
      "{'loss': 0.0232, 'grad_norm': 0.17363908886909485, 'learning_rate': 0.00021092378552185626, 'epoch': 0.3}\n",
      "{'loss': 0.0241, 'grad_norm': 0.44790565967559814, 'learning_rate': 0.00020875119492482836, 'epoch': 0.3}\n",
      "{'loss': 0.0187, 'grad_norm': 0.7061352133750916, 'learning_rate': 0.00020657860432780046, 'epoch': 0.31}\n",
      "{'loss': 0.0201, 'grad_norm': 0.33281245827674866, 'learning_rate': 0.00020440601373077254, 'epoch': 0.32}\n",
      "{'loss': 0.0224, 'grad_norm': 0.13450472056865692, 'learning_rate': 0.00020223342313374466, 'epoch': 0.33}\n",
      "{'loss': 0.0194, 'grad_norm': 0.31190940737724304, 'learning_rate': 0.00020006083253671676, 'epoch': 0.33}\n",
      "{'loss': 0.0203, 'grad_norm': 0.3418930768966675, 'learning_rate': 0.00019788824193968886, 'epoch': 0.34}\n",
      "{'loss': 0.0184, 'grad_norm': 0.2671009600162506, 'learning_rate': 0.000195715651342661, 'epoch': 0.35}\n",
      "{'loss': 0.0234, 'grad_norm': 0.3466199040412903, 'learning_rate': 0.00019354306074563307, 'epoch': 0.35}\n",
      "{'loss': 0.0182, 'grad_norm': 0.051946692168712616, 'learning_rate': 0.00019137047014860517, 'epoch': 0.36}\n",
      "{'loss': 0.023, 'grad_norm': 0.4069294035434723, 'learning_rate': 0.0001891978795515773, 'epoch': 0.37}\n",
      "{'loss': 0.0199, 'grad_norm': 0.5616439580917358, 'learning_rate': 0.0001870252889545494, 'epoch': 0.38}\n",
      "{'loss': 0.0219, 'grad_norm': 0.3056151866912842, 'learning_rate': 0.0001848526983575215, 'epoch': 0.38}\n",
      "{'loss': 0.0213, 'grad_norm': 0.1308666169643402, 'learning_rate': 0.00018268010776049362, 'epoch': 0.39}\n",
      "{'loss': 0.0184, 'grad_norm': 0.12237431854009628, 'learning_rate': 0.0001805075171634657, 'epoch': 0.4}\n",
      "{'loss': 0.0216, 'grad_norm': 0.18185465037822723, 'learning_rate': 0.0001783349265664378, 'epoch': 0.41}\n",
      "{'loss': 0.017, 'grad_norm': 0.502490758895874, 'learning_rate': 0.0001761623359694099, 'epoch': 0.41}\n",
      "{'loss': 0.0181, 'grad_norm': 0.18781720101833344, 'learning_rate': 0.00017398974537238202, 'epoch': 0.42}\n",
      "{'loss': 0.0203, 'grad_norm': 0.46021541953086853, 'learning_rate': 0.00017181715477535413, 'epoch': 0.43}\n",
      "{'loss': 0.0176, 'grad_norm': 0.18600919842720032, 'learning_rate': 0.00016964456417832623, 'epoch': 0.43}\n",
      "{'loss': 0.0243, 'grad_norm': 0.3353152573108673, 'learning_rate': 0.00016747197358129833, 'epoch': 0.44}\n",
      "{'loss': 0.021, 'grad_norm': 0.06801659613847733, 'learning_rate': 0.00016529938298427043, 'epoch': 0.45}\n",
      "{'loss': 0.0204, 'grad_norm': 0.29136842489242554, 'learning_rate': 0.00016312679238724253, 'epoch': 0.46}\n",
      "{'loss': 0.0174, 'grad_norm': 0.7802876234054565, 'learning_rate': 0.00016095420179021466, 'epoch': 0.46}\n",
      "{'loss': 0.02, 'grad_norm': 0.396329790353775, 'learning_rate': 0.00015878161119318676, 'epoch': 0.47}\n",
      "{'loss': 0.0164, 'grad_norm': 0.12247548252344131, 'learning_rate': 0.00015660902059615883, 'epoch': 0.48}\n",
      "{'loss': 0.0191, 'grad_norm': 0.12258180230855942, 'learning_rate': 0.00015443642999913093, 'epoch': 0.49}\n",
      "{'loss': 0.0179, 'grad_norm': 0.3523789346218109, 'learning_rate': 0.00015226383940210306, 'epoch': 0.49}\n",
      "{'loss': 0.017, 'grad_norm': 0.05816764757037163, 'learning_rate': 0.00015009124880507516, 'epoch': 0.5}\n",
      "{'loss': 0.0158, 'grad_norm': 0.3271571397781372, 'learning_rate': 0.00014791865820804726, 'epoch': 0.51}\n",
      "{'loss': 0.0184, 'grad_norm': 0.3065672516822815, 'learning_rate': 0.00014574606761101936, 'epoch': 0.51}\n",
      "{'loss': 0.0197, 'grad_norm': 0.32275906205177307, 'learning_rate': 0.00014357347701399146, 'epoch': 0.52}\n",
      "{'loss': 0.0233, 'grad_norm': 0.1936105191707611, 'learning_rate': 0.0001414008864169636, 'epoch': 0.53}\n",
      "{'loss': 0.0173, 'grad_norm': 1.6575028896331787, 'learning_rate': 0.0001392282958199357, 'epoch': 0.54}\n",
      "{'loss': 0.0161, 'grad_norm': 0.2274927943944931, 'learning_rate': 0.0001370557052229078, 'epoch': 0.54}\n",
      "{'loss': 0.0174, 'grad_norm': 0.11491481214761734, 'learning_rate': 0.0001348831146258799, 'epoch': 0.55}\n",
      "{'loss': 0.0197, 'grad_norm': 0.14635586738586426, 'learning_rate': 0.000132710524028852, 'epoch': 0.56}\n",
      "{'loss': 0.0183, 'grad_norm': 0.16871698200702667, 'learning_rate': 0.0001305379334318241, 'epoch': 0.56}\n",
      "{'loss': 0.0156, 'grad_norm': 0.3459698557853699, 'learning_rate': 0.0001283653428347962, 'epoch': 0.57}\n",
      "{'loss': 0.0156, 'grad_norm': 0.28699609637260437, 'learning_rate': 0.0001261927522377683, 'epoch': 0.58}\n",
      "{'loss': 0.0162, 'grad_norm': 0.21068820357322693, 'learning_rate': 0.00012402016164074042, 'epoch': 0.59}\n",
      "{'loss': 0.0163, 'grad_norm': 0.1555889993906021, 'learning_rate': 0.00012184757104371251, 'epoch': 0.59}\n",
      "{'loss': 0.0159, 'grad_norm': 0.4098544120788574, 'learning_rate': 0.00011967498044668462, 'epoch': 0.6}\n",
      "{'loss': 0.017, 'grad_norm': 0.12853722274303436, 'learning_rate': 0.00011750238984965672, 'epoch': 0.61}\n",
      "{'loss': 0.014, 'grad_norm': 0.3421058654785156, 'learning_rate': 0.00011532979925262882, 'epoch': 0.62}\n",
      "{'loss': 0.0155, 'grad_norm': 0.5074938535690308, 'learning_rate': 0.00011315720865560092, 'epoch': 0.62}\n",
      "{'loss': 0.0175, 'grad_norm': 0.09226164221763611, 'learning_rate': 0.00011098461805857304, 'epoch': 0.63}\n",
      "{'loss': 0.0168, 'grad_norm': 0.09848301112651825, 'learning_rate': 0.00010881202746154514, 'epoch': 0.64}\n",
      "{'loss': 0.0145, 'grad_norm': 0.09237788617610931, 'learning_rate': 0.00010663943686451724, 'epoch': 0.64}\n",
      "{'loss': 0.0182, 'grad_norm': 0.12344929575920105, 'learning_rate': 0.00010446684626748935, 'epoch': 0.65}\n",
      "{'loss': 0.0134, 'grad_norm': 0.1710340827703476, 'learning_rate': 0.00010229425567046144, 'epoch': 0.66}\n",
      "{'loss': 0.0151, 'grad_norm': 0.049585700035095215, 'learning_rate': 0.00010012166507343355, 'epoch': 0.67}\n",
      "{'loss': 0.0156, 'grad_norm': 0.36271539330482483, 'learning_rate': 9.794907447640567e-05, 'epoch': 0.67}\n",
      "{'loss': 0.0144, 'grad_norm': 0.051949694752693176, 'learning_rate': 9.577648387937775e-05, 'epoch': 0.68}\n",
      "{'loss': 0.016, 'grad_norm': 0.030896449461579323, 'learning_rate': 9.360389328234987e-05, 'epoch': 0.69}\n",
      "{'loss': 0.0167, 'grad_norm': 0.22145476937294006, 'learning_rate': 9.143130268532198e-05, 'epoch': 0.7}\n",
      "{'loss': 0.0165, 'grad_norm': 0.10817809402942657, 'learning_rate': 8.925871208829407e-05, 'epoch': 0.7}\n",
      "{'loss': 0.0139, 'grad_norm': 0.3325555622577667, 'learning_rate': 8.708612149126618e-05, 'epoch': 0.71}\n",
      "{'loss': 0.0132, 'grad_norm': 0.07020188868045807, 'learning_rate': 8.491353089423827e-05, 'epoch': 0.72}\n",
      "{'loss': 0.017, 'grad_norm': 0.07131584733724594, 'learning_rate': 8.274094029721039e-05, 'epoch': 0.72}\n",
      "{'loss': 0.015, 'grad_norm': 0.16093863546848297, 'learning_rate': 8.05683497001825e-05, 'epoch': 0.73}\n",
      "{'loss': 0.013, 'grad_norm': 0.22918392717838287, 'learning_rate': 7.839575910315459e-05, 'epoch': 0.74}\n",
      "{'loss': 0.013, 'grad_norm': 0.0612836591899395, 'learning_rate': 7.62231685061267e-05, 'epoch': 0.75}\n",
      "{'loss': 0.015, 'grad_norm': 0.055039651691913605, 'learning_rate': 7.40505779090988e-05, 'epoch': 0.75}\n",
      "{'loss': 0.014, 'grad_norm': 1.227791666984558, 'learning_rate': 7.187798731207092e-05, 'epoch': 0.76}\n",
      "{'loss': 0.0155, 'grad_norm': 0.12432209402322769, 'learning_rate': 6.970539671504302e-05, 'epoch': 0.77}\n",
      "{'loss': 0.0148, 'grad_norm': 0.4470590353012085, 'learning_rate': 6.753280611801512e-05, 'epoch': 0.77}\n",
      "{'loss': 0.0154, 'grad_norm': 0.4707831144332886, 'learning_rate': 6.536021552098722e-05, 'epoch': 0.78}\n",
      "{'loss': 0.0162, 'grad_norm': 0.02939688228070736, 'learning_rate': 6.318762492395932e-05, 'epoch': 0.79}\n",
      "{'loss': 0.0121, 'grad_norm': 0.47134968638420105, 'learning_rate': 6.1015034326931425e-05, 'epoch': 0.8}\n",
      "{'loss': 0.0158, 'grad_norm': 0.24628382921218872, 'learning_rate': 5.884244372990353e-05, 'epoch': 0.8}\n",
      "{'loss': 0.0148, 'grad_norm': 0.04888918995857239, 'learning_rate': 5.666985313287564e-05, 'epoch': 0.81}\n",
      "{'loss': 0.0165, 'grad_norm': 0.13320700824260712, 'learning_rate': 5.449726253584774e-05, 'epoch': 0.82}\n",
      "{'loss': 0.0116, 'grad_norm': 0.010068826377391815, 'learning_rate': 5.232467193881985e-05, 'epoch': 0.83}\n",
      "{'loss': 0.0169, 'grad_norm': 0.11595448106527328, 'learning_rate': 5.015208134179195e-05, 'epoch': 0.83}\n",
      "{'loss': 0.0136, 'grad_norm': 0.6190317273139954, 'learning_rate': 4.797949074476405e-05, 'epoch': 0.84}\n",
      "{'loss': 0.0143, 'grad_norm': 0.20433610677719116, 'learning_rate': 4.5806900147736156e-05, 'epoch': 0.85}\n",
      "{'loss': 0.0161, 'grad_norm': 0.3056310713291168, 'learning_rate': 4.3634309550708264e-05, 'epoch': 0.85}\n",
      "{'loss': 0.0137, 'grad_norm': 0.07013304531574249, 'learning_rate': 4.1461718953680364e-05, 'epoch': 0.86}\n",
      "{'loss': 0.017, 'grad_norm': 0.13986541330814362, 'learning_rate': 3.9289128356652465e-05, 'epoch': 0.87}\n",
      "{'loss': 0.0123, 'grad_norm': 0.11420523375272751, 'learning_rate': 3.711653775962457e-05, 'epoch': 0.88}\n",
      "{'loss': 0.0136, 'grad_norm': 0.5873585939407349, 'learning_rate': 3.494394716259668e-05, 'epoch': 0.88}\n",
      "{'loss': 0.0185, 'grad_norm': 0.22021007537841797, 'learning_rate': 3.277135656556878e-05, 'epoch': 0.89}\n",
      "{'loss': 0.0145, 'grad_norm': 0.48021194338798523, 'learning_rate': 3.059876596854089e-05, 'epoch': 0.9}\n",
      "{'loss': 0.0157, 'grad_norm': 0.03803728148341179, 'learning_rate': 2.842617537151299e-05, 'epoch': 0.91}\n",
      "{'loss': 0.0144, 'grad_norm': 0.5018863677978516, 'learning_rate': 2.6253584774485092e-05, 'epoch': 0.91}\n",
      "{'loss': 0.0132, 'grad_norm': 0.05960678681731224, 'learning_rate': 2.40809941774572e-05, 'epoch': 0.92}\n",
      "{'loss': 0.0125, 'grad_norm': 0.49102896451950073, 'learning_rate': 2.1908403580429303e-05, 'epoch': 0.93}\n",
      "{'loss': 0.0129, 'grad_norm': 0.35898107290267944, 'learning_rate': 1.9735812983401404e-05, 'epoch': 0.93}\n",
      "{'loss': 0.0148, 'grad_norm': 0.12693233788013458, 'learning_rate': 1.7563222386373508e-05, 'epoch': 0.94}\n",
      "{'loss': 0.0153, 'grad_norm': 0.23851391673088074, 'learning_rate': 1.5390631789345615e-05, 'epoch': 0.95}\n",
      "{'loss': 0.011, 'grad_norm': 0.05868153274059296, 'learning_rate': 1.321804119231772e-05, 'epoch': 0.96}\n",
      "{'loss': 0.0167, 'grad_norm': 0.056668851524591446, 'learning_rate': 1.1045450595289822e-05, 'epoch': 0.96}\n",
      "{'loss': 0.0143, 'grad_norm': 0.21491053700447083, 'learning_rate': 8.872859998261927e-06, 'epoch': 0.97}\n",
      "{'loss': 0.0136, 'grad_norm': 0.25878140330314636, 'learning_rate': 6.7002694012340304e-06, 'epoch': 0.98}\n",
      "{'loss': 0.0133, 'grad_norm': 0.21008580923080444, 'learning_rate': 4.527678804206135e-06, 'epoch': 0.98}\n",
      "{'loss': 0.0126, 'grad_norm': 0.669549822807312, 'learning_rate': 2.3550882071782392e-06, 'epoch': 0.99}\n",
      "{'loss': 0.0142, 'grad_norm': 0.2675545811653137, 'learning_rate': 1.8249761015034325e-07, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/j/Desktop/MLotsawa/.venv/lib/python3.10/site-packages/transformers/generation/utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b4f40766364431ac96ca1f2282537f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1523 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_translation_loss': 0.00932574737817049, 'eval_translation_bleu': 65.4073, 'eval_translation_gen_len': 14.3828, 'eval_translation_runtime': 1841.5002, 'eval_translation_samples_per_second': 6.616, 'eval_translation_steps_per_second': 0.827, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce79a37b0014206a0ccca1b6ecd334a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1523 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_transliteration_loss': 0.008420788682997227, 'eval_transliteration_bleu': 66.0247, 'eval_transliteration_gen_len': 17.6756, 'eval_transliteration_runtime': 1863.538, 'eval_transliteration_samples_per_second': 6.538, 'eval_transliteration_steps_per_second': 0.817, 'epoch': 1.0}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"The `metric_for_best_model` training argument is set to 'eval_loss', which is not found in the evaluation metrics. The available evaluation metrics are: ['eval_translation_loss', 'eval_translation_bleu', 'eval_translation_gen_len', 'eval_translation_runtime', 'eval_translation_samples_per_second', 'eval_translation_steps_per_second', 'epoch', 'eval_transliteration_loss', 'eval_transliteration_bleu', 'eval_transliteration_gen_len', 'eval_transliteration_runtime', 'eval_transliteration_samples_per_second', 'eval_transliteration_steps_per_second']. Consider changing the `metric_for_best_model` via the TrainingArguments.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/MLotsawa/.venv/lib/python3.10/site-packages/transformers/trainer.py:3022\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   3021\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3022\u001b[0m     metric_value \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetric_to_check\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   3023\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'eval_loss'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 24\u001b[0m\n\u001b[1;32m      1\u001b[0m training_args \u001b[38;5;241m=\u001b[39m Seq2SeqTrainingArguments(\n\u001b[1;32m      2\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdual-task-add-both\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     auto_find_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m     14\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     15\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics\n\u001b[1;32m     22\u001b[0m )\n\u001b[0;32m---> 24\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/MLotsawa/.venv/lib/python3.10/site-packages/transformers/trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/MLotsawa/.venv/lib/python3.10/site-packages/accelerate/utils/memory.py:157\u001b[0m, in \u001b[0;36mfind_executable_batch_size.<locals>.decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo executable batch size found, reached zero.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_reduce_batch_size(e):\n",
      "File \u001b[0;32m~/Desktop/MLotsawa/.venv/lib/python3.10/site-packages/transformers/trainer.py:2487\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2484\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2487\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[1;32m   2490\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_xla_available():\n\u001b[1;32m   2491\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/MLotsawa/.venv/lib/python3.10/site-packages/transformers/trainer.py:2918\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2915\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate(trial, ignore_keys_for_eval)\n\u001b[1;32m   2917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 2918\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2919\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_save(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/Desktop/MLotsawa/.venv/lib/python3.10/site-packages/transformers/trainer.py:3024\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   3022\u001b[0m     metric_value \u001b[38;5;241m=\u001b[39m metrics[metric_to_check]\n\u001b[1;32m   3023\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m-> 3024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m   3025\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `metric_for_best_model` training argument is set to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_to_check\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, which is not found in the evaluation metrics. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3026\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe available evaluation metrics are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(metrics\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Consider changing the `metric_for_best_model` via the TrainingArguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3027\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m   3029\u001b[0m operator \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mgreater \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgreater_is_better \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mless\n\u001b[1;32m   3030\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3031\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mbest_metric \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3032\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mbest_model_checkpoint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3033\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m operator(metric_value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mbest_metric)\n\u001b[1;32m   3034\u001b[0m ):\n",
      "\u001b[0;31mKeyError\u001b[0m: \"The `metric_for_best_model` training argument is set to 'eval_loss', which is not found in the evaluation metrics. The available evaluation metrics are: ['eval_translation_loss', 'eval_translation_bleu', 'eval_translation_gen_len', 'eval_translation_runtime', 'eval_translation_samples_per_second', 'eval_translation_steps_per_second', 'epoch', 'eval_transliteration_loss', 'eval_transliteration_bleu', 'eval_transliteration_gen_len', 'eval_transliteration_runtime', 'eval_transliteration_samples_per_second', 'eval_transliteration_steps_per_second']. Consider changing the `metric_for_best_model` via the TrainingArguments.\""
     ]
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"dual-task-add-both\",\n",
    "    auto_find_batch_size=True,\n",
    "    predict_with_generate=True,\n",
    "    fp16=False, #check this\n",
    "    push_to_hub=False,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    num_train_epochs=1\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset={'translation':translation_tokenized_dataset['test'], 'transliteration':transliteration_tokenized_dataset['test']},\n",
    "    tokenizer=tokenizer,\n",
    "    optimizers=(optimizer, None),\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
