{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since openpecha/cleaned_MT_v1.0.2 couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /home/j/.cache/huggingface/datasets/openpecha___cleaned_mt_v1.0.2/default/0.0.0/f89a8ce696a5711c5dfd57352677aad125224ee9 (last modified on Fri Dec  6 10:55:31 2024).\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "dataset = DatasetDict()\n",
    "\n",
    "dataset['train'] = load_dataset('openpecha/cleaned_MT_v1.0.2', split='train')\n",
    "dataset['test'] = load_dataset('openpecha/cleaned_MT_v1.0.3', split='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Source': 'ཐུབ་པས་རྟག་ཏུ་དེ་བཞིན་སྤྱད།།',\n",
       " 'Target': 'The aspirant should move in such a way at all times.',\n",
       " 'File_Name': 'TM2382',\n",
       " 'Machine Aligned': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Source': 'ཚད་མེད་བཏང་སྙོམས་གསུམ་ལས།',\n",
       " 'Target': '3. Immeasureable equanimity ',\n",
       " 'File_Name': 'TM2203',\n",
       " 'Machine Aligned': True,\n",
       " '__index_level_0__': 0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Tokenizer, Model, and Data Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorForSeq2Seq, AutoModelForSeq2SeqLM\n",
    "\n",
    "checkpoint = \"google-t5/t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint, device_map=\"cuda:0\")\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32355, 512)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a list of all Tibetan Unicode characters (U+0F00 to U+0FFF)\n",
    "tibetan_chars = [chr(codepoint) for codepoint in range(0x0F00, 0x0FFF)]\n",
    "\n",
    "# Add the Tibetan characters to the tokenizer's vocabulary\n",
    "new_tokens = [char for char in tibetan_chars if char not in tokenizer.get_vocab()]\n",
    "\n",
    "# Add new tokens to the tokenizer\n",
    "tokenizer.add_tokens(new_tokens)\n",
    "\n",
    "# Resize model embeddings to accommodate the new vocabulary size\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ཐུབ་པས་རྟག་ཏུ་དེ་བཞིན་སྤྱད།།</s>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = tokenizer.encode(dataset['train'][0]['Source'])\n",
    "dec = tokenizer.decode(enc)\n",
    "dec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "\n",
    "The dataset can now be tokenized for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_lang = 'Source'\n",
    "target_lang = 'Target'\n",
    "\n",
    "def preprocess_function(examples):\n",
    "\n",
    "    inputs = [example for example in examples[source_lang]]\n",
    "    targets = [example for example in examples[target_lang]]\n",
    "    \n",
    "    model_inputs = tokenizer(inputs, text_target=targets, max_length=256, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b2e473c61c248ebb5d8cbd6f715dea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1562949 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, Adafactor\n",
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "\n",
    "optimizer = Adafactor(\n",
    "    model.parameters(), \n",
    "    scale_parameter=True, \n",
    "    relative_step=False, \n",
    "    warmup_init=False, \n",
    "    lr=3e-4\n",
    ")\n",
    "\n",
    "model, optimizer = accelerator.prepare(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbillingsmoore\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/j/Desktop/MLotsawa/Notebooks/Models/openpecha/wandb/run-20241206_125419-qctrh6t2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/billingsmoore/huggingface/runs/qctrh6t2' target=\"_blank\">clean_1.0.2</a></strong> to <a href='https://wandb.ai/billingsmoore/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/billingsmoore/huggingface' target=\"_blank\">https://wandb.ai/billingsmoore/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/billingsmoore/huggingface/runs/qctrh6t2' target=\"_blank\">https://wandb.ai/billingsmoore/huggingface/runs/qctrh6t2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d43b0e64658451ab1181f54443be1e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195369 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1938, 'grad_norm': 0.224343940615654, 'learning_rate': 0.00029923222210279007, 'epoch': 0.0}\n",
      "{'loss': 0.96, 'grad_norm': 0.1544794887304306, 'learning_rate': 0.00029846444420558016, 'epoch': 0.01}\n",
      "{'loss': 0.9863, 'grad_norm': 1.4241544008255005, 'learning_rate': 0.00029769666630837026, 'epoch': 0.01}\n",
      "{'loss': 0.9716, 'grad_norm': 0.1773810237646103, 'learning_rate': 0.0002969288884111604, 'epoch': 0.01}\n",
      "{'loss': 0.9727, 'grad_norm': 0.324550062417984, 'learning_rate': 0.0002961611105139505, 'epoch': 0.01}\n",
      "{'loss': 0.9705, 'grad_norm': 0.29743683338165283, 'learning_rate': 0.0002953933326167406, 'epoch': 0.02}\n",
      "{'loss': 0.9208, 'grad_norm': 0.17542213201522827, 'learning_rate': 0.0002946255547195307, 'epoch': 0.02}\n",
      "{'loss': 0.9064, 'grad_norm': 0.1885157972574234, 'learning_rate': 0.0002938577768223208, 'epoch': 0.02}\n",
      "{'loss': 0.9468, 'grad_norm': 0.5190813541412354, 'learning_rate': 0.00029308999892511094, 'epoch': 0.02}\n",
      "{'loss': 0.9297, 'grad_norm': 0.3789009749889374, 'learning_rate': 0.00029232222102790103, 'epoch': 0.03}\n",
      "{'loss': 0.8838, 'grad_norm': 0.7035062313079834, 'learning_rate': 0.0002915544431306911, 'epoch': 0.03}\n",
      "{'loss': 0.9224, 'grad_norm': 0.35127386450767517, 'learning_rate': 0.0002907866652334812, 'epoch': 0.03}\n",
      "{'loss': 0.8921, 'grad_norm': 0.2703893184661865, 'learning_rate': 0.0002900188873362713, 'epoch': 0.03}\n",
      "{'loss': 0.9065, 'grad_norm': 0.20863056182861328, 'learning_rate': 0.00028925110943906146, 'epoch': 0.04}\n",
      "{'loss': 0.8928, 'grad_norm': 0.35883745551109314, 'learning_rate': 0.00028848333154185156, 'epoch': 0.04}\n",
      "{'loss': 0.9362, 'grad_norm': 0.3062784969806671, 'learning_rate': 0.00028771555364464165, 'epoch': 0.04}\n",
      "{'loss': 0.8994, 'grad_norm': 0.47753217816352844, 'learning_rate': 0.00028694777574743175, 'epoch': 0.04}\n",
      "{'loss': 0.8875, 'grad_norm': 0.2888180911540985, 'learning_rate': 0.0002861799978502219, 'epoch': 0.05}\n",
      "{'loss': 0.877, 'grad_norm': 0.3648921251296997, 'learning_rate': 0.000285412219953012, 'epoch': 0.05}\n",
      "{'loss': 0.8916, 'grad_norm': 0.42227286100387573, 'learning_rate': 0.00028464444205580203, 'epoch': 0.05}\n",
      "{'loss': 0.9064, 'grad_norm': 0.435547798871994, 'learning_rate': 0.0002838766641585922, 'epoch': 0.05}\n",
      "{'loss': 0.8822, 'grad_norm': 0.5223085880279541, 'learning_rate': 0.0002831088862613823, 'epoch': 0.06}\n",
      "{'loss': 0.8868, 'grad_norm': 0.34033429622650146, 'learning_rate': 0.00028234110836417237, 'epoch': 0.06}\n",
      "{'loss': 0.8826, 'grad_norm': 0.43963807821273804, 'learning_rate': 0.00028157333046696247, 'epoch': 0.06}\n",
      "{'loss': 0.9051, 'grad_norm': 0.23638957738876343, 'learning_rate': 0.0002808055525697526, 'epoch': 0.06}\n",
      "{'loss': 0.9012, 'grad_norm': 0.49483010172843933, 'learning_rate': 0.0002800377746725427, 'epoch': 0.07}\n",
      "{'loss': 0.896, 'grad_norm': 0.27666977047920227, 'learning_rate': 0.0002792699967753328, 'epoch': 0.07}\n",
      "{'loss': 0.8754, 'grad_norm': 0.2905885577201843, 'learning_rate': 0.0002785022188781229, 'epoch': 0.07}\n",
      "{'loss': 0.9177, 'grad_norm': 0.29509052634239197, 'learning_rate': 0.000277734440980913, 'epoch': 0.07}\n",
      "{'loss': 0.8496, 'grad_norm': 0.17951126396656036, 'learning_rate': 0.00027696666308370314, 'epoch': 0.08}\n",
      "{'loss': 0.8726, 'grad_norm': 0.285977840423584, 'learning_rate': 0.00027619888518649324, 'epoch': 0.08}\n",
      "{'loss': 0.8648, 'grad_norm': 0.30614936351776123, 'learning_rate': 0.00027543110728928333, 'epoch': 0.08}\n",
      "{'loss': 0.8485, 'grad_norm': 0.3482096791267395, 'learning_rate': 0.00027466332939207343, 'epoch': 0.08}\n",
      "{'loss': 0.8531, 'grad_norm': 0.39985495805740356, 'learning_rate': 0.0002738955514948635, 'epoch': 0.09}\n",
      "{'loss': 0.8572, 'grad_norm': 0.2569459080696106, 'learning_rate': 0.00027312777359765367, 'epoch': 0.09}\n",
      "{'loss': 0.8695, 'grad_norm': 0.35317501425743103, 'learning_rate': 0.00027235999570044377, 'epoch': 0.09}\n",
      "{'loss': 0.8696, 'grad_norm': 0.32815924286842346, 'learning_rate': 0.00027159221780323386, 'epoch': 0.09}\n",
      "{'loss': 0.8652, 'grad_norm': 0.30805450677871704, 'learning_rate': 0.00027082443990602396, 'epoch': 0.1}\n",
      "{'loss': 0.8541, 'grad_norm': 0.36178138852119446, 'learning_rate': 0.00027005666200881405, 'epoch': 0.1}\n",
      "{'loss': 0.8723, 'grad_norm': 0.3757253885269165, 'learning_rate': 0.0002692888841116042, 'epoch': 0.1}\n",
      "{'loss': 0.8768, 'grad_norm': 0.24396787583827972, 'learning_rate': 0.00026852110621439424, 'epoch': 0.1}\n",
      "{'loss': 0.839, 'grad_norm': 0.3867550194263458, 'learning_rate': 0.0002677533283171844, 'epoch': 0.11}\n",
      "{'loss': 0.8438, 'grad_norm': 0.44938796758651733, 'learning_rate': 0.0002669855504199745, 'epoch': 0.11}\n",
      "{'loss': 0.8501, 'grad_norm': 0.4512598216533661, 'learning_rate': 0.0002662177725227646, 'epoch': 0.11}\n",
      "{'loss': 0.8619, 'grad_norm': 0.2663022577762604, 'learning_rate': 0.0002654499946255547, 'epoch': 0.12}\n",
      "{'loss': 0.8599, 'grad_norm': 0.2757408320903778, 'learning_rate': 0.00026468221672834477, 'epoch': 0.12}\n",
      "{'loss': 0.8575, 'grad_norm': 0.2625575363636017, 'learning_rate': 0.0002639144388311349, 'epoch': 0.12}\n",
      "{'loss': 0.8643, 'grad_norm': 0.3950636386871338, 'learning_rate': 0.000263146660933925, 'epoch': 0.12}\n",
      "{'loss': 0.8828, 'grad_norm': 0.2186916321516037, 'learning_rate': 0.0002623788830367151, 'epoch': 0.13}\n",
      "{'loss': 0.8513, 'grad_norm': 0.4122300148010254, 'learning_rate': 0.0002616111051395052, 'epoch': 0.13}\n",
      "{'loss': 0.8604, 'grad_norm': 0.18493211269378662, 'learning_rate': 0.00026084332724229535, 'epoch': 0.13}\n",
      "{'loss': 0.8473, 'grad_norm': 0.18690955638885498, 'learning_rate': 0.00026007554934508545, 'epoch': 0.13}\n",
      "{'loss': 0.8539, 'grad_norm': 0.2850842773914337, 'learning_rate': 0.00025930777144787554, 'epoch': 0.14}\n",
      "{'loss': 0.8536, 'grad_norm': 0.47018149495124817, 'learning_rate': 0.00025853999355066564, 'epoch': 0.14}\n",
      "{'loss': 0.8173, 'grad_norm': 0.2105291783809662, 'learning_rate': 0.00025777221565345573, 'epoch': 0.14}\n",
      "{'loss': 0.8464, 'grad_norm': 0.4260012209415436, 'learning_rate': 0.0002570044377562459, 'epoch': 0.14}\n",
      "{'loss': 0.8331, 'grad_norm': 0.20857645571231842, 'learning_rate': 0.000256236659859036, 'epoch': 0.15}\n",
      "{'loss': 0.8422, 'grad_norm': 0.23787960410118103, 'learning_rate': 0.00025546888196182607, 'epoch': 0.15}\n",
      "{'loss': 0.8193, 'grad_norm': 0.17500878870487213, 'learning_rate': 0.00025470110406461616, 'epoch': 0.15}\n",
      "{'loss': 0.8386, 'grad_norm': 0.27738359570503235, 'learning_rate': 0.00025393332616740626, 'epoch': 0.15}\n",
      "{'loss': 0.7904, 'grad_norm': 0.17002812027931213, 'learning_rate': 0.0002531655482701964, 'epoch': 0.16}\n",
      "{'loss': 0.8467, 'grad_norm': 0.3415271043777466, 'learning_rate': 0.00025239777037298645, 'epoch': 0.16}\n",
      "{'loss': 0.843, 'grad_norm': 0.30580976605415344, 'learning_rate': 0.0002516299924757766, 'epoch': 0.16}\n",
      "{'loss': 0.8349, 'grad_norm': 0.1790003627538681, 'learning_rate': 0.0002508622145785667, 'epoch': 0.16}\n",
      "{'loss': 0.8173, 'grad_norm': 0.3542773425579071, 'learning_rate': 0.0002500944366813568, 'epoch': 0.17}\n",
      "{'loss': 0.8105, 'grad_norm': 0.6508361101150513, 'learning_rate': 0.0002493266587841469, 'epoch': 0.17}\n",
      "{'loss': 0.8461, 'grad_norm': 0.36309704184532166, 'learning_rate': 0.000248558880886937, 'epoch': 0.17}\n",
      "{'loss': 0.808, 'grad_norm': 0.3135949373245239, 'learning_rate': 0.0002477911029897271, 'epoch': 0.17}\n",
      "{'loss': 0.8386, 'grad_norm': 0.45387232303619385, 'learning_rate': 0.0002470233250925172, 'epoch': 0.18}\n",
      "{'loss': 0.8342, 'grad_norm': 0.29098501801490784, 'learning_rate': 0.0002462555471953073, 'epoch': 0.18}\n",
      "{'loss': 0.8119, 'grad_norm': 0.323706716299057, 'learning_rate': 0.0002454877692980974, 'epoch': 0.18}\n",
      "{'loss': 0.8306, 'grad_norm': 0.4462757110595703, 'learning_rate': 0.0002447199914008875, 'epoch': 0.18}\n",
      "{'loss': 0.8103, 'grad_norm': 0.3431558907032013, 'learning_rate': 0.00024395221350367765, 'epoch': 0.19}\n",
      "{'loss': 0.8193, 'grad_norm': 0.33697348833084106, 'learning_rate': 0.00024318443560646772, 'epoch': 0.19}\n",
      "{'loss': 0.8063, 'grad_norm': 0.3145200312137604, 'learning_rate': 0.00024241665770925784, 'epoch': 0.19}\n",
      "{'loss': 0.8169, 'grad_norm': 0.22689059376716614, 'learning_rate': 0.00024164887981204794, 'epoch': 0.19}\n",
      "{'loss': 0.803, 'grad_norm': 0.4832858145236969, 'learning_rate': 0.00024088110191483806, 'epoch': 0.2}\n",
      "{'loss': 0.7886, 'grad_norm': 0.4724779725074768, 'learning_rate': 0.00024011332401762815, 'epoch': 0.2}\n",
      "{'loss': 0.7921, 'grad_norm': 0.5560048222541809, 'learning_rate': 0.00023934554612041825, 'epoch': 0.2}\n",
      "{'loss': 0.8162, 'grad_norm': 0.3437892496585846, 'learning_rate': 0.00023857776822320837, 'epoch': 0.2}\n",
      "{'loss': 0.7935, 'grad_norm': 0.33752676844596863, 'learning_rate': 0.00023780999032599847, 'epoch': 0.21}\n",
      "{'loss': 0.8015, 'grad_norm': 0.18176153302192688, 'learning_rate': 0.0002370422124287886, 'epoch': 0.21}\n",
      "{'loss': 0.8213, 'grad_norm': 0.5555035471916199, 'learning_rate': 0.00023627443453157868, 'epoch': 0.21}\n",
      "{'loss': 0.8109, 'grad_norm': 0.2186124175786972, 'learning_rate': 0.00023550665663436878, 'epoch': 0.21}\n",
      "{'loss': 0.8021, 'grad_norm': 0.34082481265068054, 'learning_rate': 0.0002347388787371589, 'epoch': 0.22}\n",
      "{'loss': 0.7944, 'grad_norm': 0.2674863338470459, 'learning_rate': 0.000233971100839949, 'epoch': 0.22}\n",
      "{'loss': 0.782, 'grad_norm': 0.35994234681129456, 'learning_rate': 0.00023320332294273912, 'epoch': 0.22}\n",
      "{'loss': 0.8143, 'grad_norm': 0.4238473176956177, 'learning_rate': 0.0002324355450455292, 'epoch': 0.23}\n",
      "{'loss': 0.8195, 'grad_norm': 0.30072924494743347, 'learning_rate': 0.00023166776714831933, 'epoch': 0.23}\n",
      "{'loss': 0.7915, 'grad_norm': 0.2792549133300781, 'learning_rate': 0.00023089998925110943, 'epoch': 0.23}\n",
      "{'loss': 0.8237, 'grad_norm': 0.29380786418914795, 'learning_rate': 0.00023013221135389952, 'epoch': 0.23}\n",
      "{'loss': 0.8222, 'grad_norm': 0.5668373107910156, 'learning_rate': 0.00022936443345668964, 'epoch': 0.24}\n",
      "{'loss': 0.8267, 'grad_norm': 0.3103516399860382, 'learning_rate': 0.0002285966555594797, 'epoch': 0.24}\n",
      "{'loss': 0.7567, 'grad_norm': 0.17971177399158478, 'learning_rate': 0.00022782887766226986, 'epoch': 0.24}\n",
      "{'loss': 0.8601, 'grad_norm': 0.3858075737953186, 'learning_rate': 0.00022706109976505993, 'epoch': 0.24}\n",
      "{'loss': 0.7835, 'grad_norm': 0.5482571125030518, 'learning_rate': 0.00022629332186785005, 'epoch': 0.25}\n",
      "{'loss': 0.8181, 'grad_norm': 0.34960752725601196, 'learning_rate': 0.00022552554397064015, 'epoch': 0.25}\n",
      "{'loss': 0.812, 'grad_norm': 0.4062331020832062, 'learning_rate': 0.00022475776607343024, 'epoch': 0.25}\n",
      "{'loss': 0.8049, 'grad_norm': 0.4155985116958618, 'learning_rate': 0.00022398998817622036, 'epoch': 0.25}\n",
      "{'loss': 0.8261, 'grad_norm': 0.22950628399848938, 'learning_rate': 0.00022322221027901046, 'epoch': 0.26}\n",
      "{'loss': 0.7943, 'grad_norm': 0.31518006324768066, 'learning_rate': 0.00022245443238180058, 'epoch': 0.26}\n",
      "{'loss': 0.7599, 'grad_norm': 0.22374506294727325, 'learning_rate': 0.00022168665448459067, 'epoch': 0.26}\n",
      "{'loss': 0.7706, 'grad_norm': 0.3805389106273651, 'learning_rate': 0.0002209188765873808, 'epoch': 0.26}\n",
      "{'loss': 0.7682, 'grad_norm': 0.21880999207496643, 'learning_rate': 0.0002201510986901709, 'epoch': 0.27}\n",
      "{'loss': 0.7946, 'grad_norm': 0.23165050148963928, 'learning_rate': 0.00021938332079296099, 'epoch': 0.27}\n",
      "{'loss': 0.8156, 'grad_norm': 0.30541089177131653, 'learning_rate': 0.0002186155428957511, 'epoch': 0.27}\n",
      "{'loss': 0.7746, 'grad_norm': 0.2504136860370636, 'learning_rate': 0.0002178477649985412, 'epoch': 0.27}\n",
      "{'loss': 0.8119, 'grad_norm': 0.22987575829029083, 'learning_rate': 0.00021707998710133132, 'epoch': 0.28}\n",
      "{'loss': 0.7818, 'grad_norm': 0.38104522228240967, 'learning_rate': 0.00021631220920412142, 'epoch': 0.28}\n",
      "{'loss': 0.8014, 'grad_norm': 0.47027477622032166, 'learning_rate': 0.0002155444313069115, 'epoch': 0.28}\n",
      "{'loss': 0.7854, 'grad_norm': 0.3096032738685608, 'learning_rate': 0.00021477665340970164, 'epoch': 0.28}\n",
      "{'loss': 0.8186, 'grad_norm': 0.3752152621746063, 'learning_rate': 0.00021400887551249173, 'epoch': 0.29}\n",
      "{'loss': 0.8044, 'grad_norm': 0.265581876039505, 'learning_rate': 0.00021324109761528185, 'epoch': 0.29}\n",
      "{'loss': 0.78, 'grad_norm': 0.13189108669757843, 'learning_rate': 0.00021247331971807192, 'epoch': 0.29}\n",
      "{'loss': 0.824, 'grad_norm': 0.478724867105484, 'learning_rate': 0.00021170554182086207, 'epoch': 0.29}\n",
      "{'loss': 0.7891, 'grad_norm': 0.445824533700943, 'learning_rate': 0.00021093776392365214, 'epoch': 0.3}\n",
      "{'loss': 0.7792, 'grad_norm': 0.2181548923254013, 'learning_rate': 0.00021016998602644223, 'epoch': 0.3}\n",
      "{'loss': 0.8065, 'grad_norm': 0.19608354568481445, 'learning_rate': 0.00020940220812923235, 'epoch': 0.3}\n",
      "{'loss': 0.7777, 'grad_norm': 0.22802554070949554, 'learning_rate': 0.00020863443023202245, 'epoch': 0.3}\n",
      "{'loss': 0.786, 'grad_norm': 0.29489919543266296, 'learning_rate': 0.00020786665233481257, 'epoch': 0.31}\n",
      "{'loss': 0.7632, 'grad_norm': 0.42863431572914124, 'learning_rate': 0.00020709887443760266, 'epoch': 0.31}\n",
      "{'loss': 0.7692, 'grad_norm': 0.4803467392921448, 'learning_rate': 0.00020633109654039279, 'epoch': 0.31}\n",
      "{'loss': 0.7725, 'grad_norm': 0.3898450434207916, 'learning_rate': 0.00020556331864318288, 'epoch': 0.31}\n",
      "{'loss': 0.7707, 'grad_norm': 0.5710672736167908, 'learning_rate': 0.00020479554074597298, 'epoch': 0.32}\n",
      "{'loss': 0.7964, 'grad_norm': 0.3615869879722595, 'learning_rate': 0.0002040277628487631, 'epoch': 0.32}\n",
      "{'loss': 0.7992, 'grad_norm': 0.4276953935623169, 'learning_rate': 0.0002032599849515532, 'epoch': 0.32}\n",
      "{'loss': 0.8076, 'grad_norm': 0.5206500291824341, 'learning_rate': 0.00020249220705434331, 'epoch': 0.33}\n",
      "{'loss': 0.7747, 'grad_norm': 0.6067222952842712, 'learning_rate': 0.0002017244291571334, 'epoch': 0.33}\n",
      "{'loss': 0.7708, 'grad_norm': 0.25759419798851013, 'learning_rate': 0.0002009566512599235, 'epoch': 0.33}\n",
      "{'loss': 0.7729, 'grad_norm': 0.24530835449695587, 'learning_rate': 0.00020018887336271363, 'epoch': 0.33}\n",
      "{'loss': 0.8109, 'grad_norm': 0.8999313116073608, 'learning_rate': 0.00019942109546550372, 'epoch': 0.34}\n",
      "{'loss': 0.7472, 'grad_norm': 0.37105196714401245, 'learning_rate': 0.00019865331756829384, 'epoch': 0.34}\n",
      "{'loss': 0.7695, 'grad_norm': 0.4465014934539795, 'learning_rate': 0.00019788553967108394, 'epoch': 0.34}\n",
      "{'loss': 0.7857, 'grad_norm': 0.23836667835712433, 'learning_rate': 0.00019711776177387406, 'epoch': 0.34}\n",
      "{'loss': 0.794, 'grad_norm': 2.7922067642211914, 'learning_rate': 0.00019634998387666415, 'epoch': 0.35}\n",
      "{'loss': 0.7782, 'grad_norm': 0.36835235357284546, 'learning_rate': 0.00019558220597945422, 'epoch': 0.35}\n",
      "{'loss': 0.8141, 'grad_norm': 0.19329586625099182, 'learning_rate': 0.00019481442808224434, 'epoch': 0.35}\n",
      "{'loss': 0.7866, 'grad_norm': 0.31884831190109253, 'learning_rate': 0.00019404665018503444, 'epoch': 0.35}\n",
      "{'loss': 0.7616, 'grad_norm': 0.37839147448539734, 'learning_rate': 0.00019327887228782456, 'epoch': 0.36}\n",
      "{'loss': 0.7586, 'grad_norm': 0.38899490237236023, 'learning_rate': 0.00019251109439061466, 'epoch': 0.36}\n",
      "{'loss': 0.7958, 'grad_norm': 0.4115971326828003, 'learning_rate': 0.00019174331649340478, 'epoch': 0.36}\n",
      "{'loss': 0.773, 'grad_norm': 0.3230626881122589, 'learning_rate': 0.00019097553859619487, 'epoch': 0.36}\n",
      "{'loss': 0.7635, 'grad_norm': 0.3169317841529846, 'learning_rate': 0.00019020776069898497, 'epoch': 0.37}\n",
      "{'loss': 0.781, 'grad_norm': 0.24350504577159882, 'learning_rate': 0.0001894399828017751, 'epoch': 0.37}\n",
      "{'loss': 0.7479, 'grad_norm': 0.3098669946193695, 'learning_rate': 0.00018867220490456518, 'epoch': 0.37}\n",
      "{'loss': 0.7736, 'grad_norm': 0.17881184816360474, 'learning_rate': 0.0001879044270073553, 'epoch': 0.37}\n",
      "{'loss': 0.778, 'grad_norm': 0.34984228014945984, 'learning_rate': 0.0001871366491101454, 'epoch': 0.38}\n",
      "{'loss': 0.7679, 'grad_norm': 0.3717173933982849, 'learning_rate': 0.00018636887121293552, 'epoch': 0.38}\n",
      "{'loss': 0.7777, 'grad_norm': 0.46567028760910034, 'learning_rate': 0.00018560109331572562, 'epoch': 0.38}\n",
      "{'loss': 0.7577, 'grad_norm': 0.6241481900215149, 'learning_rate': 0.0001848333154185157, 'epoch': 0.38}\n",
      "{'loss': 0.755, 'grad_norm': 0.44804108142852783, 'learning_rate': 0.00018406553752130583, 'epoch': 0.39}\n",
      "{'loss': 0.7539, 'grad_norm': 0.42700260877609253, 'learning_rate': 0.00018329775962409593, 'epoch': 0.39}\n",
      "{'loss': 0.777, 'grad_norm': 0.4599551260471344, 'learning_rate': 0.00018252998172688605, 'epoch': 0.39}\n",
      "{'loss': 0.7639, 'grad_norm': 0.7136893272399902, 'learning_rate': 0.00018176220382967615, 'epoch': 0.39}\n",
      "{'loss': 0.7585, 'grad_norm': 0.5474004745483398, 'learning_rate': 0.0001809944259324662, 'epoch': 0.4}\n",
      "{'loss': 0.7747, 'grad_norm': 0.2721060514450073, 'learning_rate': 0.00018022664803525636, 'epoch': 0.4}\n",
      "{'loss': 0.787, 'grad_norm': 0.29296815395355225, 'learning_rate': 0.00017945887013804643, 'epoch': 0.4}\n",
      "{'loss': 0.7708, 'grad_norm': 0.29328420758247375, 'learning_rate': 0.00017869109224083655, 'epoch': 0.4}\n",
      "{'loss': 0.7776, 'grad_norm': 0.3784429430961609, 'learning_rate': 0.00017792331434362665, 'epoch': 0.41}\n",
      "{'loss': 0.7608, 'grad_norm': 0.5622108578681946, 'learning_rate': 0.00017715553644641677, 'epoch': 0.41}\n",
      "{'loss': 0.7677, 'grad_norm': 0.2829323709011078, 'learning_rate': 0.00017638775854920686, 'epoch': 0.41}\n",
      "{'loss': 0.7592, 'grad_norm': 0.31731393933296204, 'learning_rate': 0.00017561998065199696, 'epoch': 0.41}\n",
      "{'loss': 0.7382, 'grad_norm': 0.2227497547864914, 'learning_rate': 0.00017485220275478708, 'epoch': 0.42}\n",
      "{'loss': 0.755, 'grad_norm': 0.24095244705677032, 'learning_rate': 0.00017408442485757717, 'epoch': 0.42}\n",
      "{'loss': 0.7723, 'grad_norm': 0.5485988259315491, 'learning_rate': 0.0001733166469603673, 'epoch': 0.42}\n",
      "{'loss': 0.7765, 'grad_norm': 0.3191682696342468, 'learning_rate': 0.0001725488690631574, 'epoch': 0.42}\n",
      "{'loss': 0.767, 'grad_norm': 0.2500290870666504, 'learning_rate': 0.0001717810911659475, 'epoch': 0.43}\n",
      "{'loss': 0.7676, 'grad_norm': 0.2371065318584442, 'learning_rate': 0.0001710133132687376, 'epoch': 0.43}\n",
      "{'loss': 0.7613, 'grad_norm': 0.22955507040023804, 'learning_rate': 0.0001702455353715277, 'epoch': 0.43}\n",
      "{'loss': 0.7882, 'grad_norm': 0.3511466383934021, 'learning_rate': 0.00016947775747431782, 'epoch': 0.44}\n",
      "{'loss': 0.7488, 'grad_norm': 0.41390010714530945, 'learning_rate': 0.00016870997957710792, 'epoch': 0.44}\n",
      "{'loss': 0.752, 'grad_norm': 0.49364304542541504, 'learning_rate': 0.00016794220167989804, 'epoch': 0.44}\n",
      "{'loss': 0.7509, 'grad_norm': 0.4568350911140442, 'learning_rate': 0.00016717442378268814, 'epoch': 0.44}\n",
      "{'loss': 0.7544, 'grad_norm': 0.567589282989502, 'learning_rate': 0.00016640664588547823, 'epoch': 0.45}\n",
      "{'loss': 0.7629, 'grad_norm': 0.2967965006828308, 'learning_rate': 0.00016563886798826835, 'epoch': 0.45}\n",
      "{'loss': 0.7736, 'grad_norm': 0.42569267749786377, 'learning_rate': 0.00016487109009105842, 'epoch': 0.45}\n",
      "{'loss': 0.7949, 'grad_norm': 0.4059421420097351, 'learning_rate': 0.00016410331219384857, 'epoch': 0.45}\n",
      "{'loss': 0.7393, 'grad_norm': 0.4160389006137848, 'learning_rate': 0.00016333553429663864, 'epoch': 0.46}\n",
      "{'loss': 0.7498, 'grad_norm': 0.3552355468273163, 'learning_rate': 0.00016256775639942876, 'epoch': 0.46}\n",
      "{'loss': 0.7503, 'grad_norm': 0.19957156479358673, 'learning_rate': 0.00016179997850221885, 'epoch': 0.46}\n",
      "{'loss': 0.7529, 'grad_norm': 0.40536928176879883, 'learning_rate': 0.00016103220060500895, 'epoch': 0.46}\n",
      "{'loss': 0.7611, 'grad_norm': 0.2850699722766876, 'learning_rate': 0.00016026442270779907, 'epoch': 0.47}\n",
      "{'loss': 0.754, 'grad_norm': 0.4145878255367279, 'learning_rate': 0.00015949664481058917, 'epoch': 0.47}\n",
      "{'loss': 0.7478, 'grad_norm': 0.2637519836425781, 'learning_rate': 0.0001587288669133793, 'epoch': 0.47}\n",
      "{'loss': 0.7402, 'grad_norm': 0.47524887323379517, 'learning_rate': 0.00015796108901616938, 'epoch': 0.47}\n",
      "{'loss': 0.7726, 'grad_norm': 0.6493052244186401, 'learning_rate': 0.0001571933111189595, 'epoch': 0.48}\n",
      "{'loss': 0.7256, 'grad_norm': 0.2816653549671173, 'learning_rate': 0.0001564255332217496, 'epoch': 0.48}\n",
      "{'loss': 0.728, 'grad_norm': 0.39745429158210754, 'learning_rate': 0.0001556577553245397, 'epoch': 0.48}\n",
      "{'loss': 0.7325, 'grad_norm': 0.27314913272857666, 'learning_rate': 0.00015488997742732982, 'epoch': 0.48}\n",
      "{'loss': 0.7409, 'grad_norm': 0.36193251609802246, 'learning_rate': 0.0001541221995301199, 'epoch': 0.49}\n",
      "{'loss': 0.7708, 'grad_norm': 0.32691532373428345, 'learning_rate': 0.00015335442163291003, 'epoch': 0.49}\n",
      "{'loss': 0.7507, 'grad_norm': 0.2562456727027893, 'learning_rate': 0.00015258664373570013, 'epoch': 0.49}\n",
      "{'loss': 0.7412, 'grad_norm': 0.2848514914512634, 'learning_rate': 0.00015181886583849025, 'epoch': 0.49}\n",
      "{'loss': 0.7452, 'grad_norm': 0.51204514503479, 'learning_rate': 0.00015105108794128034, 'epoch': 0.5}\n",
      "{'loss': 0.774, 'grad_norm': 0.4390578866004944, 'learning_rate': 0.00015028331004407044, 'epoch': 0.5}\n",
      "{'loss': 0.7341, 'grad_norm': 0.5647538900375366, 'learning_rate': 0.00014951553214686056, 'epoch': 0.5}\n",
      "{'loss': 0.753, 'grad_norm': 0.22786319255828857, 'learning_rate': 0.00014874775424965063, 'epoch': 0.5}\n",
      "{'loss': 0.7483, 'grad_norm': 0.3123365342617035, 'learning_rate': 0.00014797997635244075, 'epoch': 0.51}\n",
      "{'loss': 0.7469, 'grad_norm': 0.34536516666412354, 'learning_rate': 0.00014721219845523085, 'epoch': 0.51}\n",
      "{'loss': 0.7507, 'grad_norm': 0.36594897508621216, 'learning_rate': 0.00014644442055802097, 'epoch': 0.51}\n",
      "{'loss': 0.7638, 'grad_norm': 0.19911953806877136, 'learning_rate': 0.00014567664266081106, 'epoch': 0.51}\n",
      "{'loss': 0.8078, 'grad_norm': 0.532815158367157, 'learning_rate': 0.00014490886476360118, 'epoch': 0.52}\n",
      "{'loss': 0.7349, 'grad_norm': 0.424418181180954, 'learning_rate': 0.00014414108686639128, 'epoch': 0.52}\n",
      "{'loss': 0.7472, 'grad_norm': 0.3065067529678345, 'learning_rate': 0.00014337330896918137, 'epoch': 0.52}\n",
      "{'loss': 0.7509, 'grad_norm': 0.3549928665161133, 'learning_rate': 0.0001426055310719715, 'epoch': 0.52}\n",
      "{'loss': 0.7544, 'grad_norm': 0.3780894875526428, 'learning_rate': 0.0001418377531747616, 'epoch': 0.53}\n",
      "{'loss': 0.7204, 'grad_norm': 0.6119728088378906, 'learning_rate': 0.0001410699752775517, 'epoch': 0.53}\n",
      "{'loss': 0.7669, 'grad_norm': 0.1912825107574463, 'learning_rate': 0.0001403021973803418, 'epoch': 0.53}\n",
      "{'loss': 0.7578, 'grad_norm': 0.5280844569206238, 'learning_rate': 0.00013953441948313193, 'epoch': 0.53}\n",
      "{'loss': 0.7492, 'grad_norm': 0.6106537580490112, 'learning_rate': 0.000138766641585922, 'epoch': 0.54}\n",
      "{'loss': 0.7529, 'grad_norm': 0.31193074584007263, 'learning_rate': 0.00013799886368871212, 'epoch': 0.54}\n",
      "{'loss': 0.7672, 'grad_norm': 0.5017205476760864, 'learning_rate': 0.0001372310857915022, 'epoch': 0.54}\n",
      "{'loss': 0.7268, 'grad_norm': 0.4954780042171478, 'learning_rate': 0.00013646330789429233, 'epoch': 0.55}\n",
      "{'loss': 0.7446, 'grad_norm': 0.3262594938278198, 'learning_rate': 0.00013569552999708243, 'epoch': 0.55}\n",
      "{'loss': 0.7404, 'grad_norm': 0.45857053995132446, 'learning_rate': 0.00013492775209987255, 'epoch': 0.55}\n",
      "{'loss': 0.7471, 'grad_norm': 0.3808092772960663, 'learning_rate': 0.00013415997420266265, 'epoch': 0.55}\n",
      "{'loss': 0.7282, 'grad_norm': 0.35779353976249695, 'learning_rate': 0.00013339219630545274, 'epoch': 0.56}\n",
      "{'loss': 0.7494, 'grad_norm': 0.4085994362831116, 'learning_rate': 0.00013262441840824286, 'epoch': 0.56}\n",
      "{'loss': 0.7094, 'grad_norm': 0.4424879252910614, 'learning_rate': 0.00013185664051103296, 'epoch': 0.56}\n",
      "{'loss': 0.7491, 'grad_norm': 0.4077501595020294, 'learning_rate': 0.00013108886261382305, 'epoch': 0.56}\n",
      "{'loss': 0.7434, 'grad_norm': 0.3706226646900177, 'learning_rate': 0.00013032108471661317, 'epoch': 0.57}\n",
      "{'loss': 0.7435, 'grad_norm': 0.4117499589920044, 'learning_rate': 0.00012955330681940327, 'epoch': 0.57}\n",
      "{'loss': 0.748, 'grad_norm': 0.516465961933136, 'learning_rate': 0.00012878552892219336, 'epoch': 0.57}\n",
      "{'loss': 0.7498, 'grad_norm': 0.4701817035675049, 'learning_rate': 0.00012801775102498349, 'epoch': 0.57}\n",
      "{'loss': 0.7213, 'grad_norm': 0.39449891448020935, 'learning_rate': 0.00012724997312777358, 'epoch': 0.58}\n",
      "{'loss': 0.754, 'grad_norm': 0.3384435474872589, 'learning_rate': 0.0001264821952305637, 'epoch': 0.58}\n",
      "{'loss': 0.7342, 'grad_norm': 0.30770143866539, 'learning_rate': 0.0001257144173333538, 'epoch': 0.58}\n",
      "{'loss': 0.7472, 'grad_norm': 0.35826972126960754, 'learning_rate': 0.00012494663943614392, 'epoch': 0.58}\n",
      "{'loss': 0.7245, 'grad_norm': 0.4885408878326416, 'learning_rate': 0.000124178861538934, 'epoch': 0.59}\n",
      "{'loss': 0.764, 'grad_norm': 0.4680364727973938, 'learning_rate': 0.0001234110836417241, 'epoch': 0.59}\n",
      "{'loss': 0.7711, 'grad_norm': 0.3297977149486542, 'learning_rate': 0.0001226433057445142, 'epoch': 0.59}\n",
      "{'loss': 0.7445, 'grad_norm': 0.20729780197143555, 'learning_rate': 0.00012187552784730433, 'epoch': 0.59}\n",
      "{'loss': 0.7254, 'grad_norm': 0.5325940847396851, 'learning_rate': 0.00012110774995009443, 'epoch': 0.6}\n",
      "{'loss': 0.7265, 'grad_norm': 0.4270637333393097, 'learning_rate': 0.00012033997205288454, 'epoch': 0.6}\n",
      "{'loss': 0.7347, 'grad_norm': 0.29884082078933716, 'learning_rate': 0.00011957219415567462, 'epoch': 0.6}\n",
      "{'loss': 0.7375, 'grad_norm': 0.47470250725746155, 'learning_rate': 0.00011880441625846473, 'epoch': 0.6}\n",
      "{'loss': 0.7672, 'grad_norm': 0.35939595103263855, 'learning_rate': 0.00011803663836125484, 'epoch': 0.61}\n",
      "{'loss': 0.7385, 'grad_norm': 0.4214167594909668, 'learning_rate': 0.00011726886046404495, 'epoch': 0.61}\n",
      "{'loss': 0.7298, 'grad_norm': 0.3716651201248169, 'learning_rate': 0.00011650108256683506, 'epoch': 0.61}\n",
      "{'loss': 0.7207, 'grad_norm': 0.5350624322891235, 'learning_rate': 0.00011573330466962517, 'epoch': 0.61}\n",
      "{'loss': 0.7368, 'grad_norm': 0.253583163022995, 'learning_rate': 0.00011496552677241527, 'epoch': 0.62}\n",
      "{'loss': 0.7287, 'grad_norm': 0.2282550185918808, 'learning_rate': 0.00011419774887520537, 'epoch': 0.62}\n",
      "{'loss': 0.7563, 'grad_norm': 0.4467952251434326, 'learning_rate': 0.00011342997097799548, 'epoch': 0.62}\n",
      "{'loss': 0.7565, 'grad_norm': 0.28474247455596924, 'learning_rate': 0.00011266219308078559, 'epoch': 0.62}\n",
      "{'loss': 0.7299, 'grad_norm': 0.4157496690750122, 'learning_rate': 0.00011189441518357568, 'epoch': 0.63}\n",
      "{'loss': 0.7206, 'grad_norm': 0.48659196496009827, 'learning_rate': 0.00011112663728636579, 'epoch': 0.63}\n",
      "{'loss': 0.7302, 'grad_norm': 0.43824881315231323, 'learning_rate': 0.0001103588593891559, 'epoch': 0.63}\n",
      "{'loss': 0.7336, 'grad_norm': 0.35876113176345825, 'learning_rate': 0.00010959108149194599, 'epoch': 0.63}\n",
      "{'loss': 0.7124, 'grad_norm': 0.4029596447944641, 'learning_rate': 0.0001088233035947361, 'epoch': 0.64}\n",
      "{'loss': 0.7567, 'grad_norm': 0.3055990934371948, 'learning_rate': 0.00010805552569752621, 'epoch': 0.64}\n",
      "{'loss': 0.7291, 'grad_norm': 0.4040619134902954, 'learning_rate': 0.00010728774780031632, 'epoch': 0.64}\n",
      "{'loss': 0.7385, 'grad_norm': 0.353389173746109, 'learning_rate': 0.00010651996990310643, 'epoch': 0.64}\n",
      "{'loss': 0.7321, 'grad_norm': 0.5220528841018677, 'learning_rate': 0.00010575219200589653, 'epoch': 0.65}\n",
      "{'loss': 0.735, 'grad_norm': 0.4355156123638153, 'learning_rate': 0.00010498441410868664, 'epoch': 0.65}\n",
      "{'loss': 0.7115, 'grad_norm': 0.3996707797050476, 'learning_rate': 0.00010421663621147672, 'epoch': 0.65}\n",
      "{'loss': 0.7467, 'grad_norm': 0.37404149770736694, 'learning_rate': 0.00010344885831426683, 'epoch': 0.66}\n",
      "{'loss': 0.7424, 'grad_norm': 0.44964927434921265, 'learning_rate': 0.00010268108041705694, 'epoch': 0.66}\n",
      "{'loss': 0.7402, 'grad_norm': 0.2869848906993866, 'learning_rate': 0.00010191330251984705, 'epoch': 0.66}\n",
      "{'loss': 0.7172, 'grad_norm': 0.27727383375167847, 'learning_rate': 0.00010114552462263716, 'epoch': 0.66}\n",
      "{'loss': 0.7504, 'grad_norm': 0.39705267548561096, 'learning_rate': 0.00010037774672542726, 'epoch': 0.67}\n",
      "{'loss': 0.7496, 'grad_norm': 0.5012506246566772, 'learning_rate': 9.960996882821736e-05, 'epoch': 0.67}\n",
      "{'loss': 0.7552, 'grad_norm': 0.45474866032600403, 'learning_rate': 9.884219093100747e-05, 'epoch': 0.67}\n",
      "{'loss': 0.7312, 'grad_norm': 0.2865775227546692, 'learning_rate': 9.807441303379758e-05, 'epoch': 0.67}\n",
      "{'loss': 0.7185, 'grad_norm': 0.3947620987892151, 'learning_rate': 9.730663513658768e-05, 'epoch': 0.68}\n",
      "{'loss': 0.75, 'grad_norm': 0.45521777868270874, 'learning_rate': 9.653885723937779e-05, 'epoch': 0.68}\n",
      "{'loss': 0.7454, 'grad_norm': 0.8126139044761658, 'learning_rate': 9.577107934216789e-05, 'epoch': 0.68}\n",
      "{'loss': 0.7451, 'grad_norm': 0.31260213255882263, 'learning_rate': 9.5003301444958e-05, 'epoch': 0.68}\n",
      "{'loss': 0.7427, 'grad_norm': 0.5194043517112732, 'learning_rate': 9.423552354774809e-05, 'epoch': 0.69}\n",
      "{'loss': 0.7386, 'grad_norm': 0.30341583490371704, 'learning_rate': 9.34677456505382e-05, 'epoch': 0.69}\n",
      "{'loss': 0.7002, 'grad_norm': 0.35522568225860596, 'learning_rate': 9.269996775332831e-05, 'epoch': 0.69}\n",
      "{'loss': 0.7454, 'grad_norm': 0.49142447113990784, 'learning_rate': 9.193218985611842e-05, 'epoch': 0.69}\n",
      "{'loss': 0.7483, 'grad_norm': 0.326400488615036, 'learning_rate': 9.116441195890852e-05, 'epoch': 0.7}\n",
      "{'loss': 0.7378, 'grad_norm': 0.4210163652896881, 'learning_rate': 9.039663406169863e-05, 'epoch': 0.7}\n",
      "{'loss': 0.7601, 'grad_norm': 0.3748083710670471, 'learning_rate': 8.962885616448873e-05, 'epoch': 0.7}\n",
      "{'loss': 0.7155, 'grad_norm': 0.2278996855020523, 'learning_rate': 8.886107826727882e-05, 'epoch': 0.7}\n",
      "{'loss': 0.738, 'grad_norm': 0.4742938280105591, 'learning_rate': 8.809330037006893e-05, 'epoch': 0.71}\n",
      "{'loss': 0.7389, 'grad_norm': 0.48743152618408203, 'learning_rate': 8.732552247285904e-05, 'epoch': 0.71}\n",
      "{'loss': 0.747, 'grad_norm': 0.5064182877540588, 'learning_rate': 8.655774457564915e-05, 'epoch': 0.71}\n",
      "{'loss': 0.7472, 'grad_norm': 0.5171255469322205, 'learning_rate': 8.578996667843926e-05, 'epoch': 0.71}\n",
      "{'loss': 0.7252, 'grad_norm': 0.2760976254940033, 'learning_rate': 8.502218878122936e-05, 'epoch': 0.72}\n",
      "{'loss': 0.7467, 'grad_norm': 0.5658839344978333, 'learning_rate': 8.425441088401946e-05, 'epoch': 0.72}\n",
      "{'loss': 0.7472, 'grad_norm': 0.49401554465293884, 'learning_rate': 8.348663298680957e-05, 'epoch': 0.72}\n",
      "{'loss': 0.7221, 'grad_norm': 0.4159393012523651, 'learning_rate': 8.271885508959968e-05, 'epoch': 0.72}\n",
      "{'loss': 0.7231, 'grad_norm': 0.25926080346107483, 'learning_rate': 8.195107719238978e-05, 'epoch': 0.73}\n",
      "{'loss': 0.7281, 'grad_norm': 0.43433311581611633, 'learning_rate': 8.118329929517989e-05, 'epoch': 0.73}\n",
      "{'loss': 0.7372, 'grad_norm': 0.3294465243816376, 'learning_rate': 8.041552139797e-05, 'epoch': 0.73}\n",
      "{'loss': 0.71, 'grad_norm': 0.45245182514190674, 'learning_rate': 7.964774350076008e-05, 'epoch': 0.73}\n",
      "{'loss': 0.7361, 'grad_norm': 0.27778133749961853, 'learning_rate': 7.887996560355019e-05, 'epoch': 0.74}\n",
      "{'loss': 0.7265, 'grad_norm': 0.2787776589393616, 'learning_rate': 7.81121877063403e-05, 'epoch': 0.74}\n",
      "{'loss': 0.7169, 'grad_norm': 0.48195016384124756, 'learning_rate': 7.734440980913041e-05, 'epoch': 0.74}\n",
      "{'loss': 0.733, 'grad_norm': 0.8294654488563538, 'learning_rate': 7.657663191192052e-05, 'epoch': 0.74}\n",
      "{'loss': 0.7279, 'grad_norm': 0.324685275554657, 'learning_rate': 7.580885401471062e-05, 'epoch': 0.75}\n",
      "{'loss': 0.7404, 'grad_norm': 0.6631954312324524, 'learning_rate': 7.504107611750072e-05, 'epoch': 0.75}\n",
      "{'loss': 0.7068, 'grad_norm': 0.2692728042602539, 'learning_rate': 7.427329822029083e-05, 'epoch': 0.75}\n",
      "{'loss': 0.7218, 'grad_norm': 0.4586467444896698, 'learning_rate': 7.350552032308094e-05, 'epoch': 0.75}\n",
      "{'loss': 0.7524, 'grad_norm': 0.66182941198349, 'learning_rate': 7.273774242587104e-05, 'epoch': 0.76}\n",
      "{'loss': 0.7336, 'grad_norm': 0.5002105832099915, 'learning_rate': 7.196996452866114e-05, 'epoch': 0.76}\n",
      "{'loss': 0.7306, 'grad_norm': 0.39492589235305786, 'learning_rate': 7.120218663145125e-05, 'epoch': 0.76}\n",
      "{'loss': 0.728, 'grad_norm': 0.3411419987678528, 'learning_rate': 7.043440873424136e-05, 'epoch': 0.77}\n",
      "{'loss': 0.7192, 'grad_norm': 0.3904650807380676, 'learning_rate': 6.966663083703146e-05, 'epoch': 0.77}\n",
      "{'loss': 0.7635, 'grad_norm': 0.3703842759132385, 'learning_rate': 6.889885293982156e-05, 'epoch': 0.77}\n",
      "{'loss': 0.7222, 'grad_norm': 0.3138255476951599, 'learning_rate': 6.813107504261167e-05, 'epoch': 0.77}\n",
      "{'loss': 0.7031, 'grad_norm': 0.37496325373649597, 'learning_rate': 6.736329714540178e-05, 'epoch': 0.78}\n",
      "{'loss': 0.7203, 'grad_norm': 0.3873898983001709, 'learning_rate': 6.659551924819188e-05, 'epoch': 0.78}\n",
      "{'loss': 0.7022, 'grad_norm': 0.3169248104095459, 'learning_rate': 6.582774135098198e-05, 'epoch': 0.78}\n",
      "{'loss': 0.7204, 'grad_norm': 0.46868059039115906, 'learning_rate': 6.505996345377209e-05, 'epoch': 0.78}\n",
      "{'loss': 0.7275, 'grad_norm': 0.25249138474464417, 'learning_rate': 6.42921855565622e-05, 'epoch': 0.79}\n",
      "{'loss': 0.7201, 'grad_norm': 0.6898773908615112, 'learning_rate': 6.352440765935229e-05, 'epoch': 0.79}\n",
      "{'loss': 0.742, 'grad_norm': 0.2814297676086426, 'learning_rate': 6.27566297621424e-05, 'epoch': 0.79}\n",
      "{'loss': 0.7225, 'grad_norm': 0.5161955952644348, 'learning_rate': 6.19888518649325e-05, 'epoch': 0.79}\n",
      "{'loss': 0.7263, 'grad_norm': 0.3911959230899811, 'learning_rate': 6.122107396772261e-05, 'epoch': 0.8}\n",
      "{'loss': 0.706, 'grad_norm': 0.33435535430908203, 'learning_rate': 6.0453296070512716e-05, 'epoch': 0.8}\n",
      "{'loss': 0.7392, 'grad_norm': 0.268065482378006, 'learning_rate': 5.9685518173302825e-05, 'epoch': 0.8}\n",
      "{'loss': 0.7207, 'grad_norm': 0.3554796576499939, 'learning_rate': 5.891774027609292e-05, 'epoch': 0.8}\n",
      "{'loss': 0.7137, 'grad_norm': 0.3506990075111389, 'learning_rate': 5.814996237888303e-05, 'epoch': 0.81}\n",
      "{'loss': 0.7431, 'grad_norm': 0.25949978828430176, 'learning_rate': 5.7382184481673136e-05, 'epoch': 0.81}\n",
      "{'loss': 0.7328, 'grad_norm': 0.4258100092411041, 'learning_rate': 5.6614406584463245e-05, 'epoch': 0.81}\n",
      "{'loss': 0.7235, 'grad_norm': 0.48864784836769104, 'learning_rate': 5.5846628687253346e-05, 'epoch': 0.81}\n",
      "{'loss': 0.7365, 'grad_norm': 0.44339048862457275, 'learning_rate': 5.5078850790043455e-05, 'epoch': 0.82}\n",
      "{'loss': 0.7303, 'grad_norm': 0.42275509238243103, 'learning_rate': 5.431107289283356e-05, 'epoch': 0.82}\n",
      "{'loss': 0.7742, 'grad_norm': 0.6288005113601685, 'learning_rate': 5.354329499562366e-05, 'epoch': 0.82}\n",
      "{'loss': 0.7381, 'grad_norm': 0.2984216809272766, 'learning_rate': 5.2775517098413766e-05, 'epoch': 0.82}\n",
      "{'loss': 0.7332, 'grad_norm': 0.2687206566333771, 'learning_rate': 5.2007739201203874e-05, 'epoch': 0.83}\n",
      "{'loss': 0.7213, 'grad_norm': 0.2802385091781616, 'learning_rate': 5.1239961303993976e-05, 'epoch': 0.83}\n",
      "{'loss': 0.7458, 'grad_norm': 0.37929385900497437, 'learning_rate': 5.047218340678408e-05, 'epoch': 0.83}\n",
      "{'loss': 0.7396, 'grad_norm': 0.24754126369953156, 'learning_rate': 4.9704405509574186e-05, 'epoch': 0.83}\n",
      "{'loss': 0.7219, 'grad_norm': 0.26944565773010254, 'learning_rate': 4.893662761236429e-05, 'epoch': 0.84}\n",
      "{'loss': 0.7088, 'grad_norm': 0.26711222529411316, 'learning_rate': 4.8168849715154396e-05, 'epoch': 0.84}\n",
      "{'loss': 0.7244, 'grad_norm': 0.20702597498893738, 'learning_rate': 4.7401071817944504e-05, 'epoch': 0.84}\n",
      "{'loss': 0.7257, 'grad_norm': 0.23670950531959534, 'learning_rate': 4.66332939207346e-05, 'epoch': 0.84}\n",
      "{'loss': 0.6998, 'grad_norm': 0.41756942868232727, 'learning_rate': 4.586551602352471e-05, 'epoch': 0.85}\n",
      "{'loss': 0.7002, 'grad_norm': 0.4350195825099945, 'learning_rate': 4.5097738126314816e-05, 'epoch': 0.85}\n",
      "{'loss': 0.7069, 'grad_norm': 0.48209238052368164, 'learning_rate': 4.4329960229104924e-05, 'epoch': 0.85}\n",
      "{'loss': 0.698, 'grad_norm': 0.2833086848258972, 'learning_rate': 4.3562182331895026e-05, 'epoch': 0.85}\n",
      "{'loss': 0.7032, 'grad_norm': 0.5347577929496765, 'learning_rate': 4.2794404434685134e-05, 'epoch': 0.86}\n",
      "{'loss': 0.7155, 'grad_norm': 0.555619478225708, 'learning_rate': 4.2026626537475236e-05, 'epoch': 0.86}\n",
      "{'loss': 0.7192, 'grad_norm': 0.4426388740539551, 'learning_rate': 4.125884864026534e-05, 'epoch': 0.86}\n",
      "{'loss': 0.7213, 'grad_norm': 0.6171525716781616, 'learning_rate': 4.0491070743055446e-05, 'epoch': 0.87}\n",
      "{'loss': 0.7194, 'grad_norm': 0.3153947591781616, 'learning_rate': 3.9723292845845554e-05, 'epoch': 0.87}\n",
      "{'loss': 0.7119, 'grad_norm': 0.46166881918907166, 'learning_rate': 3.8955514948635655e-05, 'epoch': 0.87}\n",
      "{'loss': 0.6897, 'grad_norm': 0.384274423122406, 'learning_rate': 3.818773705142576e-05, 'epoch': 0.87}\n",
      "{'loss': 0.7245, 'grad_norm': 0.23116640746593475, 'learning_rate': 3.7419959154215865e-05, 'epoch': 0.88}\n",
      "{'loss': 0.74, 'grad_norm': 0.4164285361766815, 'learning_rate': 3.6652181257005974e-05, 'epoch': 0.88}\n",
      "{'loss': 0.7306, 'grad_norm': 0.5024785399436951, 'learning_rate': 3.5884403359796075e-05, 'epoch': 0.88}\n",
      "{'loss': 0.7066, 'grad_norm': 0.32244884967803955, 'learning_rate': 3.5116625462586184e-05, 'epoch': 0.88}\n",
      "{'loss': 0.7359, 'grad_norm': 0.3609629273414612, 'learning_rate': 3.4348847565376285e-05, 'epoch': 0.89}\n",
      "{'loss': 0.7213, 'grad_norm': 1.8536937236785889, 'learning_rate': 3.358106966816639e-05, 'epoch': 0.89}\n",
      "{'loss': 0.7239, 'grad_norm': 0.43980321288108826, 'learning_rate': 3.2813291770956495e-05, 'epoch': 0.89}\n",
      "{'loss': 0.732, 'grad_norm': 0.33076807856559753, 'learning_rate': 3.20455138737466e-05, 'epoch': 0.89}\n",
      "{'loss': 0.7264, 'grad_norm': 0.4302218556404114, 'learning_rate': 3.1277735976536705e-05, 'epoch': 0.9}\n",
      "{'loss': 0.716, 'grad_norm': 0.37399059534072876, 'learning_rate': 3.050995807932681e-05, 'epoch': 0.9}\n",
      "{'loss': 0.7164, 'grad_norm': 0.6629664897918701, 'learning_rate': 2.9742180182116915e-05, 'epoch': 0.9}\n",
      "{'loss': 0.7321, 'grad_norm': 0.2440727800130844, 'learning_rate': 2.897440228490702e-05, 'epoch': 0.9}\n",
      "{'loss': 0.7149, 'grad_norm': 0.37798210978507996, 'learning_rate': 2.8206624387697125e-05, 'epoch': 0.91}\n",
      "{'loss': 0.7137, 'grad_norm': 0.4601452946662903, 'learning_rate': 2.7438846490487227e-05, 'epoch': 0.91}\n",
      "{'loss': 0.7289, 'grad_norm': 0.3798578083515167, 'learning_rate': 2.6671068593277335e-05, 'epoch': 0.91}\n",
      "{'loss': 0.7148, 'grad_norm': 0.3395811915397644, 'learning_rate': 2.590329069606744e-05, 'epoch': 0.91}\n",
      "{'loss': 0.7066, 'grad_norm': 0.6163970232009888, 'learning_rate': 2.5135512798857545e-05, 'epoch': 0.92}\n",
      "{'loss': 0.723, 'grad_norm': 0.28352001309394836, 'learning_rate': 2.436773490164765e-05, 'epoch': 0.92}\n",
      "{'loss': 0.7361, 'grad_norm': 0.22789354622364044, 'learning_rate': 2.359995700443775e-05, 'epoch': 0.92}\n",
      "{'loss': 0.7167, 'grad_norm': 0.23886644840240479, 'learning_rate': 2.283217910722786e-05, 'epoch': 0.92}\n",
      "{'loss': 0.7274, 'grad_norm': 0.44742512702941895, 'learning_rate': 2.2064401210017965e-05, 'epoch': 0.93}\n",
      "{'loss': 0.7167, 'grad_norm': 0.44725537300109863, 'learning_rate': 2.1296623312808066e-05, 'epoch': 0.93}\n",
      "{'loss': 0.7185, 'grad_norm': 0.2930621802806854, 'learning_rate': 2.0528845415598175e-05, 'epoch': 0.93}\n",
      "{'loss': 0.7502, 'grad_norm': 0.5555850863456726, 'learning_rate': 1.976106751838828e-05, 'epoch': 0.93}\n",
      "{'loss': 0.7536, 'grad_norm': 0.28232091665267944, 'learning_rate': 1.8993289621178385e-05, 'epoch': 0.94}\n",
      "{'loss': 0.714, 'grad_norm': 0.20106828212738037, 'learning_rate': 1.822551172396849e-05, 'epoch': 0.94}\n",
      "{'loss': 0.6902, 'grad_norm': 0.27035191655158997, 'learning_rate': 1.7457733826758594e-05, 'epoch': 0.94}\n",
      "{'loss': 0.7041, 'grad_norm': 0.7014227509498596, 'learning_rate': 1.6689955929548696e-05, 'epoch': 0.94}\n",
      "{'loss': 0.6963, 'grad_norm': 0.34554383158683777, 'learning_rate': 1.5922178032338804e-05, 'epoch': 0.95}\n",
      "{'loss': 0.7083, 'grad_norm': 0.561339795589447, 'learning_rate': 1.515440013512891e-05, 'epoch': 0.95}\n",
      "{'loss': 0.7215, 'grad_norm': 0.4374707341194153, 'learning_rate': 1.4386622237919014e-05, 'epoch': 0.95}\n",
      "{'loss': 0.7053, 'grad_norm': 0.36132556200027466, 'learning_rate': 1.3618844340709118e-05, 'epoch': 0.95}\n",
      "{'loss': 0.7207, 'grad_norm': 1.1102354526519775, 'learning_rate': 1.2851066443499223e-05, 'epoch': 0.96}\n",
      "{'loss': 0.7279, 'grad_norm': 0.44847768545150757, 'learning_rate': 1.2083288546289328e-05, 'epoch': 0.96}\n",
      "{'loss': 0.7115, 'grad_norm': 0.5046964287757874, 'learning_rate': 1.1315510649079434e-05, 'epoch': 0.96}\n",
      "{'loss': 0.7294, 'grad_norm': 0.43054020404815674, 'learning_rate': 1.054773275186954e-05, 'epoch': 0.96}\n",
      "{'loss': 0.7565, 'grad_norm': 0.35398146510124207, 'learning_rate': 9.779954854659642e-06, 'epoch': 0.97}\n",
      "{'loss': 0.7323, 'grad_norm': 0.24652467668056488, 'learning_rate': 9.012176957449747e-06, 'epoch': 0.97}\n",
      "{'loss': 0.7299, 'grad_norm': 0.39235347509384155, 'learning_rate': 8.244399060239854e-06, 'epoch': 0.97}\n",
      "{'loss': 0.7343, 'grad_norm': 0.4387376308441162, 'learning_rate': 7.476621163029958e-06, 'epoch': 0.98}\n",
      "{'loss': 0.7442, 'grad_norm': 0.37846413254737854, 'learning_rate': 6.708843265820063e-06, 'epoch': 0.98}\n",
      "{'loss': 0.7117, 'grad_norm': 0.4678981602191925, 'learning_rate': 5.941065368610168e-06, 'epoch': 0.98}\n",
      "{'loss': 0.719, 'grad_norm': 1.712742567062378, 'learning_rate': 5.173287471400273e-06, 'epoch': 0.98}\n",
      "{'loss': 0.7199, 'grad_norm': 0.424560546875, 'learning_rate': 4.405509574190378e-06, 'epoch': 0.99}\n",
      "{'loss': 0.715, 'grad_norm': 0.24172823131084442, 'learning_rate': 3.6377316769804826e-06, 'epoch': 0.99}\n",
      "{'loss': 0.7058, 'grad_norm': 0.3209395408630371, 'learning_rate': 2.8699537797705876e-06, 'epoch': 0.99}\n",
      "{'loss': 0.7187, 'grad_norm': 0.45887529850006104, 'learning_rate': 2.1021758825606925e-06, 'epoch': 0.99}\n",
      "{'loss': 0.745, 'grad_norm': 0.41654935479164124, 'learning_rate': 1.3343979853507977e-06, 'epoch': 1.0}\n",
      "{'loss': 0.7195, 'grad_norm': 0.30803489685058594, 'learning_rate': 5.666200881409026e-07, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/j/Desktop/MLotsawa/.venv/lib/python3.10/site-packages/transformers/generation/utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6aab377a62f421ead358712ed5817d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3263661861419678, 'eval_bleu': 2.6598, 'eval_gen_len': 16.7499, 'eval_runtime': 289.8016, 'eval_samples_per_second': 31.283, 'eval_steps_per_second': 3.913, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 32229.7966, 'train_samples_per_second': 48.494, 'train_steps_per_second': 6.062, 'train_loss': 0.7735757870275787, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=195369, training_loss=0.7735757870275787, metrics={'train_runtime': 32229.7966, 'train_samples_per_second': 48.494, 'train_steps_per_second': 6.062, 'total_flos': 1.0576616663443046e+17, 'train_loss': 0.7735757870275787, 'epoch': 1.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"clean_1.0.2\",\n",
    "    auto_find_batch_size=True,\n",
    "    predict_with_generate=True,\n",
    "    fp16=False, #check this\n",
    "    push_to_hub=False,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    num_train_epochs=1\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    optimizers=(optimizer, None),\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
