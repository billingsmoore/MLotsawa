{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since billingsmoore/tibetan-to-english-translation-dataset couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /home/j/.cache/huggingface/datasets/billingsmoore___tibetan-to-english-translation-dataset/default/0.0.0/489c8f300991c7fafd496c8f91cf451d34192d8e (last modified on Sat Oct 12 16:12:29 2024).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tibetan': 'གསང་བའི་དཀྱིལ་འཁོར་འདི་ལ་བྱིན་ཕོབ་ཅིག།',\n",
       " 'phonetic': 'sangwé kyilkhor di la jin pob chik',\n",
       " 'english': 'In a rain of auspicious substances blazing with lights.'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "dataset = load_dataset('billingsmoore/tibetan-to-english-translation-dataset')\n",
    "dataset = dataset['train'].train_test_split(.15)\n",
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Unfinetuned Tokenizer, Model, and Data Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorForSeq2Seq, AutoModelForSeq2SeqLM\n",
    "\n",
    "checkpoint = \"google-t5/t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint, device_map=\"cuda:0\")\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Tibetan to Tokenizer\n",
    "\n",
    "The T5 tokenizer does not notably support the Tibetan script. So, we need to add it manually. Once the characters have been added to the tokenizer, the model needs to have its token embeddings resized to accomodate the added tokens. This is all pretty straightforward, as seen in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32245, 512)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tibetan characters to add\n",
    "tibetan_chars = [\n",
    "    # Consonants\n",
    "    \"ཀ\", \"ཁ\", \"ག\", \"ང\", \"ཅ\", \"ཆ\", \"ཇ\", \"ཉ\", \"ཏ\", \"ཐ\", \"ད\", \"ན\", \"པ\", \"པ\", \"ཕ\", \"བ\", \"མ\",\n",
    "    \"ཙ\", \"ཚ\", \"ཛ\", \"ཝ\", \"ཞ\", \"ཟ\", \"འ\", \"ཡ\", \"ར\", \"ལ\", \"ཤ\", \"ཥ\", \"ས\", \"ཧ\", \"ཨ\",\n",
    "\n",
    "    # Subjoined Consonants\n",
    "    \"ྐ\", \"ྑ\", \"ྒ\", \"ྒྷ\", \"ྔ\", \"ྕ\", \"ྖ\", \"ྗ\", \"྘\", \"ྙ\", \"ྚ\", \"ྛ\", \"ྜ\", \"ྜྷ\", \"ྞ\", \"ྟ\",\n",
    "    \"ྠ\", \"ྡ\", \"ྡྷ\", \"ྣ\", \"ྤ\", \"ྥ\", \"ྦ\", \"ྦྷ\", \"ྨ\", \"ྩ\", \"ྪ\", \"ྫ\", \"ྫྷ\", \"ྭ\", \"ྮ\", \"ྯ\",\n",
    "    \"ྰ\", \"ྱ\", \"ྲ\", \"ླ\", \"ྴ\", \"ྵ\", \"ྶ\", \"ྷ\", \"ྸ\", \"ྐྵ\", \"ྺ\", \"ྻ\", \"ྼ\", \"྽\", \"྾\", \"྿\",\n",
    "\n",
    "    # Vowels\n",
    "    \"ི\", \"ཱི\", \"ུ\", \"ཱུ\", \"ྲྀ\", \"ཷ\", \"ླྀ\", \"ཹ\", \"ེ\", \"ཻ\", \"ོ\", \"ཽ\", \"ཾ\", \"ཿ\",\n",
    "\n",
    "    # Other Marks and Symbols\n",
    "    \"འ\", \"ཡ\", \"ར\", \"ལ\", \"ཤ\", \"ཥ\", \"ས\", \"ཧ\", \"ཨ\",\n",
    "\n",
    "    # Additional Tibetan Characters\n",
    "    \"ཀྵ\", \"ཁྵ\", \"གྵ\", \"ངྵ\", \"ཅྵ\", \"ཆྵ\", \"ཇྵ\", \"ཉྵ\", \"ཏྵ\", \"ཐྵ\", \"དྵ\", \"ནྵ\", \"པྵ\", \n",
    "    \"པྵ\", \"ཕྵ\", \"བྵ\", \"མྵ\", \"ཙྵ\", \"ཚྵ\", \"ཛྵ\", \"ཝྵ\", \"ཞྵ\", \"ཟྵ\", \"འྵ\", \"ཡྵ\", \"རྵ\", \n",
    "    \"ལྵ\", \"ཤྵ\", \"ཥྵ\", \"སྵ\", \"ཧྵ\", \"ཨྵ\", \"པྪ\", \"པྫ\", \"པྫྷ\", \"པྭ\", \"པྮ\", \"པྯ\", \"པྰ\", \n",
    "    \"པྱ\", \"པྲ\", \"པླ\", \"པྴ\", \"པྵ\", \"པྶ\", \"པྷ\", \"པྸ\", \"པྐྵ\", \"པྺ\", \"པྻ\", \"པྼ\", \"པ྽\", \n",
    "    \"པ྾\", \"པ྿\"\n",
    "]\n",
    "\n",
    "\n",
    "#'ཀཁགངཅཆཇཉཏཐདནཔཕབམཙཚཛཝཞཟའཡརལཤཥསཧཨ'\n",
    "\n",
    "# Add the Tibetan characters to the tokenizer's vocabulary\n",
    "new_tokens = [char for char in tibetan_chars if char not in tokenizer.get_vocab()]\n",
    "\n",
    "# Add new tokens to the tokenizer\n",
    "tokenizer.add_tokens(new_tokens)\n",
    "\n",
    "# Resize model embeddings to accommodate the new vocabulary size\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "\n",
    "The dataset can now be tokenized for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bo_en_preprocess_function(examples):\n",
    "\n",
    "    # Prepare translation inputs and targets\n",
    "    translation_inputs = ['Translate Tibetan to English: ' + example for example in examples['tibetan']]\n",
    "    translation_targets = [example for example in examples['english']]\n",
    "    \n",
    "    # Tokenize translation inputs and targets\n",
    "    bo_en_model_inputs = tokenizer(translation_inputs, text_target=translation_targets, \n",
    "                                         max_length=300, truncation=True, padding=\"max_length\")\n",
    "    \n",
    "    \n",
    "    return bo_en_model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def en_bo_preprocess_function(examples):\n",
    "\n",
    "    # Prepare translation inputs and targets\n",
    "    translation_inputs = ['Translate English to Tibetan: ' + example for example in examples['english']]\n",
    "    translation_targets = [example for example in examples['tibetan']]\n",
    "    \n",
    "    # Tokenize translation inputs and targets\n",
    "    en_bo_model_inputs = tokenizer(translation_inputs, text_target=translation_targets, \n",
    "                                         max_length=300, truncation=True, padding=\"max_length\")\n",
    "    \n",
    "    \n",
    "    return en_bo_model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028e3dc52364489e846797eb96a78987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/69042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40eaa9f95db34cdf9ec23bb42791e384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12184 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bo_en_tokenized_dataset = dataset.map(bo_en_preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a6cd5f77c64eefb90ec849905aa39e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/69042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c9526b3670c41869bed666295124efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12184 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "en_bo_tokenized_dataset = dataset.map(en_bo_preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = {}\n",
    "\n",
    "tokenized_dataset['train'] = concatenate_datasets([bo_en_tokenized_dataset['train'], en_bo_tokenized_dataset['train']])\n",
    "tokenized_dataset['test'] = bo_en_tokenized_dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n",
    "Finally, we can train the model. Note that the optimizer used is Adafactor. This is the optimizer that is preferred for translation tasks and for the T5 model in general. The transformers api includes a built in version of Adafactor, but I define it separately here so that we can optimize it with the 'accelerate' library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, Adafactor\n",
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "\n",
    "optimizer = Adafactor(\n",
    "    model.parameters(), \n",
    "    scale_parameter=True, \n",
    "    relative_step=False, \n",
    "    warmup_init=False, \n",
    "    lr=3e-4\n",
    ")\n",
    "\n",
    "model, optimizer = accelerator.prepare(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbillingsmoore\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/j/Desktop/MLotsawa/Notebooks/Models/BidirectionalTest/wandb/run-20241012_175622-u509ue1f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/billingsmoore/huggingface/runs/u509ue1f' target=\"_blank\">bidirectional</a></strong> to <a href='https://wandb.ai/billingsmoore/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/billingsmoore/huggingface' target=\"_blank\">https://wandb.ai/billingsmoore/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/billingsmoore/huggingface/runs/u509ue1f' target=\"_blank\">https://wandb.ai/billingsmoore/huggingface/runs/u509ue1f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b2895632d6489b94fa44e6fdff2b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51783 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6332, 'grad_norm': 0.17786581814289093, 'learning_rate': 0.0002971032964486414, 'epoch': 0.03}\n",
      "{'loss': 0.299, 'grad_norm': 0.12014766037464142, 'learning_rate': 0.00029420659289728285, 'epoch': 0.06}\n",
      "{'loss': 0.2795, 'grad_norm': 0.16227394342422485, 'learning_rate': 0.0002913098893459243, 'epoch': 0.09}\n",
      "{'loss': 0.2722, 'grad_norm': 0.21368838846683502, 'learning_rate': 0.00028841318579456577, 'epoch': 0.12}\n",
      "{'loss': 0.2595, 'grad_norm': 0.14164778590202332, 'learning_rate': 0.0002855164822432072, 'epoch': 0.14}\n",
      "{'loss': 0.2529, 'grad_norm': 0.1506086140871048, 'learning_rate': 0.00028261977869184864, 'epoch': 0.17}\n",
      "{'loss': 0.2533, 'grad_norm': 0.14093157649040222, 'learning_rate': 0.0002797230751404901, 'epoch': 0.2}\n",
      "{'loss': 0.2459, 'grad_norm': 0.13410639762878418, 'learning_rate': 0.0002768263715891315, 'epoch': 0.23}\n",
      "{'loss': 0.2392, 'grad_norm': 0.16665083169937134, 'learning_rate': 0.00027392966803777295, 'epoch': 0.26}\n",
      "{'loss': 0.2356, 'grad_norm': 0.12141254544258118, 'learning_rate': 0.00027103296448641444, 'epoch': 0.29}\n",
      "{'loss': 0.237, 'grad_norm': 0.14494578540325165, 'learning_rate': 0.0002681362609350559, 'epoch': 0.32}\n",
      "{'loss': 0.2297, 'grad_norm': 0.13729073107242584, 'learning_rate': 0.0002652395573836973, 'epoch': 0.35}\n",
      "{'loss': 0.2262, 'grad_norm': 0.13771331310272217, 'learning_rate': 0.00026234285383233875, 'epoch': 0.38}\n",
      "{'loss': 0.2256, 'grad_norm': 0.11324585974216461, 'learning_rate': 0.0002594461502809802, 'epoch': 0.41}\n",
      "{'loss': 0.2247, 'grad_norm': 0.19301949441432953, 'learning_rate': 0.0002565494467296217, 'epoch': 0.43}\n",
      "{'loss': 0.2192, 'grad_norm': 0.11749507486820221, 'learning_rate': 0.0002536527431782631, 'epoch': 0.46}\n",
      "{'loss': 0.2194, 'grad_norm': 0.23562310636043549, 'learning_rate': 0.00025075603962690455, 'epoch': 0.49}\n",
      "{'loss': 0.2129, 'grad_norm': 0.12827111780643463, 'learning_rate': 0.000247859336075546, 'epoch': 0.52}\n",
      "{'loss': 0.2147, 'grad_norm': 0.10488127171993256, 'learning_rate': 0.0002449626325241875, 'epoch': 0.55}\n",
      "{'loss': 0.2082, 'grad_norm': 0.09931923449039459, 'learning_rate': 0.00024206592897282889, 'epoch': 0.58}\n",
      "{'loss': 0.206, 'grad_norm': 0.19773146510124207, 'learning_rate': 0.00023916922542147032, 'epoch': 0.61}\n",
      "{'loss': 0.2072, 'grad_norm': 0.12132272869348526, 'learning_rate': 0.0002362725218701118, 'epoch': 0.64}\n",
      "{'loss': 0.2059, 'grad_norm': 0.17182865738868713, 'learning_rate': 0.00023337581831875325, 'epoch': 0.67}\n",
      "{'loss': 0.2057, 'grad_norm': 0.18233232200145721, 'learning_rate': 0.00023047911476739468, 'epoch': 0.7}\n",
      "{'loss': 0.199, 'grad_norm': 0.19675636291503906, 'learning_rate': 0.00022758241121603612, 'epoch': 0.72}\n",
      "{'loss': 0.204, 'grad_norm': 0.15161052346229553, 'learning_rate': 0.00022468570766467758, 'epoch': 0.75}\n",
      "{'loss': 0.2013, 'grad_norm': 0.1458878070116043, 'learning_rate': 0.00022178900411331902, 'epoch': 0.78}\n",
      "{'loss': 0.1948, 'grad_norm': 0.4383593797683716, 'learning_rate': 0.00021889230056196046, 'epoch': 0.81}\n",
      "{'loss': 0.1943, 'grad_norm': 0.15126468241214752, 'learning_rate': 0.00021599559701060192, 'epoch': 0.84}\n",
      "{'loss': 0.1931, 'grad_norm': 0.13386555016040802, 'learning_rate': 0.00021309889345924338, 'epoch': 0.87}\n",
      "{'loss': 0.1935, 'grad_norm': 0.14189554750919342, 'learning_rate': 0.00021020218990788482, 'epoch': 0.9}\n",
      "{'loss': 0.192, 'grad_norm': 0.13429906964302063, 'learning_rate': 0.00020730548635652625, 'epoch': 0.93}\n",
      "{'loss': 0.1916, 'grad_norm': 0.11079487949609756, 'learning_rate': 0.0002044087828051677, 'epoch': 0.96}\n",
      "{'loss': 0.1902, 'grad_norm': 0.15575429797172546, 'learning_rate': 0.00020151207925380913, 'epoch': 0.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/j/Desktop/MLotsawa/.venv/lib/python3.10/site-packages/transformers/generation/utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1aac7bfbe84552bcbc4b6df0d482f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1523 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.14627183973789215, 'eval_bleu': 3.6518, 'eval_gen_len': 16.1257, 'eval_runtime': 414.8777, 'eval_samples_per_second': 29.368, 'eval_steps_per_second': 3.671, 'epoch': 1.0}\n",
      "{'loss': 0.1894, 'grad_norm': 0.13471776247024536, 'learning_rate': 0.00019861537570245062, 'epoch': 1.01}\n",
      "{'loss': 0.1862, 'grad_norm': 0.1104794517159462, 'learning_rate': 0.00019571867215109205, 'epoch': 1.04}\n",
      "{'loss': 0.1858, 'grad_norm': 0.15300562977790833, 'learning_rate': 0.0001928219685997335, 'epoch': 1.07}\n",
      "{'loss': 0.1839, 'grad_norm': 0.13286134600639343, 'learning_rate': 0.00018992526504837493, 'epoch': 1.1}\n",
      "{'loss': 0.1819, 'grad_norm': 0.1635775864124298, 'learning_rate': 0.00018702856149701636, 'epoch': 1.13}\n",
      "{'loss': 0.1857, 'grad_norm': 0.11667294055223465, 'learning_rate': 0.00018413185794565783, 'epoch': 1.16}\n",
      "{'loss': 0.1816, 'grad_norm': 0.18541409075260162, 'learning_rate': 0.0001812351543942993, 'epoch': 1.19}\n",
      "{'loss': 0.1787, 'grad_norm': 0.1281498521566391, 'learning_rate': 0.00017833845084294072, 'epoch': 1.22}\n",
      "{'loss': 0.1776, 'grad_norm': 0.1520354300737381, 'learning_rate': 0.00017544174729158216, 'epoch': 1.25}\n",
      "{'loss': 0.1782, 'grad_norm': 0.1436372548341751, 'learning_rate': 0.0001725450437402236, 'epoch': 1.27}\n",
      "{'loss': 0.1783, 'grad_norm': 0.10992834717035294, 'learning_rate': 0.00016964834018886506, 'epoch': 1.3}\n",
      "{'loss': 0.1794, 'grad_norm': 0.14493317902088165, 'learning_rate': 0.0001667516366375065, 'epoch': 1.33}\n",
      "{'loss': 0.1762, 'grad_norm': 0.14009808003902435, 'learning_rate': 0.00016385493308614796, 'epoch': 1.36}\n",
      "{'loss': 0.179, 'grad_norm': 0.20203466713428497, 'learning_rate': 0.0001609582295347894, 'epoch': 1.39}\n",
      "{'loss': 0.1747, 'grad_norm': 0.15068554878234863, 'learning_rate': 0.00015806152598343086, 'epoch': 1.42}\n",
      "{'loss': 0.1757, 'grad_norm': 0.1184670627117157, 'learning_rate': 0.0001551648224320723, 'epoch': 1.45}\n",
      "{'loss': 0.1707, 'grad_norm': 0.13226626813411713, 'learning_rate': 0.00015226811888071373, 'epoch': 1.48}\n",
      "{'loss': 0.1784, 'grad_norm': 0.15169791877269745, 'learning_rate': 0.0001493714153293552, 'epoch': 1.51}\n",
      "{'loss': 0.172, 'grad_norm': 0.10360972583293915, 'learning_rate': 0.00014647471177799663, 'epoch': 1.54}\n",
      "{'loss': 0.1751, 'grad_norm': 0.15313060581684113, 'learning_rate': 0.00014357800822663807, 'epoch': 1.56}\n",
      "{'loss': 0.1753, 'grad_norm': 0.18761515617370605, 'learning_rate': 0.00014068130467527953, 'epoch': 1.59}\n",
      "{'loss': 0.1703, 'grad_norm': 0.1436864733695984, 'learning_rate': 0.00013778460112392097, 'epoch': 1.62}\n",
      "{'loss': 0.1709, 'grad_norm': 0.13446404039859772, 'learning_rate': 0.0001348878975725624, 'epoch': 1.65}\n",
      "{'loss': 0.1725, 'grad_norm': 0.1563652753829956, 'learning_rate': 0.00013199119402120387, 'epoch': 1.68}\n",
      "{'loss': 0.1712, 'grad_norm': 0.13539506494998932, 'learning_rate': 0.0001290944904698453, 'epoch': 1.71}\n",
      "{'loss': 0.1668, 'grad_norm': 0.1566898673772812, 'learning_rate': 0.00012619778691848674, 'epoch': 1.74}\n",
      "{'loss': 0.1716, 'grad_norm': 0.2360876202583313, 'learning_rate': 0.0001233010833671282, 'epoch': 1.77}\n",
      "{'loss': 0.1682, 'grad_norm': 0.11532856523990631, 'learning_rate': 0.00012040437981576965, 'epoch': 1.8}\n",
      "{'loss': 0.1644, 'grad_norm': 0.17140084505081177, 'learning_rate': 0.00011750767626441109, 'epoch': 1.82}\n",
      "{'loss': 0.1699, 'grad_norm': 0.1296064853668213, 'learning_rate': 0.00011461097271305252, 'epoch': 1.85}\n",
      "{'loss': 0.1663, 'grad_norm': 0.16760723292827606, 'learning_rate': 0.00011171426916169399, 'epoch': 1.88}\n",
      "{'loss': 0.1663, 'grad_norm': 0.1417946070432663, 'learning_rate': 0.00010881756561033542, 'epoch': 1.91}\n",
      "{'loss': 0.1659, 'grad_norm': 0.14406202733516693, 'learning_rate': 0.00010592086205897687, 'epoch': 1.94}\n",
      "{'loss': 0.1651, 'grad_norm': 0.18205967545509338, 'learning_rate': 0.00010302415850761832, 'epoch': 1.97}\n",
      "{'loss': 0.1675, 'grad_norm': 0.17796412110328674, 'learning_rate': 0.00010012745495625977, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/j/Desktop/MLotsawa/.venv/lib/python3.10/site-packages/transformers/generation/utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e333f05f4d49c7a7f23ee93078e8e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1523 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1341230273246765, 'eval_bleu': 4.6624, 'eval_gen_len': 16.1466, 'eval_runtime': 422.1308, 'eval_samples_per_second': 28.863, 'eval_steps_per_second': 3.608, 'epoch': 2.0}\n",
      "{'loss': 0.1629, 'grad_norm': 0.18075750768184662, 'learning_rate': 9.723075140490121e-05, 'epoch': 2.03}\n",
      "{'loss': 0.1627, 'grad_norm': 0.29260414838790894, 'learning_rate': 9.433404785354267e-05, 'epoch': 2.06}\n",
      "{'loss': 0.1626, 'grad_norm': 0.1274515837430954, 'learning_rate': 9.14373443021841e-05, 'epoch': 2.09}\n",
      "{'loss': 0.1629, 'grad_norm': 0.16370031237602234, 'learning_rate': 8.854064075082554e-05, 'epoch': 2.11}\n",
      "{'loss': 0.164, 'grad_norm': 0.1507793813943863, 'learning_rate': 8.5643937199467e-05, 'epoch': 2.14}\n",
      "{'loss': 0.1666, 'grad_norm': 0.11839388310909271, 'learning_rate': 8.274723364810844e-05, 'epoch': 2.17}\n",
      "{'loss': 0.1612, 'grad_norm': 0.15337583422660828, 'learning_rate': 7.985053009674989e-05, 'epoch': 2.2}\n",
      "{'loss': 0.1639, 'grad_norm': 0.2055007815361023, 'learning_rate': 7.695382654539134e-05, 'epoch': 2.23}\n",
      "{'loss': 0.1623, 'grad_norm': 0.13200953602790833, 'learning_rate': 7.405712299403279e-05, 'epoch': 2.26}\n",
      "{'loss': 0.1638, 'grad_norm': 0.1409507840871811, 'learning_rate': 7.116041944267423e-05, 'epoch': 2.29}\n",
      "{'loss': 0.1619, 'grad_norm': 0.15658685564994812, 'learning_rate': 6.826371589131568e-05, 'epoch': 2.32}\n",
      "{'loss': 0.1619, 'grad_norm': 0.1291464865207672, 'learning_rate': 6.536701233995713e-05, 'epoch': 2.35}\n",
      "{'loss': 0.162, 'grad_norm': 0.15704958140850067, 'learning_rate': 6.247030878859856e-05, 'epoch': 2.38}\n",
      "{'loss': 0.1586, 'grad_norm': 0.15808796882629395, 'learning_rate': 5.957360523724002e-05, 'epoch': 2.4}\n",
      "{'loss': 0.1599, 'grad_norm': 0.10375279188156128, 'learning_rate': 5.667690168588146e-05, 'epoch': 2.43}\n",
      "{'loss': 0.1577, 'grad_norm': 0.19029079377651215, 'learning_rate': 5.3780198134522905e-05, 'epoch': 2.46}\n",
      "{'loss': 0.1599, 'grad_norm': 0.13976408541202545, 'learning_rate': 5.0883494583164354e-05, 'epoch': 2.49}\n",
      "{'loss': 0.1603, 'grad_norm': 0.2075130194425583, 'learning_rate': 4.7986791031805804e-05, 'epoch': 2.52}\n",
      "{'loss': 0.1606, 'grad_norm': 0.12486708909273148, 'learning_rate': 4.509008748044725e-05, 'epoch': 2.55}\n",
      "{'loss': 0.1577, 'grad_norm': 0.20161373913288116, 'learning_rate': 4.2193383929088697e-05, 'epoch': 2.58}\n",
      "{'loss': 0.1561, 'grad_norm': 0.12639252841472626, 'learning_rate': 3.929668037773013e-05, 'epoch': 2.61}\n",
      "{'loss': 0.162, 'grad_norm': 0.1343013048171997, 'learning_rate': 3.639997682637158e-05, 'epoch': 2.64}\n",
      "{'loss': 0.1608, 'grad_norm': 0.1224772110581398, 'learning_rate': 3.350327327501303e-05, 'epoch': 2.66}\n",
      "{'loss': 0.1586, 'grad_norm': 0.16602283716201782, 'learning_rate': 3.060656972365448e-05, 'epoch': 2.69}\n",
      "{'loss': 0.1603, 'grad_norm': 0.13062161207199097, 'learning_rate': 2.7709866172295925e-05, 'epoch': 2.72}\n",
      "{'loss': 0.1594, 'grad_norm': 0.18520332872867584, 'learning_rate': 2.481316262093737e-05, 'epoch': 2.75}\n",
      "{'loss': 0.1606, 'grad_norm': 0.21514829993247986, 'learning_rate': 2.191645906957882e-05, 'epoch': 2.78}\n",
      "{'loss': 0.1595, 'grad_norm': 0.14966285228729248, 'learning_rate': 1.9019755518220264e-05, 'epoch': 2.81}\n",
      "{'loss': 0.1617, 'grad_norm': 0.1444791555404663, 'learning_rate': 1.612305196686171e-05, 'epoch': 2.84}\n",
      "{'loss': 0.1603, 'grad_norm': 0.12736007571220398, 'learning_rate': 1.3226348415503156e-05, 'epoch': 2.87}\n",
      "{'loss': 0.1595, 'grad_norm': 0.158569797873497, 'learning_rate': 1.0329644864144602e-05, 'epoch': 2.9}\n",
      "{'loss': 0.1585, 'grad_norm': 0.16774699091911316, 'learning_rate': 7.432941312786049e-06, 'epoch': 2.93}\n",
      "{'loss': 0.1619, 'grad_norm': 0.19029484689235687, 'learning_rate': 4.536237761427495e-06, 'epoch': 2.95}\n",
      "{'loss': 0.1611, 'grad_norm': 0.11147435754537582, 'learning_rate': 1.6395342100689414e-06, 'epoch': 2.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/j/Desktop/MLotsawa/.venv/lib/python3.10/site-packages/transformers/generation/utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e02ecfaa224f448cee3bf7f8db4402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1523 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1302887201309204, 'eval_bleu': 5.4383, 'eval_gen_len': 16.0153, 'eval_runtime': 421.8028, 'eval_samples_per_second': 28.886, 'eval_steps_per_second': 3.611, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 10903.968, 'train_samples_per_second': 37.991, 'train_steps_per_second': 4.749, 'train_loss': 0.18972355383442457, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=51783, training_loss=0.18972355383442457, metrics={'train_runtime': 10903.968, 'train_samples_per_second': 37.991, 'train_steps_per_second': 4.749, 'total_flos': 3.28509444980736e+16, 'train_loss': 0.18972355383442457, 'epoch': 3.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"bidirectional\",\n",
    "    auto_find_batch_size=True,\n",
    "    predict_with_generate=True,\n",
    "    fp16=False, #check this\n",
    "    push_to_hub=False,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    num_train_epochs=3\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    optimizers=(optimizer, None),\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
