{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "75b58048-7d14-4fc6-8085-1fc08c81b4a6",
      "metadata": {
        "id": "75b58048-7d14-4fc6-8085-1fc08c81b4a6"
      },
      "source": [
        "# Fine-Tune Wav2Vec2\n",
        "\n",
        "Adapted from guide here: https://colab.research.google.com/drive/1FjTsqbYKphl9kL-eILgUc-bl4zVThL8F?usp=sharing#scrollTo=e7cqAWIayn6w"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ed937ca",
      "metadata": {},
      "source": [
        "## Create Tokenizer Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a2787582-554f-44ce-9f38-4180a5ed6b44",
      "metadata": {
        "id": "a2787582-554f-44ce-9f38-4180a5ed6b44"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e0784b5ff834716834c8714ecb5b957",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading dataset from disk:   0%|          | 0/34 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['file_name', 'uni', 'wylie', 'url', 'dept', 'grade', 'char_len', 'audio_len', '__index_level_0__', 'audio', 'transcript'],\n",
              "        num_rows: 67273\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['file_name', 'uni', 'wylie', 'url', 'dept', 'grade', 'char_len', 'audio_len', '__index_level_0__', 'audio', 'transcript'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['file_name', 'uni', 'wylie', 'url', 'dept', 'grade', 'char_len', 'audio_len', '__index_level_0__', 'audio', 'transcript'],\n",
              "        num_rows: 4000\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import load_from_disk\n",
        "\n",
        "dataset = load_from_disk(\"Data/kham_asr_dataset\")\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6314fe0b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f2e772b236d4bc793e57c693dfe9984",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/67273 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0f99c20159d48d397f6a1847d07d6b5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "24ac8294162a4dad8ae0e87e93044067",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def extract_all_chars(batch):\n",
        "  all_text = \" \".join(batch[\"uni\"])\n",
        "  vocab = list(set(all_text))\n",
        "  return {\"vocab\": [vocab], \"all_text\": [all_text]}\n",
        "\n",
        "vocabs = dataset.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=dataset.column_names[\"train\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b1883124",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{' ': 0,\n",
              " '\\x7f': 1,\n",
              " '་': 2,\n",
              " '།': 3,\n",
              " '༕': 4,\n",
              " 'ཀ': 5,\n",
              " 'ཁ': 6,\n",
              " 'ག': 7,\n",
              " 'གྷ': 8,\n",
              " 'ང': 9,\n",
              " 'ཅ': 10,\n",
              " 'ཆ': 11,\n",
              " 'ཇ': 12,\n",
              " 'ཉ': 13,\n",
              " 'ཊ': 14,\n",
              " 'ཋ': 15,\n",
              " 'ཌ': 16,\n",
              " 'ཎ': 17,\n",
              " 'ཏ': 18,\n",
              " 'ཐ': 19,\n",
              " 'ད': 20,\n",
              " 'ན': 21,\n",
              " 'པ': 22,\n",
              " 'ཕ': 23,\n",
              " 'བ': 24,\n",
              " 'བྷ': 25,\n",
              " 'མ': 26,\n",
              " 'ཙ': 27,\n",
              " 'ཚ': 28,\n",
              " 'ཛ': 29,\n",
              " 'ཝ': 30,\n",
              " 'ཞ': 31,\n",
              " 'ཟ': 32,\n",
              " 'འ': 33,\n",
              " 'ཡ': 34,\n",
              " 'ར': 35,\n",
              " 'ལ': 36,\n",
              " 'ཤ': 37,\n",
              " 'ཥ': 38,\n",
              " 'ས': 39,\n",
              " 'ཧ': 40,\n",
              " 'ཨ': 41,\n",
              " 'ཪ': 42,\n",
              " 'ཱ': 43,\n",
              " 'ི': 44,\n",
              " 'ུ': 45,\n",
              " 'ྲྀ': 46,\n",
              " 'ེ': 47,\n",
              " 'ོ': 48,\n",
              " 'ཾ': 49,\n",
              " 'ྀ': 50,\n",
              " 'ྃ': 51,\n",
              " 'ྐ': 52,\n",
              " 'ྒ': 53,\n",
              " 'ྔ': 54,\n",
              " 'ྕ': 55,\n",
              " 'ྗ': 56,\n",
              " 'ྙ': 57,\n",
              " 'ྜ': 58,\n",
              " 'ྞ': 59,\n",
              " 'ྟ': 60,\n",
              " 'ྠ': 61,\n",
              " 'ྡ': 62,\n",
              " 'ྣ': 63,\n",
              " 'ྤ': 64,\n",
              " 'ྥ': 65,\n",
              " 'ྦ': 66,\n",
              " 'ྨ': 67,\n",
              " 'ྩ': 68,\n",
              " 'ྫ': 69,\n",
              " 'ྭ': 70,\n",
              " 'ྰ': 71,\n",
              " 'ྱ': 72,\n",
              " 'ྲ': 73,\n",
              " 'ླ': 74,\n",
              " 'ྴ': 75,\n",
              " 'ྵ': 76,\n",
              " 'ྶ': 77,\n",
              " 'ྷ': 78}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_chars = sorted(set(vocabs[\"train\"][\"vocab\"][0] + vocabs[\"test\"][\"vocab\"][0]))\n",
        "vocab_dict = {char: idx for idx, char in enumerate(all_chars)}\n",
        "vocab_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c25f2493",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_dict[\"་\"] = vocab_dict[\" \"]\n",
        "del vocab_dict[\" \"]\n",
        "\n",
        "vocab_dict[\"[UNK]\"] = len(vocab_dict)\n",
        "vocab_dict[\"[PAD]\"] = len(vocab_dict)\n",
        "len(vocab_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "031c12ea",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "with open('vocab.json', 'w') as vocab_file:\n",
        "    json.dump(vocab_dict, vocab_file)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.12.7)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
