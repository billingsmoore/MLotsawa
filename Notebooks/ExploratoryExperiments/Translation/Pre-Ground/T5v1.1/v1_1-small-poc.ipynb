{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('openpecha/cleaned_MT_v1.0.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1429192"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Source': 'ཐུབ་པས་རྟག་ཏུ་དེ་བཞིན་སྤྱད།།',\n",
       " 'Target': 'The aspirant should move in such a way at all times.',\n",
       " 'File_Name': 'TM2382',\n",
       " 'Machine Aligned': True,\n",
       " '__index_level_0__': 0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Source': 'ཚད་མེད་བཏང་སྙོམས་གསུམ་ལས།',\n",
       " 'Target': '3. Immeasureable equanimity ',\n",
       " 'File_Name': 'TM2203',\n",
       " 'Machine Aligned': True,\n",
       " '__index_level_0__': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Tokenizer, Model, and Data Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorForSeq2Seq, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_id = \"google/t5-v1_1-small\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id, device_map=\"auto\")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32355, 512)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a list of all Tibetan Unicode characters (U+0F00 to U+0FFF)\n",
    "tibetan_chars = [chr(codepoint) for codepoint in range(0x0F00, 0x0FFF)]\n",
    "\n",
    "# Add the Tibetan characters to the tokenizer's vocabulary\n",
    "new_tokens = [char for char in tibetan_chars if char not in tokenizer.get_vocab()]\n",
    "\n",
    "# Add new tokens to the tokenizer\n",
    "tokenizer.add_tokens(new_tokens)\n",
    "\n",
    "# Resize model embeddings to accommodate the new vocabulary size\n",
    "model.resize_token_embeddings(len(tokenizer), mean_resizing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ཐུབ་པས་རྟག་ཏུ་དེ་བཞིན་སྤྱད།།</s>'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = tokenizer.encode(dataset['train'][0]['Source'])\n",
    "dec = tokenizer.decode(enc)\n",
    "dec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "\n",
    "The dataset can now be tokenized for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_lang = 'Source'\n",
    "target_lang = 'Target'\n",
    "\n",
    "def preprocess_function(examples):\n",
    "\n",
    "    inputs = [example for example in examples[source_lang]]\n",
    "    targets = [example for example in examples[target_lang]]\n",
    "    \n",
    "    model_inputs = tokenizer(inputs, text_target=targets, max_length=256, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3886ddc2290b437aaffd1282354d0ab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1429192 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6fb5af036dc44899de8c8b2aaf57872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, Adafactor\n",
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "\n",
    "optimizer = Adafactor(\n",
    "    model.parameters(), \n",
    "    scale_parameter=True, \n",
    "    relative_step=False, \n",
    "    warmup_init=False, \n",
    "    lr=3e-4\n",
    ")\n",
    "\n",
    "model, optimizer = accelerator.prepare(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4659/2336255047.py:14: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4123a6f2794d473da4b9125be49bfaac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178649 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1001, 'grad_norm': 1.1236166954040527, 'learning_rate': 0.000299160364737558, 'epoch': 0.0}\n",
      "{'loss': 1.107, 'grad_norm': 0.4474409222602844, 'learning_rate': 0.000298320729475116, 'epoch': 0.01}\n",
      "{'loss': 1.1037, 'grad_norm': 0.45653262734413147, 'learning_rate': 0.000297481094212674, 'epoch': 0.01}\n",
      "{'loss': 1.1049, 'grad_norm': 0.4536183774471283, 'learning_rate': 0.000296641458950232, 'epoch': 0.01}\n",
      "{'loss': 1.063, 'grad_norm': 0.2168353646993637, 'learning_rate': 0.00029580182368779, 'epoch': 0.01}\n",
      "{'loss': 1.0191, 'grad_norm': 0.4735202193260193, 'learning_rate': 0.000294962188425348, 'epoch': 0.02}\n",
      "{'loss': 1.056, 'grad_norm': 0.3177906274795532, 'learning_rate': 0.000294122553162906, 'epoch': 0.02}\n",
      "{'loss': 1.053, 'grad_norm': 0.4990245997905731, 'learning_rate': 0.000293282917900464, 'epoch': 0.02}\n",
      "{'loss': 0.9733, 'grad_norm': 0.3776359558105469, 'learning_rate': 0.000292443282638022, 'epoch': 0.03}\n",
      "{'loss': 1.0178, 'grad_norm': 0.24495179951190948, 'learning_rate': 0.00029160364737558004, 'epoch': 0.03}\n",
      "{'loss': 1.0407, 'grad_norm': 0.38252687454223633, 'learning_rate': 0.000290764012113138, 'epoch': 0.03}\n",
      "{'loss': 1.0102, 'grad_norm': 0.5247417092323303, 'learning_rate': 0.00028992437685069605, 'epoch': 0.03}\n",
      "{'loss': 1.0126, 'grad_norm': 0.2122243195772171, 'learning_rate': 0.000289084741588254, 'epoch': 0.04}\n",
      "{'loss': 0.9983, 'grad_norm': 0.3350665271282196, 'learning_rate': 0.00028824510632581205, 'epoch': 0.04}\n",
      "{'loss': 0.9671, 'grad_norm': 0.46187472343444824, 'learning_rate': 0.00028740547106337, 'epoch': 0.04}\n",
      "{'loss': 0.9731, 'grad_norm': 0.419545978307724, 'learning_rate': 0.00028656583580092805, 'epoch': 0.04}\n",
      "{'loss': 0.9858, 'grad_norm': 0.5591886639595032, 'learning_rate': 0.0002857262005384861, 'epoch': 0.05}\n",
      "{'loss': 0.9984, 'grad_norm': 0.5038840770721436, 'learning_rate': 0.00028488656527604405, 'epoch': 0.05}\n",
      "{'loss': 0.9766, 'grad_norm': 0.48767977952957153, 'learning_rate': 0.0002840469300136021, 'epoch': 0.05}\n",
      "{'loss': 0.9783, 'grad_norm': 0.3011976182460785, 'learning_rate': 0.0002832072947511601, 'epoch': 0.06}\n",
      "{'loss': 0.9579, 'grad_norm': 0.4312812089920044, 'learning_rate': 0.0002823676594887181, 'epoch': 0.06}\n",
      "{'loss': 0.9761, 'grad_norm': 0.4499143958091736, 'learning_rate': 0.00028152802422627606, 'epoch': 0.06}\n",
      "{'loss': 0.9671, 'grad_norm': 0.323518842458725, 'learning_rate': 0.0002806883889638341, 'epoch': 0.06}\n",
      "{'loss': 0.9679, 'grad_norm': 0.38955676555633545, 'learning_rate': 0.00027984875370139206, 'epoch': 0.07}\n",
      "{'loss': 1.0004, 'grad_norm': 0.40769293904304504, 'learning_rate': 0.0002790091184389501, 'epoch': 0.07}\n",
      "{'loss': 0.9452, 'grad_norm': 0.2363991141319275, 'learning_rate': 0.0002781694831765081, 'epoch': 0.07}\n",
      "{'loss': 0.9494, 'grad_norm': 0.4373152256011963, 'learning_rate': 0.0002773298479140661, 'epoch': 0.08}\n",
      "{'loss': 0.9273, 'grad_norm': 0.21227611601352692, 'learning_rate': 0.0002764902126516241, 'epoch': 0.08}\n",
      "{'loss': 0.9371, 'grad_norm': 0.39982831478118896, 'learning_rate': 0.00027565057738918215, 'epoch': 0.08}\n",
      "{'loss': 0.9556, 'grad_norm': 0.4441312551498413, 'learning_rate': 0.0002748109421267401, 'epoch': 0.08}\n",
      "{'loss': 0.9361, 'grad_norm': 0.3811992108821869, 'learning_rate': 0.0002739713068642981, 'epoch': 0.09}\n",
      "{'loss': 0.9654, 'grad_norm': 0.39904555678367615, 'learning_rate': 0.00027313167160185613, 'epoch': 0.09}\n",
      "{'loss': 0.9146, 'grad_norm': 0.18641409277915955, 'learning_rate': 0.0002722920363394141, 'epoch': 0.09}\n",
      "{'loss': 0.9574, 'grad_norm': 0.250306099653244, 'learning_rate': 0.00027145240107697213, 'epoch': 0.1}\n",
      "{'loss': 0.9349, 'grad_norm': 0.338822603225708, 'learning_rate': 0.00027061276581453016, 'epoch': 0.1}\n",
      "{'loss': 0.9274, 'grad_norm': 0.25389739871025085, 'learning_rate': 0.00026977313055208814, 'epoch': 0.1}\n",
      "{'loss': 0.9299, 'grad_norm': 0.4777078330516815, 'learning_rate': 0.00026893349528964616, 'epoch': 0.1}\n",
      "{'loss': 0.9297, 'grad_norm': 0.33656230568885803, 'learning_rate': 0.00026809386002720414, 'epoch': 0.11}\n",
      "{'loss': 0.8987, 'grad_norm': 0.2642640173435211, 'learning_rate': 0.00026725422476476217, 'epoch': 0.11}\n",
      "{'loss': 0.9036, 'grad_norm': 0.3966217041015625, 'learning_rate': 0.00026641458950232014, 'epoch': 0.11}\n",
      "{'loss': 0.9028, 'grad_norm': 0.2039964646100998, 'learning_rate': 0.00026557495423987817, 'epoch': 0.11}\n",
      "{'loss': 0.92, 'grad_norm': 0.4365159571170807, 'learning_rate': 0.0002647353189774362, 'epoch': 0.12}\n",
      "{'loss': 0.9352, 'grad_norm': 0.29686760902404785, 'learning_rate': 0.0002638956837149942, 'epoch': 0.12}\n",
      "{'loss': 0.9335, 'grad_norm': 0.1955755203962326, 'learning_rate': 0.0002630560484525522, 'epoch': 0.12}\n",
      "{'loss': 0.9145, 'grad_norm': 0.338667631149292, 'learning_rate': 0.00026221641319011023, 'epoch': 0.13}\n",
      "{'loss': 0.9678, 'grad_norm': 0.2828401029109955, 'learning_rate': 0.0002613767779276682, 'epoch': 0.13}\n",
      "{'loss': 0.9385, 'grad_norm': 0.39258259534835815, 'learning_rate': 0.0002605371426652262, 'epoch': 0.13}\n",
      "{'loss': 0.9221, 'grad_norm': 0.31460461020469666, 'learning_rate': 0.0002596975074027842, 'epoch': 0.13}\n",
      "{'loss': 0.9384, 'grad_norm': 0.553049623966217, 'learning_rate': 0.0002588578721403422, 'epoch': 0.14}\n",
      "{'loss': 0.8944, 'grad_norm': 0.4082223176956177, 'learning_rate': 0.0002580182368779002, 'epoch': 0.14}\n",
      "{'loss': 0.9324, 'grad_norm': 0.35653552412986755, 'learning_rate': 0.00025717860161545824, 'epoch': 0.14}\n",
      "{'loss': 0.9058, 'grad_norm': 0.23028546571731567, 'learning_rate': 0.0002563389663530162, 'epoch': 0.15}\n",
      "{'loss': 0.9146, 'grad_norm': 0.49761030077934265, 'learning_rate': 0.00025549933109057424, 'epoch': 0.15}\n",
      "{'loss': 0.917, 'grad_norm': 0.3146977722644806, 'learning_rate': 0.00025465969582813227, 'epoch': 0.15}\n",
      "{'loss': 0.934, 'grad_norm': 0.4324358105659485, 'learning_rate': 0.00025382006056569025, 'epoch': 0.15}\n",
      "{'loss': 0.8879, 'grad_norm': 0.34558072686195374, 'learning_rate': 0.0002529804253032482, 'epoch': 0.16}\n",
      "{'loss': 0.9021, 'grad_norm': 0.17692086100578308, 'learning_rate': 0.00025214079004080625, 'epoch': 0.16}\n",
      "{'loss': 0.9304, 'grad_norm': 0.2822573184967041, 'learning_rate': 0.0002513011547783642, 'epoch': 0.16}\n",
      "{'loss': 0.9311, 'grad_norm': 0.25254541635513306, 'learning_rate': 0.00025046151951592225, 'epoch': 0.17}\n",
      "{'loss': 0.8899, 'grad_norm': 0.5408682227134705, 'learning_rate': 0.0002496218842534803, 'epoch': 0.17}\n",
      "{'loss': 0.9038, 'grad_norm': 0.27381572127342224, 'learning_rate': 0.00024878224899103825, 'epoch': 0.17}\n",
      "{'loss': 0.9257, 'grad_norm': 0.32922154664993286, 'learning_rate': 0.0002479426137285963, 'epoch': 0.17}\n",
      "{'loss': 0.9175, 'grad_norm': 0.37475264072418213, 'learning_rate': 0.0002471029784661543, 'epoch': 0.18}\n",
      "{'loss': 0.8973, 'grad_norm': 0.3009214699268341, 'learning_rate': 0.0002462633432037123, 'epoch': 0.18}\n",
      "{'loss': 0.8953, 'grad_norm': 0.3333212435245514, 'learning_rate': 0.00024542370794127026, 'epoch': 0.18}\n",
      "{'loss': 0.8344, 'grad_norm': 0.330023854970932, 'learning_rate': 0.0002445840726788283, 'epoch': 0.18}\n",
      "{'loss': 0.874, 'grad_norm': 0.3179131746292114, 'learning_rate': 0.0002437444374163863, 'epoch': 0.19}\n",
      "{'loss': 0.9072, 'grad_norm': 0.3975506126880646, 'learning_rate': 0.0002429048021539443, 'epoch': 0.19}\n",
      "{'loss': 0.9121, 'grad_norm': 0.1517956405878067, 'learning_rate': 0.00024206516689150232, 'epoch': 0.19}\n",
      "{'loss': 0.8731, 'grad_norm': 0.23342159390449524, 'learning_rate': 0.00024122553162906032, 'epoch': 0.2}\n",
      "{'loss': 0.8794, 'grad_norm': 0.3886822462081909, 'learning_rate': 0.00024038589636661832, 'epoch': 0.2}\n",
      "{'loss': 0.8941, 'grad_norm': 0.31867584586143494, 'learning_rate': 0.00023954626110417633, 'epoch': 0.2}\n",
      "{'loss': 0.9261, 'grad_norm': 0.19614560902118683, 'learning_rate': 0.00023870662584173435, 'epoch': 0.2}\n",
      "{'loss': 0.8819, 'grad_norm': 0.3230873942375183, 'learning_rate': 0.00023786699057929233, 'epoch': 0.21}\n",
      "{'loss': 0.8969, 'grad_norm': 0.22484523057937622, 'learning_rate': 0.00023702735531685033, 'epoch': 0.21}\n",
      "{'loss': 0.8746, 'grad_norm': 0.3725186288356781, 'learning_rate': 0.00023618772005440836, 'epoch': 0.21}\n",
      "{'loss': 0.892, 'grad_norm': 0.24147820472717285, 'learning_rate': 0.00023534808479196633, 'epoch': 0.22}\n",
      "{'loss': 0.866, 'grad_norm': 0.34720513224601746, 'learning_rate': 0.00023450844952952436, 'epoch': 0.22}\n",
      "{'loss': 0.8813, 'grad_norm': 0.5225441455841064, 'learning_rate': 0.00023366881426708236, 'epoch': 0.22}\n",
      "{'loss': 0.8524, 'grad_norm': 0.35304462909698486, 'learning_rate': 0.00023282917900464036, 'epoch': 0.22}\n",
      "{'loss': 0.8923, 'grad_norm': 0.3113939166069031, 'learning_rate': 0.00023198954374219837, 'epoch': 0.23}\n",
      "{'loss': 0.9037, 'grad_norm': 0.23151730000972748, 'learning_rate': 0.0002311499084797564, 'epoch': 0.23}\n",
      "{'loss': 0.875, 'grad_norm': 0.4144454300403595, 'learning_rate': 0.00023031027321731437, 'epoch': 0.23}\n",
      "{'loss': 0.8991, 'grad_norm': 0.37744465470314026, 'learning_rate': 0.00022947063795487237, 'epoch': 0.24}\n",
      "{'loss': 0.8845, 'grad_norm': 0.4983863830566406, 'learning_rate': 0.0002286310026924304, 'epoch': 0.24}\n",
      "{'loss': 0.8865, 'grad_norm': 0.4170891344547272, 'learning_rate': 0.00022779136742998837, 'epoch': 0.24}\n",
      "{'loss': 0.8749, 'grad_norm': 0.33466479182243347, 'learning_rate': 0.0002269517321675464, 'epoch': 0.24}\n",
      "{'loss': 0.8904, 'grad_norm': 0.28151124715805054, 'learning_rate': 0.0002261120969051044, 'epoch': 0.25}\n",
      "{'loss': 0.8658, 'grad_norm': 0.4972790777683258, 'learning_rate': 0.0002252724616426624, 'epoch': 0.25}\n",
      "{'loss': 0.8558, 'grad_norm': 0.3489723801612854, 'learning_rate': 0.0002244328263802204, 'epoch': 0.25}\n",
      "{'loss': 0.8661, 'grad_norm': 0.4752437174320221, 'learning_rate': 0.00022359319111777843, 'epoch': 0.25}\n",
      "{'loss': 0.8654, 'grad_norm': 0.4241248071193695, 'learning_rate': 0.0002227535558553364, 'epoch': 0.26}\n",
      "{'loss': 0.8581, 'grad_norm': 0.375938355922699, 'learning_rate': 0.0002219139205928944, 'epoch': 0.26}\n",
      "{'loss': 0.864, 'grad_norm': 0.31089287996292114, 'learning_rate': 0.00022107428533045244, 'epoch': 0.26}\n",
      "{'loss': 0.8862, 'grad_norm': 0.4385814964771271, 'learning_rate': 0.00022023465006801041, 'epoch': 0.27}\n",
      "{'loss': 0.8927, 'grad_norm': 0.39403215050697327, 'learning_rate': 0.00021939501480556844, 'epoch': 0.27}\n",
      "{'loss': 0.901, 'grad_norm': 0.3502132296562195, 'learning_rate': 0.00021855537954312644, 'epoch': 0.27}\n",
      "{'loss': 0.8789, 'grad_norm': 0.19655661284923553, 'learning_rate': 0.00021771574428068447, 'epoch': 0.27}\n",
      "{'loss': 0.8644, 'grad_norm': 0.502360999584198, 'learning_rate': 0.00021687610901824245, 'epoch': 0.28}\n",
      "{'loss': 0.8729, 'grad_norm': 0.3069070279598236, 'learning_rate': 0.00021603647375580048, 'epoch': 0.28}\n",
      "{'loss': 0.8552, 'grad_norm': 0.3718395531177521, 'learning_rate': 0.00021519683849335848, 'epoch': 0.28}\n",
      "{'loss': 0.8356, 'grad_norm': 0.47668129205703735, 'learning_rate': 0.00021435720323091645, 'epoch': 0.29}\n",
      "{'loss': 0.8458, 'grad_norm': 0.2056594043970108, 'learning_rate': 0.00021351756796847448, 'epoch': 0.29}\n",
      "{'loss': 0.8671, 'grad_norm': 0.4620639681816101, 'learning_rate': 0.00021267793270603248, 'epoch': 0.29}\n",
      "{'loss': 0.852, 'grad_norm': 0.6046159863471985, 'learning_rate': 0.00021183829744359048, 'epoch': 0.29}\n",
      "{'loss': 0.8885, 'grad_norm': 0.566375195980072, 'learning_rate': 0.00021099866218114848, 'epoch': 0.3}\n",
      "{'loss': 0.8715, 'grad_norm': 0.32634302973747253, 'learning_rate': 0.0002101590269187065, 'epoch': 0.3}\n",
      "{'loss': 0.8393, 'grad_norm': 0.2280171513557434, 'learning_rate': 0.0002093193916562645, 'epoch': 0.3}\n",
      "{'loss': 0.8562, 'grad_norm': 0.31591084599494934, 'learning_rate': 0.00020847975639382252, 'epoch': 0.31}\n",
      "{'loss': 0.8536, 'grad_norm': 0.24812085926532745, 'learning_rate': 0.00020764012113138052, 'epoch': 0.31}\n",
      "{'loss': 0.8748, 'grad_norm': 0.5562400817871094, 'learning_rate': 0.0002068004858689385, 'epoch': 0.31}\n",
      "{'loss': 0.8587, 'grad_norm': 0.4761257767677307, 'learning_rate': 0.00020596085060649652, 'epoch': 0.31}\n",
      "{'loss': 0.8883, 'grad_norm': 0.3880158066749573, 'learning_rate': 0.00020512121534405452, 'epoch': 0.32}\n",
      "{'loss': 0.8354, 'grad_norm': 0.3126160800457001, 'learning_rate': 0.00020428158008161252, 'epoch': 0.32}\n",
      "{'loss': 0.8423, 'grad_norm': 0.26229390501976013, 'learning_rate': 0.00020344194481917053, 'epoch': 0.32}\n",
      "{'loss': 0.8569, 'grad_norm': 0.4495408236980438, 'learning_rate': 0.00020260230955672855, 'epoch': 0.32}\n",
      "{'loss': 0.8683, 'grad_norm': 0.19553667306900024, 'learning_rate': 0.00020176267429428653, 'epoch': 0.33}\n",
      "{'loss': 0.8657, 'grad_norm': 0.2500152289867401, 'learning_rate': 0.00020092303903184456, 'epoch': 0.33}\n",
      "{'loss': 0.8439, 'grad_norm': 0.23564471304416656, 'learning_rate': 0.00020008340376940256, 'epoch': 0.33}\n",
      "{'loss': 0.8566, 'grad_norm': 0.4414602220058441, 'learning_rate': 0.00019924376850696053, 'epoch': 0.34}\n",
      "{'loss': 0.8357, 'grad_norm': 0.5030151605606079, 'learning_rate': 0.00019840413324451856, 'epoch': 0.34}\n",
      "{'loss': 0.8863, 'grad_norm': 0.4529078006744385, 'learning_rate': 0.00019756449798207656, 'epoch': 0.34}\n",
      "{'loss': 0.879, 'grad_norm': 0.24929513037204742, 'learning_rate': 0.00019672486271963456, 'epoch': 0.34}\n",
      "{'loss': 0.8527, 'grad_norm': 0.33521610498428345, 'learning_rate': 0.00019588522745719257, 'epoch': 0.35}\n",
      "{'loss': 0.8663, 'grad_norm': 0.34755638241767883, 'learning_rate': 0.0001950455921947506, 'epoch': 0.35}\n",
      "{'loss': 0.8366, 'grad_norm': 0.21750731766223907, 'learning_rate': 0.0001942059569323086, 'epoch': 0.35}\n",
      "{'loss': 0.8424, 'grad_norm': 0.4137304425239563, 'learning_rate': 0.0001933663216698666, 'epoch': 0.36}\n",
      "{'loss': 0.8527, 'grad_norm': 0.36237961053848267, 'learning_rate': 0.0001925266864074246, 'epoch': 0.36}\n",
      "{'loss': 0.8413, 'grad_norm': 0.4346396327018738, 'learning_rate': 0.00019168705114498263, 'epoch': 0.36}\n",
      "{'loss': 0.8575, 'grad_norm': 0.4472862482070923, 'learning_rate': 0.0001908474158825406, 'epoch': 0.36}\n",
      "{'loss': 0.8518, 'grad_norm': 0.38812828063964844, 'learning_rate': 0.0001900077806200986, 'epoch': 0.37}\n",
      "{'loss': 0.8559, 'grad_norm': 0.2720288634300232, 'learning_rate': 0.00018916814535765663, 'epoch': 0.37}\n",
      "{'loss': 0.8748, 'grad_norm': 0.43961063027381897, 'learning_rate': 0.0001883285100952146, 'epoch': 0.37}\n",
      "{'loss': 0.8451, 'grad_norm': 0.47161757946014404, 'learning_rate': 0.00018748887483277263, 'epoch': 0.38}\n",
      "{'loss': 0.8292, 'grad_norm': 0.4589960277080536, 'learning_rate': 0.00018664923957033064, 'epoch': 0.38}\n",
      "{'loss': 0.8603, 'grad_norm': 0.3674686551094055, 'learning_rate': 0.00018580960430788864, 'epoch': 0.38}\n",
      "{'loss': 0.851, 'grad_norm': 0.2540165185928345, 'learning_rate': 0.00018496996904544664, 'epoch': 0.38}\n",
      "{'loss': 0.8469, 'grad_norm': 0.30898720026016235, 'learning_rate': 0.00018413033378300467, 'epoch': 0.39}\n",
      "{'loss': 0.8449, 'grad_norm': 0.22367337346076965, 'learning_rate': 0.00018329069852056264, 'epoch': 0.39}\n",
      "{'loss': 0.8597, 'grad_norm': 0.4406776428222656, 'learning_rate': 0.00018245106325812064, 'epoch': 0.39}\n",
      "{'loss': 0.8589, 'grad_norm': 0.21408449113368988, 'learning_rate': 0.00018161142799567867, 'epoch': 0.39}\n",
      "{'loss': 0.838, 'grad_norm': 0.44553712010383606, 'learning_rate': 0.00018077179273323665, 'epoch': 0.4}\n",
      "{'loss': 0.8594, 'grad_norm': 0.16914460062980652, 'learning_rate': 0.00017993215747079468, 'epoch': 0.4}\n",
      "{'loss': 0.8767, 'grad_norm': 0.38544633984565735, 'learning_rate': 0.00017909252220835268, 'epoch': 0.4}\n",
      "{'loss': 0.8558, 'grad_norm': 0.29233911633491516, 'learning_rate': 0.00017825288694591068, 'epoch': 0.41}\n",
      "{'loss': 0.8515, 'grad_norm': 0.4536295235157013, 'learning_rate': 0.00017741325168346868, 'epoch': 0.41}\n",
      "{'loss': 0.8648, 'grad_norm': 0.4916091859340668, 'learning_rate': 0.0001765736164210267, 'epoch': 0.41}\n",
      "{'loss': 0.8624, 'grad_norm': 0.19732244312763214, 'learning_rate': 0.00017573398115858468, 'epoch': 0.41}\n",
      "{'loss': 0.8492, 'grad_norm': 0.2236565798521042, 'learning_rate': 0.00017489434589614268, 'epoch': 0.42}\n",
      "{'loss': 0.8428, 'grad_norm': 0.35094311833381653, 'learning_rate': 0.0001740547106337007, 'epoch': 0.42}\n",
      "{'loss': 0.8318, 'grad_norm': 0.2554991841316223, 'learning_rate': 0.0001732150753712587, 'epoch': 0.42}\n",
      "{'loss': 0.8352, 'grad_norm': 0.3753984570503235, 'learning_rate': 0.00017237544010881672, 'epoch': 0.43}\n",
      "{'loss': 0.8374, 'grad_norm': 0.23962102830410004, 'learning_rate': 0.00017153580484637472, 'epoch': 0.43}\n",
      "{'loss': 0.8287, 'grad_norm': 0.3172823488712311, 'learning_rate': 0.00017069616958393275, 'epoch': 0.43}\n",
      "{'loss': 0.8346, 'grad_norm': 0.5069175362586975, 'learning_rate': 0.00016985653432149072, 'epoch': 0.43}\n",
      "{'loss': 0.8204, 'grad_norm': 0.528892993927002, 'learning_rate': 0.00016901689905904875, 'epoch': 0.44}\n",
      "{'loss': 0.8669, 'grad_norm': 0.5210959911346436, 'learning_rate': 0.00016817726379660675, 'epoch': 0.44}\n",
      "{'loss': 0.8695, 'grad_norm': 0.23015931248664856, 'learning_rate': 0.00016733762853416472, 'epoch': 0.44}\n",
      "{'loss': 0.8597, 'grad_norm': 0.48234596848487854, 'learning_rate': 0.00016649799327172275, 'epoch': 0.45}\n",
      "{'loss': 0.8565, 'grad_norm': 0.36222562193870544, 'learning_rate': 0.00016565835800928075, 'epoch': 0.45}\n",
      "{'loss': 0.852, 'grad_norm': 0.5919095277786255, 'learning_rate': 0.00016481872274683876, 'epoch': 0.45}\n",
      "{'loss': 0.8195, 'grad_norm': 0.21894045174121857, 'learning_rate': 0.00016397908748439676, 'epoch': 0.45}\n",
      "{'loss': 0.8467, 'grad_norm': 0.2566275894641876, 'learning_rate': 0.0001631394522219548, 'epoch': 0.46}\n",
      "{'loss': 0.8494, 'grad_norm': 0.39508679509162903, 'learning_rate': 0.00016229981695951276, 'epoch': 0.46}\n",
      "{'loss': 0.8312, 'grad_norm': 0.33269140124320984, 'learning_rate': 0.0001614601816970708, 'epoch': 0.46}\n",
      "{'loss': 0.8579, 'grad_norm': 0.5053675174713135, 'learning_rate': 0.0001606205464346288, 'epoch': 0.46}\n",
      "{'loss': 0.8318, 'grad_norm': 0.4754739999771118, 'learning_rate': 0.00015978091117218677, 'epoch': 0.47}\n",
      "{'loss': 0.8392, 'grad_norm': 0.5451395511627197, 'learning_rate': 0.0001589412759097448, 'epoch': 0.47}\n",
      "{'loss': 0.8499, 'grad_norm': 0.3912610411643982, 'learning_rate': 0.0001581016406473028, 'epoch': 0.47}\n",
      "{'loss': 0.8263, 'grad_norm': 0.2741411030292511, 'learning_rate': 0.0001572620053848608, 'epoch': 0.48}\n",
      "{'loss': 0.816, 'grad_norm': 0.3004300594329834, 'learning_rate': 0.0001564223701224188, 'epoch': 0.48}\n",
      "{'loss': 0.8272, 'grad_norm': 0.25866612792015076, 'learning_rate': 0.00015558273485997683, 'epoch': 0.48}\n",
      "{'loss': 0.8627, 'grad_norm': 0.3472806215286255, 'learning_rate': 0.0001547430995975348, 'epoch': 0.48}\n",
      "{'loss': 0.8561, 'grad_norm': 0.2538587152957916, 'learning_rate': 0.00015390346433509283, 'epoch': 0.49}\n",
      "{'loss': 0.8405, 'grad_norm': 0.3596767783164978, 'learning_rate': 0.00015306382907265083, 'epoch': 0.49}\n",
      "{'loss': 0.8256, 'grad_norm': 0.4424075186252594, 'learning_rate': 0.0001522241938102088, 'epoch': 0.49}\n",
      "{'loss': 0.839, 'grad_norm': 0.39395633339881897, 'learning_rate': 0.00015138455854776683, 'epoch': 0.5}\n",
      "{'loss': 0.8479, 'grad_norm': 0.2197851538658142, 'learning_rate': 0.00015054492328532484, 'epoch': 0.5}\n",
      "{'loss': 0.8244, 'grad_norm': 0.32048851251602173, 'learning_rate': 0.00014970528802288284, 'epoch': 0.5}\n",
      "{'loss': 0.8177, 'grad_norm': 0.6030690670013428, 'learning_rate': 0.00014886565276044084, 'epoch': 0.5}\n",
      "{'loss': 0.8282, 'grad_norm': 0.2837645709514618, 'learning_rate': 0.00014802601749799887, 'epoch': 0.51}\n",
      "{'loss': 0.8338, 'grad_norm': 0.20671801269054413, 'learning_rate': 0.00014718638223555687, 'epoch': 0.51}\n",
      "{'loss': 0.8269, 'grad_norm': 0.24431605637073517, 'learning_rate': 0.00014634674697311487, 'epoch': 0.51}\n",
      "{'loss': 0.8417, 'grad_norm': 0.32656675577163696, 'learning_rate': 0.00014550711171067287, 'epoch': 0.51}\n",
      "{'loss': 0.8333, 'grad_norm': 0.35931408405303955, 'learning_rate': 0.00014466747644823087, 'epoch': 0.52}\n",
      "{'loss': 0.8237, 'grad_norm': 0.21927109360694885, 'learning_rate': 0.00014382784118578888, 'epoch': 0.52}\n",
      "{'loss': 0.8327, 'grad_norm': 0.37416160106658936, 'learning_rate': 0.00014298820592334688, 'epoch': 0.52}\n",
      "{'loss': 0.8635, 'grad_norm': 0.33395087718963623, 'learning_rate': 0.00014214857066090488, 'epoch': 0.53}\n",
      "{'loss': 0.864, 'grad_norm': 0.26006802916526794, 'learning_rate': 0.0001413089353984629, 'epoch': 0.53}\n",
      "{'loss': 0.8373, 'grad_norm': 0.4530986547470093, 'learning_rate': 0.0001404693001360209, 'epoch': 0.53}\n",
      "{'loss': 0.8435, 'grad_norm': 0.4084303081035614, 'learning_rate': 0.0001396296648735789, 'epoch': 0.53}\n",
      "{'loss': 0.7987, 'grad_norm': 0.33312296867370605, 'learning_rate': 0.0001387900296111369, 'epoch': 0.54}\n",
      "{'loss': 0.8284, 'grad_norm': 0.31554916501045227, 'learning_rate': 0.0001379503943486949, 'epoch': 0.54}\n",
      "{'loss': 0.8588, 'grad_norm': 0.3165903091430664, 'learning_rate': 0.00013711075908625291, 'epoch': 0.54}\n",
      "{'loss': 0.8246, 'grad_norm': 0.4717217981815338, 'learning_rate': 0.00013627112382381094, 'epoch': 0.55}\n",
      "{'loss': 0.8661, 'grad_norm': 0.32211804389953613, 'learning_rate': 0.00013543148856136892, 'epoch': 0.55}\n",
      "{'loss': 0.8268, 'grad_norm': 0.34488624334335327, 'learning_rate': 0.00013459185329892692, 'epoch': 0.55}\n",
      "{'loss': 0.833, 'grad_norm': 0.3135981857776642, 'learning_rate': 0.00013375221803648495, 'epoch': 0.55}\n",
      "{'loss': 0.8393, 'grad_norm': 0.43344205617904663, 'learning_rate': 0.00013291258277404295, 'epoch': 0.56}\n",
      "{'loss': 0.8366, 'grad_norm': 0.34607556462287903, 'learning_rate': 0.00013207294751160095, 'epoch': 0.56}\n",
      "{'loss': 0.8222, 'grad_norm': 0.34947970509529114, 'learning_rate': 0.00013123331224915895, 'epoch': 0.56}\n",
      "{'loss': 0.8241, 'grad_norm': 0.23387154936790466, 'learning_rate': 0.00013039367698671695, 'epoch': 0.57}\n",
      "{'loss': 0.7986, 'grad_norm': 0.18940693140029907, 'learning_rate': 0.00012955404172427498, 'epoch': 0.57}\n",
      "{'loss': 0.8145, 'grad_norm': 0.32781487703323364, 'learning_rate': 0.00012871440646183296, 'epoch': 0.57}\n",
      "{'loss': 0.8364, 'grad_norm': 0.4459607005119324, 'learning_rate': 0.00012787477119939096, 'epoch': 0.57}\n",
      "{'loss': 0.8586, 'grad_norm': 0.43564361333847046, 'learning_rate': 0.00012703513593694899, 'epoch': 0.58}\n",
      "{'loss': 0.8379, 'grad_norm': 0.5137467384338379, 'learning_rate': 0.000126195500674507, 'epoch': 0.58}\n",
      "{'loss': 0.8479, 'grad_norm': 0.3427852690219879, 'learning_rate': 0.000125355865412065, 'epoch': 0.58}\n",
      "{'loss': 0.8469, 'grad_norm': 0.4830358326435089, 'learning_rate': 0.000124516230149623, 'epoch': 0.58}\n",
      "{'loss': 0.8336, 'grad_norm': 0.2875838279724121, 'learning_rate': 0.000123676594887181, 'epoch': 0.59}\n",
      "{'loss': 0.8431, 'grad_norm': 0.6385254263877869, 'learning_rate': 0.000122836959624739, 'epoch': 0.59}\n",
      "{'loss': 0.8356, 'grad_norm': 0.27820295095443726, 'learning_rate': 0.00012199732436229701, 'epoch': 0.59}\n",
      "{'loss': 0.8526, 'grad_norm': 0.32794106006622314, 'learning_rate': 0.00012115768909985501, 'epoch': 0.6}\n",
      "{'loss': 0.8289, 'grad_norm': 0.27024737000465393, 'learning_rate': 0.00012031805383741303, 'epoch': 0.6}\n",
      "{'loss': 0.8259, 'grad_norm': 0.36396610736846924, 'learning_rate': 0.00011947841857497103, 'epoch': 0.6}\n",
      "{'loss': 0.8406, 'grad_norm': 0.3605061173439026, 'learning_rate': 0.00011863878331252903, 'epoch': 0.6}\n",
      "{'loss': 0.8458, 'grad_norm': 0.3375343978404999, 'learning_rate': 0.00011779914805008704, 'epoch': 0.61}\n",
      "{'loss': 0.8124, 'grad_norm': 0.6017730832099915, 'learning_rate': 0.00011695951278764503, 'epoch': 0.61}\n",
      "{'loss': 0.8376, 'grad_norm': 0.4420933723449707, 'learning_rate': 0.00011611987752520303, 'epoch': 0.61}\n",
      "{'loss': 0.8171, 'grad_norm': 0.38526472449302673, 'learning_rate': 0.00011528024226276105, 'epoch': 0.62}\n",
      "{'loss': 0.8492, 'grad_norm': 0.35786372423171997, 'learning_rate': 0.00011444060700031905, 'epoch': 0.62}\n",
      "{'loss': 0.8235, 'grad_norm': 0.526121199131012, 'learning_rate': 0.00011360097173787705, 'epoch': 0.62}\n",
      "{'loss': 0.8193, 'grad_norm': 0.22798864543437958, 'learning_rate': 0.00011276133647543507, 'epoch': 0.62}\n",
      "{'loss': 0.854, 'grad_norm': 0.33390042185783386, 'learning_rate': 0.00011192170121299307, 'epoch': 0.63}\n",
      "{'loss': 0.7939, 'grad_norm': 0.3573867976665497, 'learning_rate': 0.00011108206595055107, 'epoch': 0.63}\n",
      "{'loss': 0.7981, 'grad_norm': 0.2029777467250824, 'learning_rate': 0.00011024243068810908, 'epoch': 0.63}\n",
      "{'loss': 0.854, 'grad_norm': 0.31392714381217957, 'learning_rate': 0.00010940279542566707, 'epoch': 0.64}\n",
      "{'loss': 0.8218, 'grad_norm': 0.34168216586112976, 'learning_rate': 0.00010856316016322509, 'epoch': 0.64}\n",
      "{'loss': 0.8204, 'grad_norm': 0.2995254099369049, 'learning_rate': 0.00010772352490078309, 'epoch': 0.64}\n",
      "{'loss': 0.8219, 'grad_norm': 0.29924580454826355, 'learning_rate': 0.00010688388963834109, 'epoch': 0.64}\n",
      "{'loss': 0.8451, 'grad_norm': 0.39960095286369324, 'learning_rate': 0.0001060442543758991, 'epoch': 0.65}\n",
      "{'loss': 0.8384, 'grad_norm': 0.4962557852268219, 'learning_rate': 0.0001052046191134571, 'epoch': 0.65}\n",
      "{'loss': 0.8137, 'grad_norm': 0.462505578994751, 'learning_rate': 0.00010436498385101511, 'epoch': 0.65}\n",
      "{'loss': 0.8218, 'grad_norm': 0.1951107531785965, 'learning_rate': 0.00010352534858857312, 'epoch': 0.65}\n",
      "{'loss': 0.8431, 'grad_norm': 0.3227692246437073, 'learning_rate': 0.00010268571332613112, 'epoch': 0.66}\n",
      "{'loss': 0.8339, 'grad_norm': 0.45608237385749817, 'learning_rate': 0.00010184607806368911, 'epoch': 0.66}\n",
      "{'loss': 0.854, 'grad_norm': 0.41121596097946167, 'learning_rate': 0.00010100644280124713, 'epoch': 0.66}\n",
      "{'loss': 0.8114, 'grad_norm': 0.28818967938423157, 'learning_rate': 0.00010016680753880513, 'epoch': 0.67}\n",
      "{'loss': 0.8321, 'grad_norm': 0.627643883228302, 'learning_rate': 9.932717227636313e-05, 'epoch': 0.67}\n",
      "{'loss': 0.8275, 'grad_norm': 0.4007359445095062, 'learning_rate': 9.848753701392115e-05, 'epoch': 0.67}\n",
      "{'loss': 0.8055, 'grad_norm': 0.3276919722557068, 'learning_rate': 9.764790175147915e-05, 'epoch': 0.67}\n",
      "{'loss': 0.834, 'grad_norm': 0.35003212094306946, 'learning_rate': 9.680826648903716e-05, 'epoch': 0.68}\n",
      "{'loss': 0.8181, 'grad_norm': 0.4345006048679352, 'learning_rate': 9.596863122659516e-05, 'epoch': 0.68}\n",
      "{'loss': 0.8092, 'grad_norm': 0.43828898668289185, 'learning_rate': 9.512899596415317e-05, 'epoch': 0.68}\n",
      "{'loss': 0.8071, 'grad_norm': 0.3521847724914551, 'learning_rate': 9.428936070171118e-05, 'epoch': 0.69}\n",
      "{'loss': 0.8449, 'grad_norm': 0.4710175096988678, 'learning_rate': 9.344972543926917e-05, 'epoch': 0.69}\n",
      "{'loss': 0.8086, 'grad_norm': 0.3352836072444916, 'learning_rate': 9.261009017682717e-05, 'epoch': 0.69}\n",
      "{'loss': 0.8147, 'grad_norm': 0.2486431747674942, 'learning_rate': 9.177045491438518e-05, 'epoch': 0.69}\n",
      "{'loss': 0.8243, 'grad_norm': 0.579639196395874, 'learning_rate': 9.093081965194319e-05, 'epoch': 0.7}\n",
      "{'loss': 0.8197, 'grad_norm': 0.45669662952423096, 'learning_rate': 9.009118438950119e-05, 'epoch': 0.7}\n",
      "{'loss': 0.8126, 'grad_norm': 0.4084002673625946, 'learning_rate': 8.92515491270592e-05, 'epoch': 0.7}\n",
      "{'loss': 0.8486, 'grad_norm': 0.4467126429080963, 'learning_rate': 8.84119138646172e-05, 'epoch': 0.71}\n",
      "{'loss': 0.8196, 'grad_norm': 0.5158606767654419, 'learning_rate': 8.75722786021752e-05, 'epoch': 0.71}\n",
      "{'loss': 0.8419, 'grad_norm': 0.55589759349823, 'learning_rate': 8.673264333973322e-05, 'epoch': 0.71}\n",
      "{'loss': 0.8874, 'grad_norm': 0.3611156642436981, 'learning_rate': 8.589300807729121e-05, 'epoch': 0.71}\n",
      "{'loss': 0.8093, 'grad_norm': 0.3961764872074127, 'learning_rate': 8.505337281484922e-05, 'epoch': 0.72}\n",
      "{'loss': 0.8164, 'grad_norm': 0.2487490326166153, 'learning_rate': 8.421373755240723e-05, 'epoch': 0.72}\n",
      "{'loss': 0.8136, 'grad_norm': 0.24269504845142365, 'learning_rate': 8.337410228996523e-05, 'epoch': 0.72}\n",
      "{'loss': 0.8353, 'grad_norm': 0.5157947540283203, 'learning_rate': 8.253446702752324e-05, 'epoch': 0.72}\n",
      "{'loss': 0.8192, 'grad_norm': 0.6007676720619202, 'learning_rate': 8.169483176508124e-05, 'epoch': 0.73}\n",
      "{'loss': 0.8301, 'grad_norm': 0.2952248752117157, 'learning_rate': 8.085519650263924e-05, 'epoch': 0.73}\n",
      "{'loss': 0.8539, 'grad_norm': 0.38509297370910645, 'learning_rate': 8.001556124019726e-05, 'epoch': 0.73}\n",
      "{'loss': 0.8321, 'grad_norm': 0.29044926166534424, 'learning_rate': 7.917592597775526e-05, 'epoch': 0.74}\n",
      "{'loss': 0.8189, 'grad_norm': 0.3937990665435791, 'learning_rate': 7.833629071531325e-05, 'epoch': 0.74}\n",
      "{'loss': 0.8114, 'grad_norm': 0.36848804354667664, 'learning_rate': 7.749665545287126e-05, 'epoch': 0.74}\n",
      "{'loss': 0.8219, 'grad_norm': 0.3686041235923767, 'learning_rate': 7.665702019042927e-05, 'epoch': 0.74}\n",
      "{'loss': 0.83, 'grad_norm': 0.47043514251708984, 'learning_rate': 7.581738492798727e-05, 'epoch': 0.75}\n",
      "{'loss': 0.8364, 'grad_norm': 0.3811781406402588, 'learning_rate': 7.497774966554528e-05, 'epoch': 0.75}\n",
      "{'loss': 0.8418, 'grad_norm': 0.555946946144104, 'learning_rate': 7.413811440310328e-05, 'epoch': 0.75}\n",
      "{'loss': 0.8347, 'grad_norm': 0.4034954309463501, 'learning_rate': 7.329847914066129e-05, 'epoch': 0.76}\n",
      "{'loss': 0.8261, 'grad_norm': 0.3907797336578369, 'learning_rate': 7.24588438782193e-05, 'epoch': 0.76}\n",
      "{'loss': 0.8116, 'grad_norm': 0.37442681193351746, 'learning_rate': 7.16192086157773e-05, 'epoch': 0.76}\n",
      "{'loss': 0.8457, 'grad_norm': 0.5941641330718994, 'learning_rate': 7.07795733533353e-05, 'epoch': 0.76}\n",
      "{'loss': 0.8151, 'grad_norm': 0.2747267484664917, 'learning_rate': 6.99399380908933e-05, 'epoch': 0.77}\n",
      "{'loss': 0.8206, 'grad_norm': 0.3893250823020935, 'learning_rate': 6.910030282845132e-05, 'epoch': 0.77}\n",
      "{'loss': 0.8473, 'grad_norm': 0.4113501012325287, 'learning_rate': 6.826066756600932e-05, 'epoch': 0.77}\n",
      "{'loss': 0.8143, 'grad_norm': 0.2697848975658417, 'learning_rate': 6.742103230356732e-05, 'epoch': 0.78}\n",
      "{'loss': 0.8254, 'grad_norm': 0.3894651532173157, 'learning_rate': 6.658139704112534e-05, 'epoch': 0.78}\n",
      "{'loss': 0.8241, 'grad_norm': 0.3256381154060364, 'learning_rate': 6.574176177868333e-05, 'epoch': 0.78}\n",
      "{'loss': 0.8075, 'grad_norm': 0.22467252612113953, 'learning_rate': 6.490212651624134e-05, 'epoch': 0.78}\n",
      "{'loss': 0.8336, 'grad_norm': 0.4372430145740509, 'learning_rate': 6.406249125379934e-05, 'epoch': 0.79}\n",
      "{'loss': 0.8288, 'grad_norm': 0.39867350459098816, 'learning_rate': 6.322285599135736e-05, 'epoch': 0.79}\n",
      "{'loss': 0.8301, 'grad_norm': 0.4450891315937042, 'learning_rate': 6.238322072891535e-05, 'epoch': 0.79}\n",
      "{'loss': 0.8008, 'grad_norm': 0.2697394788265228, 'learning_rate': 6.154358546647336e-05, 'epoch': 0.79}\n",
      "{'loss': 0.8198, 'grad_norm': 0.2829941511154175, 'learning_rate': 6.070395020403137e-05, 'epoch': 0.8}\n",
      "{'loss': 0.8052, 'grad_norm': 0.2645546793937683, 'learning_rate': 5.986431494158937e-05, 'epoch': 0.8}\n",
      "{'loss': 0.8267, 'grad_norm': 0.5883826613426208, 'learning_rate': 5.902467967914737e-05, 'epoch': 0.8}\n",
      "{'loss': 0.7999, 'grad_norm': 0.45380499958992004, 'learning_rate': 5.818504441670538e-05, 'epoch': 0.81}\n",
      "{'loss': 0.7951, 'grad_norm': 0.528113067150116, 'learning_rate': 5.734540915426339e-05, 'epoch': 0.81}\n",
      "{'loss': 0.8094, 'grad_norm': 0.5559248924255371, 'learning_rate': 5.650577389182138e-05, 'epoch': 0.81}\n",
      "{'loss': 0.8295, 'grad_norm': 0.44833922386169434, 'learning_rate': 5.566613862937939e-05, 'epoch': 0.81}\n",
      "{'loss': 0.8231, 'grad_norm': 0.5462622046470642, 'learning_rate': 5.48265033669374e-05, 'epoch': 0.82}\n",
      "{'loss': 0.7992, 'grad_norm': 0.33140134811401367, 'learning_rate': 5.398686810449541e-05, 'epoch': 0.82}\n",
      "{'loss': 0.8016, 'grad_norm': 0.3492116928100586, 'learning_rate': 5.31472328420534e-05, 'epoch': 0.82}\n",
      "{'loss': 0.7979, 'grad_norm': 0.4200068414211273, 'learning_rate': 5.230759757961141e-05, 'epoch': 0.83}\n",
      "{'loss': 0.7968, 'grad_norm': 0.43007373809814453, 'learning_rate': 5.146796231716942e-05, 'epoch': 0.83}\n",
      "{'loss': 0.8368, 'grad_norm': 0.30898791551589966, 'learning_rate': 5.062832705472742e-05, 'epoch': 0.83}\n",
      "{'loss': 0.779, 'grad_norm': 0.21933510899543762, 'learning_rate': 4.978869179228543e-05, 'epoch': 0.83}\n",
      "{'loss': 0.8133, 'grad_norm': 0.3787011504173279, 'learning_rate': 4.894905652984343e-05, 'epoch': 0.84}\n",
      "{'loss': 0.7945, 'grad_norm': 0.2436649352312088, 'learning_rate': 4.810942126740144e-05, 'epoch': 0.84}\n",
      "{'loss': 0.802, 'grad_norm': 0.23602896928787231, 'learning_rate': 4.726978600495944e-05, 'epoch': 0.84}\n",
      "{'loss': 0.8253, 'grad_norm': 0.5033969879150391, 'learning_rate': 4.643015074251745e-05, 'epoch': 0.85}\n",
      "{'loss': 0.8364, 'grad_norm': 0.6324219703674316, 'learning_rate': 4.5590515480075456e-05, 'epoch': 0.85}\n",
      "{'loss': 0.7975, 'grad_norm': 0.3008681833744049, 'learning_rate': 4.475088021763345e-05, 'epoch': 0.85}\n",
      "{'loss': 0.8235, 'grad_norm': 0.5089409351348877, 'learning_rate': 4.391124495519146e-05, 'epoch': 0.85}\n",
      "{'loss': 0.8061, 'grad_norm': 0.7191786170005798, 'learning_rate': 4.307160969274947e-05, 'epoch': 0.86}\n",
      "{'loss': 0.7969, 'grad_norm': 0.5290459394454956, 'learning_rate': 4.2231974430307476e-05, 'epoch': 0.86}\n",
      "{'loss': 0.7995, 'grad_norm': 0.4779050052165985, 'learning_rate': 4.139233916786547e-05, 'epoch': 0.86}\n",
      "{'loss': 0.8046, 'grad_norm': 0.41914620995521545, 'learning_rate': 4.055270390542348e-05, 'epoch': 0.86}\n",
      "{'loss': 0.8204, 'grad_norm': 0.377216637134552, 'learning_rate': 3.971306864298149e-05, 'epoch': 0.87}\n",
      "{'loss': 0.8118, 'grad_norm': 0.5535416603088379, 'learning_rate': 3.887343338053949e-05, 'epoch': 0.87}\n",
      "{'loss': 0.8044, 'grad_norm': 0.5115277767181396, 'learning_rate': 3.80337981180975e-05, 'epoch': 0.87}\n",
      "{'loss': 0.8114, 'grad_norm': 0.45724743604660034, 'learning_rate': 3.71941628556555e-05, 'epoch': 0.88}\n",
      "{'loss': 0.828, 'grad_norm': 0.3705604672431946, 'learning_rate': 3.635452759321351e-05, 'epoch': 0.88}\n",
      "{'loss': 0.8225, 'grad_norm': 0.26318731904029846, 'learning_rate': 3.551489233077151e-05, 'epoch': 0.88}\n",
      "{'loss': 0.8374, 'grad_norm': 0.274476557970047, 'learning_rate': 3.4675257068329517e-05, 'epoch': 0.88}\n",
      "{'loss': 0.8075, 'grad_norm': 0.3742012083530426, 'learning_rate': 3.383562180588752e-05, 'epoch': 0.89}\n",
      "{'loss': 0.8223, 'grad_norm': 0.4622892141342163, 'learning_rate': 3.2995986543445526e-05, 'epoch': 0.89}\n",
      "{'loss': 0.827, 'grad_norm': 0.46999698877334595, 'learning_rate': 3.215635128100353e-05, 'epoch': 0.89}\n",
      "{'loss': 0.84, 'grad_norm': 0.3295043110847473, 'learning_rate': 3.1316716018561536e-05, 'epoch': 0.9}\n",
      "{'loss': 0.7974, 'grad_norm': 0.4365634322166443, 'learning_rate': 3.0477080756119538e-05, 'epoch': 0.9}\n",
      "{'loss': 0.7852, 'grad_norm': 0.430501788854599, 'learning_rate': 2.9637445493677542e-05, 'epoch': 0.9}\n",
      "{'loss': 0.812, 'grad_norm': 0.36679622530937195, 'learning_rate': 2.879781023123555e-05, 'epoch': 0.9}\n",
      "{'loss': 0.813, 'grad_norm': 0.5583562254905701, 'learning_rate': 2.7958174968793552e-05, 'epoch': 0.91}\n",
      "{'loss': 0.7954, 'grad_norm': 0.5705386996269226, 'learning_rate': 2.711853970635156e-05, 'epoch': 0.91}\n",
      "{'loss': 0.8207, 'grad_norm': 0.45920535922050476, 'learning_rate': 2.6278904443909562e-05, 'epoch': 0.91}\n",
      "{'loss': 0.8088, 'grad_norm': 0.23936296999454498, 'learning_rate': 2.543926918146757e-05, 'epoch': 0.92}\n",
      "{'loss': 0.8248, 'grad_norm': 0.3674338757991791, 'learning_rate': 2.4599633919025572e-05, 'epoch': 0.92}\n",
      "{'loss': 0.8334, 'grad_norm': 0.6574286222457886, 'learning_rate': 2.3759998656583577e-05, 'epoch': 0.92}\n",
      "{'loss': 0.8197, 'grad_norm': 0.3519294261932373, 'learning_rate': 2.292036339414158e-05, 'epoch': 0.92}\n",
      "{'loss': 0.804, 'grad_norm': 0.5989907383918762, 'learning_rate': 2.2080728131699586e-05, 'epoch': 0.93}\n",
      "{'loss': 0.813, 'grad_norm': 0.5773645639419556, 'learning_rate': 2.1241092869257595e-05, 'epoch': 0.93}\n",
      "{'loss': 0.7756, 'grad_norm': 0.23709169030189514, 'learning_rate': 2.0401457606815596e-05, 'epoch': 0.93}\n",
      "{'loss': 0.8265, 'grad_norm': 0.2802451252937317, 'learning_rate': 1.9561822344373604e-05, 'epoch': 0.93}\n",
      "{'loss': 0.8272, 'grad_norm': 0.26967576146125793, 'learning_rate': 1.8722187081931606e-05, 'epoch': 0.94}\n",
      "{'loss': 0.8168, 'grad_norm': 0.28600168228149414, 'learning_rate': 1.788255181948961e-05, 'epoch': 0.94}\n",
      "{'loss': 0.8303, 'grad_norm': 0.6234513521194458, 'learning_rate': 1.7042916557047616e-05, 'epoch': 0.94}\n",
      "{'loss': 0.8152, 'grad_norm': 0.4452000558376312, 'learning_rate': 1.6203281294605624e-05, 'epoch': 0.95}\n",
      "{'loss': 0.83, 'grad_norm': 0.3872765898704529, 'learning_rate': 1.536364603216363e-05, 'epoch': 0.95}\n",
      "{'loss': 0.8019, 'grad_norm': 0.42946678400039673, 'learning_rate': 1.452401076972163e-05, 'epoch': 0.95}\n",
      "{'loss': 0.7931, 'grad_norm': 0.41011154651641846, 'learning_rate': 1.3684375507279635e-05, 'epoch': 0.95}\n",
      "{'loss': 0.8259, 'grad_norm': 0.25830766558647156, 'learning_rate': 1.2844740244837642e-05, 'epoch': 0.96}\n",
      "{'loss': 0.8133, 'grad_norm': 0.2660171091556549, 'learning_rate': 1.2005104982395647e-05, 'epoch': 0.96}\n",
      "{'loss': 0.8132, 'grad_norm': 0.6784020662307739, 'learning_rate': 1.1165469719953652e-05, 'epoch': 0.96}\n",
      "{'loss': 0.7967, 'grad_norm': 0.29830294847488403, 'learning_rate': 1.0325834457511656e-05, 'epoch': 0.97}\n",
      "{'loss': 0.8188, 'grad_norm': 0.41267475485801697, 'learning_rate': 9.486199195069661e-06, 'epoch': 0.97}\n",
      "{'loss': 0.7956, 'grad_norm': 0.5724202394485474, 'learning_rate': 8.646563932627666e-06, 'epoch': 0.97}\n",
      "{'loss': 0.8165, 'grad_norm': 0.6086165904998779, 'learning_rate': 7.806928670185671e-06, 'epoch': 0.97}\n",
      "{'loss': 0.8151, 'grad_norm': 0.5259858965873718, 'learning_rate': 6.967293407743675e-06, 'epoch': 0.98}\n",
      "{'loss': 0.8144, 'grad_norm': 0.39069071412086487, 'learning_rate': 6.12765814530168e-06, 'epoch': 0.98}\n",
      "{'loss': 0.8089, 'grad_norm': 0.49339112639427185, 'learning_rate': 5.288022882859686e-06, 'epoch': 0.98}\n",
      "{'loss': 0.8156, 'grad_norm': 0.35995689034461975, 'learning_rate': 4.44838762041769e-06, 'epoch': 0.99}\n",
      "{'loss': 0.7958, 'grad_norm': 0.3917235732078552, 'learning_rate': 3.608752357975695e-06, 'epoch': 0.99}\n",
      "{'loss': 0.8384, 'grad_norm': 0.25104162096977234, 'learning_rate': 2.7691170955337e-06, 'epoch': 0.99}\n",
      "{'loss': 0.8168, 'grad_norm': 0.23312126100063324, 'learning_rate': 1.929481833091705e-06, 'epoch': 0.99}\n",
      "{'loss': 0.8132, 'grad_norm': 0.42994314432144165, 'learning_rate': 1.0898465706497097e-06, 'epoch': 1.0}\n",
      "{'loss': 0.7894, 'grad_norm': 0.29908761382102966, 'learning_rate': 2.5021130820771455e-07, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ce216271a84df9b8a3f382b81502fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.37846577167510986, 'eval_bleu': 0.566, 'eval_gen_len': 18.7067, 'eval_runtime': 430.9215, 'eval_samples_per_second': 21.039, 'eval_steps_per_second': 2.632, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 38543.2152, 'train_samples_per_second': 37.08, 'train_steps_per_second': 4.635, 'train_loss': 0.8592925987040585, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=178649, training_loss=0.8592925987040585, metrics={'train_runtime': 38543.2152, 'train_samples_per_second': 37.08, 'train_steps_per_second': 4.635, 'total_flos': 1.3309175054676787e+17, 'train_loss': 0.8592925987040585, 'epoch': 1.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"v1_1-small-poc\",\n",
    "    auto_find_batch_size=True,\n",
    "    predict_with_generate=True,\n",
    "    #max_grad_norm=1.0,\n",
    "    fp16=False, #check this\n",
    "    push_to_hub=False,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    num_train_epochs=1\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    optimizers=(optimizer, None),\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
