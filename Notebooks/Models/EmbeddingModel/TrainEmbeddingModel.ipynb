{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset('billingsmoore/Aggregated-bo-en', split='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Tokenizer for Tibetan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the tokenizer already contains some Tibetan tokens but not enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tokenizer.encode('ཡུན་རིང་དུས་ནས་ཆོས་ཀྱིས་བསྐྱངས་བའི་བུ། ')\n",
    "tokenizer.decode(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import BertWordPieceTokenizer\n",
    "\n",
    "new_tokenizer = BertWordPieceTokenizer(lowercase=False, strip_accents=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tokenizer.train_from_iterator(\n",
    "    ds['bo'],\n",
    "    vocab_size=len(tokenizer.get_vocab()),\n",
    "    min_frequency=3,\n",
    "    show_progress=True,\n",
    "    limit_alphabet=500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert New Tokenizer to AutoTokenizer Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tokenizer.save_model('new_tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "\n",
    "# Load the trained tokenizer\n",
    "fast_tokenizer = BertTokenizerFast(\n",
    "    vocab_file=\"new_tokenizer/vocab.txt\",\n",
    "    do_lower_case=False\n",
    ")\n",
    "\n",
    "# Save in Hugging Face format\n",
    "fast_tokenizer.save_pretrained(\"fast_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load your new tokenizer\n",
    "new_fast_tokenizer = AutoTokenizer.from_pretrained(\"fast_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = new_fast_tokenizer.encode('ཡུན་རིང་དུས་ནས་ཆོས་ཀྱིས་བསྐྱངས་བའི་བུ། ')\n",
    "new_fast_tokenizer.decode(enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Embedding Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import (\n",
    "    SentenceTransformer,\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments,\n",
    "    models\n",
    ")\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load teacher model\n",
    "teacher_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', device='cuda')\n",
    "\n",
    "# load student model\n",
    "word_embedding_model = models.Transformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "word_embedding_model.tokenizer = AutoTokenizer.from_pretrained(\"fast_tokenizer\")\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "\n",
    "student_model = SentenceTransformer(modules=[word_embedding_model, pooling_model], device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70cb9f127429484a9645d6e22e6dc828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/878004 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'bo': '༄༅༅། །རྒྱ་གར་སྐད་དུ། ཨཱརྱ་སུ་བརྞྞ་བཱ་ལུ་ཀོ་པ་མ་ནཱ་མ་མ་ཧཱ་ཡཱ་ན་སཱུ་ཏྲ། བོད་སྐད་དུ།',\n",
       " 'en': 'The Noble Mahāyāna Sūtra Like Gold Dust',\n",
       " 'topic': 'Meditation, Ritual, Enlightenment',\n",
       " 'source': '84000',\n",
       " 'english': 'The Noble Mahāyāna Sūtra Like Gold Dust',\n",
       " 'tibetan': '༄༅༅། །རྒྱ་གར་སྐད་དུ། ཨཱརྱ་སུ་བརྞྞ་བཱ་ལུ་ཀོ་པ་མ་ནཱ་མ་མ་ཧཱ་ཡཱ་ན་སཱུ་ཏྲ། བོད་སྐད་དུ།',\n",
       " 'label': [-0.06716889888048172,\n",
       "  -0.01000198908150196,\n",
       "  -0.030257122591137886,\n",
       "  0.05288662016391754,\n",
       "  -0.024933090433478355,\n",
       "  -0.011344384402036667,\n",
       "  0.05050237104296684,\n",
       "  -0.044951360672712326,\n",
       "  -0.00341879203915596,\n",
       "  0.033140622079372406,\n",
       "  0.01606477051973343,\n",
       "  0.04913238063454628,\n",
       "  -0.07414509356021881,\n",
       "  -0.03771483898162842,\n",
       "  -0.03334968909621239,\n",
       "  -0.00014761531201656908,\n",
       "  0.05078834295272827,\n",
       "  0.017935410141944885,\n",
       "  -0.06188945844769478,\n",
       "  0.05025920644402504,\n",
       "  0.03822670876979828,\n",
       "  0.07103323936462402,\n",
       "  0.04260242357850075,\n",
       "  0.0038686522748321295,\n",
       "  -0.036233022809028625,\n",
       "  -0.0034739854745566845,\n",
       "  -0.001581312040798366,\n",
       "  -0.07827584445476532,\n",
       "  0.015463469550013542,\n",
       "  -0.02180996537208557,\n",
       "  0.014553956687450409,\n",
       "  -0.007947035133838654,\n",
       "  -0.026236146688461304,\n",
       "  0.06280592083930969,\n",
       "  -0.09881342202425003,\n",
       "  -0.005923611577600241,\n",
       "  -0.04980845749378204,\n",
       "  0.0822933241724968,\n",
       "  0.0560101643204689,\n",
       "  -0.05612827464938164,\n",
       "  -0.02540810965001583,\n",
       "  -0.025080271065235138,\n",
       "  -0.04012135788798332,\n",
       "  -0.009224019944667816,\n",
       "  -0.012349697761237621,\n",
       "  -0.0551319345831871,\n",
       "  0.0356505922973156,\n",
       "  -0.012111276388168335,\n",
       "  0.001443583401851356,\n",
       "  -0.024549223482608795,\n",
       "  -0.030744528397917747,\n",
       "  0.013148346915841103,\n",
       "  -0.06513664871454239,\n",
       "  0.028813250362873077,\n",
       "  -0.026657884940505028,\n",
       "  0.036245957016944885,\n",
       "  -0.033833809196949005,\n",
       "  -0.07311823964118958,\n",
       "  -0.003218296682462096,\n",
       "  -0.0192073043435812,\n",
       "  -0.024521980434656143,\n",
       "  0.023756591603159904,\n",
       "  -0.012428626418113708,\n",
       "  0.009394356049597263,\n",
       "  0.06437483429908752,\n",
       "  -0.02997816726565361,\n",
       "  0.07623795419931412,\n",
       "  0.04205319285392761,\n",
       "  0.037541259080171585,\n",
       "  -0.01265215128660202,\n",
       "  -0.04027995094656944,\n",
       "  0.04450124874711037,\n",
       "  -0.053782179951667786,\n",
       "  0.07384347915649414,\n",
       "  -0.11291252076625824,\n",
       "  0.04680423066020012,\n",
       "  0.03648335486650467,\n",
       "  -0.05961530655622482,\n",
       "  -0.08158430457115173,\n",
       "  -0.011488215997815132,\n",
       "  -0.03598044812679291,\n",
       "  0.03129637613892555,\n",
       "  0.07259336858987808,\n",
       "  0.0654197409749031,\n",
       "  -0.03706279769539833,\n",
       "  0.03456836938858032,\n",
       "  -0.013370717875659466,\n",
       "  -0.00015934318071231246,\n",
       "  0.02469707652926445,\n",
       "  -0.10074305534362793,\n",
       "  0.08198186755180359,\n",
       "  -0.02237529121339321,\n",
       "  -0.04861142486333847,\n",
       "  0.06440044939517975,\n",
       "  -0.08822674304246902,\n",
       "  -0.006471905391663313,\n",
       "  0.06620504707098007,\n",
       "  -0.038514841347932816,\n",
       "  -0.0064011006616055965,\n",
       "  0.08830078691244125,\n",
       "  -0.002536526881158352,\n",
       "  0.10128649324178696,\n",
       "  0.011093515902757645,\n",
       "  -0.05554307997226715,\n",
       "  -0.0028925572987645864,\n",
       "  -0.05771132558584213,\n",
       "  -0.033606112003326416,\n",
       "  -0.04139412194490433,\n",
       "  -0.02716928720474243,\n",
       "  -0.028256142511963844,\n",
       "  -0.017137592658400536,\n",
       "  -0.07481131702661514,\n",
       "  -0.020609242841601372,\n",
       "  -0.04617520421743393,\n",
       "  0.029319847002625465,\n",
       "  -0.0030787638388574123,\n",
       "  0.059653669595718384,\n",
       "  0.0074327741749584675,\n",
       "  -0.10162615031003952,\n",
       "  0.03686957061290741,\n",
       "  0.005774708464741707,\n",
       "  -0.007374541833996773,\n",
       "  0.014306844212114811,\n",
       "  0.022703932598233223,\n",
       "  -0.02050427533686161,\n",
       "  -0.09825564175844193,\n",
       "  0.023242875933647156,\n",
       "  -3.8043205554220664e-34,\n",
       "  0.0481114536523819,\n",
       "  0.06786961108446121,\n",
       "  0.058336179703474045,\n",
       "  -0.00942271202802658,\n",
       "  0.03633297607302666,\n",
       "  0.0026779386680573225,\n",
       "  0.011228750459849834,\n",
       "  -0.08075836300849915,\n",
       "  0.05285141244530678,\n",
       "  0.032284609973430634,\n",
       "  -0.024154188111424446,\n",
       "  0.05116915702819824,\n",
       "  -0.06723805516958237,\n",
       "  -0.021272700279951096,\n",
       "  -0.011513604782521725,\n",
       "  0.0723019689321518,\n",
       "  -0.0548192523419857,\n",
       "  -0.0572340190410614,\n",
       "  0.09742356091737747,\n",
       "  -0.02329205721616745,\n",
       "  -0.07945120334625244,\n",
       "  0.12687163054943085,\n",
       "  0.009673014283180237,\n",
       "  -0.05216621607542038,\n",
       "  -0.016689900308847427,\n",
       "  0.056776564568281174,\n",
       "  0.1017259880900383,\n",
       "  0.03666612133383751,\n",
       "  -0.038731444627046585,\n",
       "  0.05713886767625809,\n",
       "  0.05799480527639389,\n",
       "  0.049571339040994644,\n",
       "  -0.05125461891293526,\n",
       "  0.004283163696527481,\n",
       "  -0.003895275993272662,\n",
       "  0.061751946806907654,\n",
       "  -0.055573441088199615,\n",
       "  -0.016019416972994804,\n",
       "  0.022853771224617958,\n",
       "  0.012899409979581833,\n",
       "  -0.04132161661982536,\n",
       "  -0.041558265686035156,\n",
       "  0.019901080057024956,\n",
       "  0.0728297233581543,\n",
       "  0.014968114905059338,\n",
       "  0.07836350798606873,\n",
       "  0.02891114167869091,\n",
       "  0.06990178674459457,\n",
       "  -0.03167157247662544,\n",
       "  0.04962591454386711,\n",
       "  -0.0593331940472126,\n",
       "  0.04506466165184975,\n",
       "  0.04384870454668999,\n",
       "  0.033452533185482025,\n",
       "  -0.06668639183044434,\n",
       "  -0.062265343964099884,\n",
       "  0.03650997206568718,\n",
       "  -0.003375930478796363,\n",
       "  0.03350849822163582,\n",
       "  0.013551011681556702,\n",
       "  0.010228738188743591,\n",
       "  -0.10104291886091232,\n",
       "  -0.06541292369365692,\n",
       "  0.05507731810212135,\n",
       "  -0.055971235036849976,\n",
       "  -0.0027831420302391052,\n",
       "  -0.08810121566057205,\n",
       "  -0.031170273199677467,\n",
       "  0.053058426827192307,\n",
       "  -0.016989003866910934,\n",
       "  -0.022956734523177147,\n",
       "  0.056587863713502884,\n",
       "  0.013063750229775906,\n",
       "  0.025005361065268517,\n",
       "  -0.014634107239544392,\n",
       "  -0.07113906741142273,\n",
       "  0.046297941356897354,\n",
       "  -0.06961924582719803,\n",
       "  -0.033489543944597244,\n",
       "  -0.037812069058418274,\n",
       "  -0.018235083669424057,\n",
       "  0.03432905301451683,\n",
       "  -0.020159810781478882,\n",
       "  0.06530123949050903,\n",
       "  -0.033559225499629974,\n",
       "  0.011340859346091747,\n",
       "  0.0025585892144590616,\n",
       "  0.016062794253230095,\n",
       "  0.022453853860497475,\n",
       "  -0.0647980347275734,\n",
       "  0.04044836759567261,\n",
       "  0.044646330177783966,\n",
       "  0.1253124177455902,\n",
       "  -0.0959051102399826,\n",
       "  -0.028793226927518845,\n",
       "  -9.622352473411465e-34,\n",
       "  0.014654713682830334,\n",
       "  -0.06717471033334732,\n",
       "  -0.03923127055168152,\n",
       "  0.1340918391942978,\n",
       "  0.11741095781326294,\n",
       "  0.039458222687244415,\n",
       "  -0.09537561982870102,\n",
       "  0.10900414735078812,\n",
       "  -0.11211010813713074,\n",
       "  0.029374761506915092,\n",
       "  0.005413907114416361,\n",
       "  -0.040713779628276825,\n",
       "  0.00010374511475674808,\n",
       "  0.03828561678528786,\n",
       "  0.07864059507846832,\n",
       "  -0.0038036105688661337,\n",
       "  0.08235859870910645,\n",
       "  0.06026023253798485,\n",
       "  -0.036106809973716736,\n",
       "  0.0012951534008607268,\n",
       "  -0.008849356323480606,\n",
       "  0.07823284715414047,\n",
       "  -0.017107559368014336,\n",
       "  -0.008138319477438927,\n",
       "  0.018663162365555763,\n",
       "  -0.013737819157540798,\n",
       "  0.02817567251622677,\n",
       "  -0.036308713257312775,\n",
       "  -0.06709317117929459,\n",
       "  0.027857724577188492,\n",
       "  0.09400831162929535,\n",
       "  0.04337320104241371,\n",
       "  -0.05662043020129204,\n",
       "  -0.03171802684664726,\n",
       "  -0.006770804058760405,\n",
       "  -0.09182348102331161,\n",
       "  0.06323347985744476,\n",
       "  0.014846611768007278,\n",
       "  -0.0789044052362442,\n",
       "  -0.008090878836810589,\n",
       "  0.026819074526429176,\n",
       "  -0.022797858342528343,\n",
       "  0.041269708424806595,\n",
       "  -0.0005919816321693361,\n",
       "  -0.009140890091657639,\n",
       "  -0.02739814482629299,\n",
       "  0.028501875698566437,\n",
       "  0.03280852735042572,\n",
       "  0.009226406924426556,\n",
       "  -0.011804335750639439,\n",
       "  0.08886648714542389,\n",
       "  -0.07899358123540878,\n",
       "  -0.0019240172114223242,\n",
       "  -0.06601008772850037,\n",
       "  0.0652284100651741,\n",
       "  0.0418415330350399,\n",
       "  -0.021878773346543312,\n",
       "  0.022304460406303406,\n",
       "  0.07317252457141876,\n",
       "  0.06985784322023392,\n",
       "  0.01281587965786457,\n",
       "  0.04042625054717064,\n",
       "  -0.03090851753950119,\n",
       "  0.043457869440317154,\n",
       "  -0.00645329337567091,\n",
       "  -0.006210292689502239,\n",
       "  0.07337058335542679,\n",
       "  0.10408449918031693,\n",
       "  -0.08295491337776184,\n",
       "  -0.003936379682272673,\n",
       "  -0.06647870689630508,\n",
       "  -0.15425743162631989,\n",
       "  0.010076267644762993,\n",
       "  0.014841632917523384,\n",
       "  0.07247307896614075,\n",
       "  -0.016705436632037163,\n",
       "  0.013241834007203579,\n",
       "  -0.039834633469581604,\n",
       "  0.008648166432976723,\n",
       "  -0.02897770144045353,\n",
       "  -0.008102376013994217,\n",
       "  -0.05426177382469177,\n",
       "  0.029704006388783455,\n",
       "  -0.00574592687189579,\n",
       "  0.058007270097732544,\n",
       "  0.03036188706755638,\n",
       "  -0.05579497665166855,\n",
       "  -0.05222206935286522,\n",
       "  -0.11773552745580673,\n",
       "  -0.03237017244100571,\n",
       "  -0.023586468771100044,\n",
       "  0.0017041914397850633,\n",
       "  -0.002823590999469161,\n",
       "  -0.002417979296296835,\n",
       "  0.03185966983437538,\n",
       "  -1.4131154912888633e-08,\n",
       "  0.09618158638477325,\n",
       "  -0.01948307640850544,\n",
       "  0.003535498632118106,\n",
       "  0.0025476193986833096,\n",
       "  0.05338898301124573,\n",
       "  0.006833331193774939,\n",
       "  0.05135480314493179,\n",
       "  0.10475271195173264,\n",
       "  -0.05635242536664009,\n",
       "  0.07870970666408539,\n",
       "  0.006155940238386393,\n",
       "  0.05164041742682457,\n",
       "  0.0018322727410122752,\n",
       "  0.07658941298723221,\n",
       "  -0.02882658876478672,\n",
       "  -0.0034729717299342155,\n",
       "  0.09898857772350311,\n",
       "  -0.015117148868739605,\n",
       "  -0.06542346626520157,\n",
       "  -0.11185409873723984,\n",
       "  0.07472831010818481,\n",
       "  0.02553706243634224,\n",
       "  0.0499778687953949,\n",
       "  -0.12345171719789505,\n",
       "  -0.06317510455846786,\n",
       "  0.031384021043777466,\n",
       "  -0.02673039212822914,\n",
       "  0.025287268683314323,\n",
       "  0.008584685623645782,\n",
       "  -0.018146155402064323,\n",
       "  -0.0024172402918338776,\n",
       "  0.02890782617032528,\n",
       "  -0.010556170716881752,\n",
       "  -0.053885817527770996,\n",
       "  -0.06122763082385063,\n",
       "  0.06497444212436676,\n",
       "  -0.010777913965284824,\n",
       "  -0.0382176972925663,\n",
       "  0.03169706463813782,\n",
       "  -0.014370149932801723,\n",
       "  -0.022835522890090942,\n",
       "  -0.030332127586007118,\n",
       "  0.0290607288479805,\n",
       "  0.024211956188082695,\n",
       "  0.04270360618829727,\n",
       "  -0.027766427025198936,\n",
       "  0.04243495315313339,\n",
       "  0.004704676102846861,\n",
       "  -0.043315589427948,\n",
       "  0.004550768993794918,\n",
       "  -0.01909714564681053,\n",
       "  0.01038121897727251,\n",
       "  0.10217387974262238,\n",
       "  -0.06987353414297104,\n",
       "  -0.0525197796523571,\n",
       "  -0.007615900132805109,\n",
       "  -0.011390626430511475,\n",
       "  0.03232405334711075,\n",
       "  -0.049446478486061096,\n",
       "  -0.031117860227823257,\n",
       "  0.13637283444404602,\n",
       "  -0.09045176208019257,\n",
       "  -0.1226297989487648,\n",
       "  0.014990649186074734]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset('billingsmoore/Aggregated-bo-en', split='train')\n",
    "\n",
    "# create teacher embeddings\n",
    "def create_teacher_embeddings(batch):\n",
    "    batch['english'] = batch['en']\n",
    "    batch['tibetan'] = batch['bo']\n",
    "    batch['label'] = teacher_model.encode(batch['en'])\n",
    "    return batch\n",
    "\n",
    "ds = ds.map(create_teacher_embeddings, batched=True)\n",
    "\n",
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['english', 'tibetan', 'label'],\n",
       "        num_rows: 790203\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['english', 'tibetan', 'label'],\n",
       "        num_rows: 87801\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds.remove_columns(['bo', 'en', 'topic', 'source'])\n",
    "ds = ds.train_test_split(.1)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.losses import MSELoss\n",
    "\n",
    "# 4. Define a loss function\n",
    "loss = MSELoss(student_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Specify training arguments\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"do-it-right\",\n",
    "    num_train_epochs=25,\n",
    "    auto_find_batch_size=True,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    fp16=False,  # Set to False if you get an error that your GPU can't run on FP16\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    save_safetensors=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e902db62f06048269891ffc16769ebb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2744 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc745ebb7814b91a8f9ff62e741b0b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2744 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'stsb-dev_negative_mse': np.float32(-7.179603)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers.evaluation import MSEEvaluator\n",
    "# Create an evaluator & evaluate the base model\n",
    "dev_evaluator = MSEEvaluator(\n",
    "    source_sentences=ds['test']['english'],\n",
    "    target_sentences=ds['test']['tibetan'],\n",
    "    teacher_model=teacher_model,\n",
    "    name=\"stsb-dev\",\n",
    "    show_progress_bar=True\n",
    ")\n",
    "dev_evaluator(student_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ds['train'].remove_columns(['english'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98777' max='2469400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  98767/2469400 55:19 < 22:07:47, 29.76 it/s, Epoch 1.00/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Stsb-dev Negative Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>-0.17373772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2db55a3187b44b7be75934be4df6451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2744 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type float32 is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 7. Create a trainer & train\u001b[39;00m\n\u001b[1;32m      2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m SentenceTransformerTrainer(\n\u001b[1;32m      3\u001b[0m     model\u001b[38;5;241m=\u001b[39mstudent_model,\n\u001b[1;32m      4\u001b[0m     args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     evaluator\u001b[38;5;241m=\u001b[39mdev_evaluator,\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/MLotsawa/.venv/lib/python3.12/site-packages/transformers/trainer.py:2171\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2169\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2172\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/MLotsawa/.venv/lib/python3.12/site-packages/accelerate/utils/memory.py:159\u001b[0m, in \u001b[0;36mfind_executable_batch_size.<locals>.decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo executable batch size found, reached zero.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_reduce_batch_size(e):\n",
      "File \u001b[0;32m~/Desktop/MLotsawa/.venv/lib/python3.12/site-packages/transformers/trainer.py:2625\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2622\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2624\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2625\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[1;32m   2628\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_xla_available():\n\u001b[1;32m   2629\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/MLotsawa/.venv/lib/python3.12/site-packages/transformers/trainer.py:3078\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time)\u001b[0m\n\u001b[1;32m   3075\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save \u001b[38;5;241m=\u001b[39m is_new_best_metric\n\u001b[1;32m   3077\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 3078\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3079\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_save(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/Desktop/MLotsawa/.venv/lib/python3.12/site-packages/transformers/trainer.py:3229\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[0;34m(self, model, trial)\u001b[0m\n\u001b[1;32m   3227\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3228\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstateful_callbacks[cb_name] \u001b[38;5;241m=\u001b[39m cb_state\n\u001b[0;32m-> 3229\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_to_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTRAINER_STATE_NAME\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpush_to_hub:\n\u001b[1;32m   3232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_push_from_checkpoint(output_dir)\n",
      "File \u001b[0;32m~/Desktop/MLotsawa/.venv/lib/python3.12/site-packages/transformers/trainer_callback.py:142\u001b[0m, in \u001b[0;36mTrainerState.save_to_json\u001b[0;34m(self, json_path)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_to_json\u001b[39m(\u001b[38;5;28mself\u001b[39m, json_path: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    141\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Save the content of this instance in JSON format inside `json_path`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m     json_string \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataclasses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masdict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(json_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    144\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(json_string)\n",
      "File \u001b[0;32m/usr/lib/python3.12/json/__init__.py:238\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_circular\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseparators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseparators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m--> 238\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.12/json/encoder.py:202\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    200\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterencode(o, _one_shot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 202\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(chunks)\n",
      "File \u001b[0;32m/usr/lib/python3.12/json/encoder.py:432\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 432\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.12/json/encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3.12/json/encoder.py:326\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 326\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    328\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3.12/json/encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3.12/json/encoder.py:439\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    438\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[0;32m--> 439\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.12/json/encoder.py:180\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    181\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type float32 is not JSON serializable"
     ]
    }
   ],
   "source": [
    "# 7. Create a trainer & train\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=student_model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=ds['test'],\n",
    "    loss=loss,\n",
    "    evaluator=dev_evaluator,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model.save('./fine-tuned-minilm3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.load('./fine-tuned-minilm3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "568579271b514cb4be33ce1f02b34559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/billingsmoore/minilm-bo/commit/0b52743d41a3aea475e4bc338cb117b2b3e21770'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.push_to_hub('billingsmoore/minilm-bo')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
