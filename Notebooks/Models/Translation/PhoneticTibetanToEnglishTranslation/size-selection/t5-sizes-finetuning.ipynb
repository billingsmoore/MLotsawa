{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning T5 for Size Selection\n",
    "\n",
    "The purpose of this notebook is to document the process of finetuning Google's T5 model for translating from Literary Tibetan to English. This notebook relies on a dataset in the form of a pickled pandas dataframe which consists of a single column, 'translation'. Entries in that column should be a python dictionary of the structure: {'bo':'Tibetan text', 'en': 'English text'}.\n",
    "\n",
    "In creating this notebook I drew on the following tutorial from HuggingFace: https://huggingface.co/learn/nlp-course/chapter7/4?fw=pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only this line should be changed for testing different sizes\n",
    "# must be one of ['small', 'base', large', '3b']\n",
    "size = 'large'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Split the Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "train_dataset = load_dataset('pandas', data_files='/home/j/Documents/Projects/MLotsawa/data/size-selection-data/1M-train.p')\n",
    "eval_dataset = load_dataset('pandas', data_files='/home/j/Documents/Projects/MLotsawa/data/size-selection-data/100k-eval.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format and Tokenize the Data\n",
    "\n",
    "This notebook uses Google's T5-small model and its associated tokenizer. This model gives really great results on translation tasks despite its small size. The data must be reformatted though to accomodate the model's expectations.\n",
    "\n",
    "We will format each input as 'translate Tibetan to English: \\<Tibetan text\\>' with the English translation as the target.\n",
    "\n",
    "Once the sentence pairs are formatted, we can tokenize them for processing by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorForSeq2Seq\n",
    "\n",
    "checkpoint = f\"google-t5/t5-{size}\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_lang = 'bo'\n",
    "target_lang = 'en'\n",
    "prefix = \"translate Tibetan to English: \"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "\n",
    "    inputs = [prefix + example[source_lang] for example in examples['translation']]\n",
    "    targets = [example[target_lang] for example in examples['translation']]\n",
    "    \n",
    "    model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True)\n",
    "\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_eval_dataset = eval_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Evaluation Metrics\n",
    "\n",
    "We will be using the BLEU metric as implemented by SacreBLEU as our evaluation metric. BLEU (BiLingual Evaluation Understudy) is a standard (if not uncontroversial) metric in machine translation. BLEU gives each prediction a score between 0 and 1, where 0 means the model's predicted translation is nothing like the correct translation and 1 means the predicited translation is identical to the correct one. You can read more about the specifics here: https://en.wikipedia.org/wiki/BLEU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Train the Model\n",
    "\n",
    "Finally, we train the model. You can uncomment the line 'model.to(\"cuda:0\")' if are working on a machine that has a CUDA compatible GPU. The training arguments below are taken from the HuggingFace tutorial cited in above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, EarlyStoppingCallback\n",
    "\n",
    "early_stop = EarlyStoppingCallback()\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbillingsmoore\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/j/Documents/Projects/MLotsawa/notebooks/size-selection/wandb/run-20240801_204446-0b5h6lto</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/billingsmoore/huggingface/runs/0b5h6lto/workspace' target=\"_blank\">../../models/size-selection/large/</a></strong> to <a href='https://wandb.ai/billingsmoore/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/billingsmoore/huggingface' target=\"_blank\">https://wandb.ai/billingsmoore/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/billingsmoore/huggingface/runs/0b5h6lto/workspace' target=\"_blank\">https://wandb.ai/billingsmoore/huggingface/runs/0b5h6lto/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd17b29c9fb04c1784e4172619e611a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.0054, 'grad_norm': 2.791461229324341, 'learning_rate': 1.9973333333333334e-05, 'epoch': 0.0}\n",
      "{'loss': 3.7206, 'grad_norm': 2.7115252017974854, 'learning_rate': 1.9946666666666667e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5792, 'grad_norm': 3.222254753112793, 'learning_rate': 1.9920000000000002e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4919, 'grad_norm': 2.945887565612793, 'learning_rate': 1.9893333333333335e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4448, 'grad_norm': 3.42431902885437, 'learning_rate': 1.9866666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.3361, 'grad_norm': 3.5975170135498047, 'learning_rate': 1.9840000000000003e-05, 'epoch': 0.02}\n",
      "{'loss': 3.2599, 'grad_norm': 4.015270233154297, 'learning_rate': 1.9813333333333336e-05, 'epoch': 0.03}\n",
      "{'loss': 3.2441, 'grad_norm': 4.453704357147217, 'learning_rate': 1.9786666666666668e-05, 'epoch': 0.03}\n",
      "{'loss': 3.1757, 'grad_norm': 3.2731821537017822, 'learning_rate': 1.976e-05, 'epoch': 0.04}\n",
      "{'loss': 3.1305, 'grad_norm': 4.653375148773193, 'learning_rate': 1.9733333333333336e-05, 'epoch': 0.04}\n",
      "{'loss': 3.086, 'grad_norm': 3.507117748260498, 'learning_rate': 1.970666666666667e-05, 'epoch': 0.04}\n",
      "{'loss': 3.067, 'grad_norm': 3.2900853157043457, 'learning_rate': 1.968e-05, 'epoch': 0.05}\n",
      "{'loss': 3.0317, 'grad_norm': 3.1152050495147705, 'learning_rate': 1.9653333333333334e-05, 'epoch': 0.05}\n",
      "{'loss': 2.9972, 'grad_norm': 3.3805651664733887, 'learning_rate': 1.9626666666666666e-05, 'epoch': 0.06}\n",
      "{'loss': 2.9789, 'grad_norm': 4.040657043457031, 'learning_rate': 1.9600000000000002e-05, 'epoch': 0.06}\n",
      "{'loss': 2.9467, 'grad_norm': 3.7048144340515137, 'learning_rate': 1.9573333333333335e-05, 'epoch': 0.06}\n",
      "{'loss': 2.9154, 'grad_norm': 3.430941104888916, 'learning_rate': 1.954666666666667e-05, 'epoch': 0.07}\n",
      "{'loss': 2.8775, 'grad_norm': 3.5621583461761475, 'learning_rate': 1.9520000000000003e-05, 'epoch': 0.07}\n",
      "{'loss': 2.8669, 'grad_norm': 4.393846035003662, 'learning_rate': 1.9493333333333335e-05, 'epoch': 0.08}\n",
      "{'loss': 2.8223, 'grad_norm': 3.4105353355407715, 'learning_rate': 1.9466666666666668e-05, 'epoch': 0.08}\n",
      "{'loss': 2.801, 'grad_norm': 4.05389928817749, 'learning_rate': 1.944e-05, 'epoch': 0.08}\n",
      "{'loss': 2.7921, 'grad_norm': 3.354267120361328, 'learning_rate': 1.9413333333333336e-05, 'epoch': 0.09}\n",
      "{'loss': 2.7689, 'grad_norm': 3.638576030731201, 'learning_rate': 1.938666666666667e-05, 'epoch': 0.09}\n",
      "{'loss': 2.7725, 'grad_norm': 3.648721694946289, 'learning_rate': 1.936e-05, 'epoch': 0.1}\n",
      "{'loss': 2.7334, 'grad_norm': 3.887636661529541, 'learning_rate': 1.9333333333333333e-05, 'epoch': 0.1}\n",
      "{'loss': 2.7008, 'grad_norm': 3.217473268508911, 'learning_rate': 1.930666666666667e-05, 'epoch': 0.1}\n",
      "{'loss': 2.6694, 'grad_norm': 4.9354729652404785, 'learning_rate': 1.9280000000000002e-05, 'epoch': 0.11}\n",
      "{'loss': 2.6256, 'grad_norm': 4.365251064300537, 'learning_rate': 1.9253333333333334e-05, 'epoch': 0.11}\n",
      "{'loss': 2.6296, 'grad_norm': 4.773930549621582, 'learning_rate': 1.922666666666667e-05, 'epoch': 0.12}\n",
      "{'loss': 2.6452, 'grad_norm': 3.58625864982605, 'learning_rate': 1.9200000000000003e-05, 'epoch': 0.12}\n",
      "{'loss': 2.611, 'grad_norm': 5.243492126464844, 'learning_rate': 1.9173333333333335e-05, 'epoch': 0.12}\n",
      "{'loss': 2.5799, 'grad_norm': 5.49753999710083, 'learning_rate': 1.9146666666666667e-05, 'epoch': 0.13}\n",
      "{'loss': 2.5493, 'grad_norm': 4.355565547943115, 'learning_rate': 1.912e-05, 'epoch': 0.13}\n",
      "{'loss': 2.5092, 'grad_norm': 4.058612823486328, 'learning_rate': 1.9093333333333336e-05, 'epoch': 0.14}\n",
      "{'loss': 2.5433, 'grad_norm': 4.49870491027832, 'learning_rate': 1.9066666666666668e-05, 'epoch': 0.14}\n",
      "{'loss': 2.5309, 'grad_norm': 4.986605644226074, 'learning_rate': 1.904e-05, 'epoch': 0.14}\n",
      "{'loss': 2.5058, 'grad_norm': 4.552873611450195, 'learning_rate': 1.9013333333333333e-05, 'epoch': 0.15}\n",
      "{'loss': 2.4695, 'grad_norm': 4.168509006500244, 'learning_rate': 1.898666666666667e-05, 'epoch': 0.15}\n",
      "{'loss': 2.4548, 'grad_norm': 3.6761057376861572, 'learning_rate': 1.896e-05, 'epoch': 0.16}\n",
      "{'loss': 2.4642, 'grad_norm': 3.71894907951355, 'learning_rate': 1.8933333333333334e-05, 'epoch': 0.16}\n",
      "{'loss': 2.4316, 'grad_norm': 5.149733543395996, 'learning_rate': 1.890666666666667e-05, 'epoch': 0.16}\n",
      "{'loss': 2.3907, 'grad_norm': 4.244248867034912, 'learning_rate': 1.8880000000000002e-05, 'epoch': 0.17}\n",
      "{'loss': 2.4013, 'grad_norm': 4.626126766204834, 'learning_rate': 1.8853333333333335e-05, 'epoch': 0.17}\n",
      "{'loss': 2.3997, 'grad_norm': 5.728376865386963, 'learning_rate': 1.8826666666666667e-05, 'epoch': 0.18}\n",
      "{'loss': 2.3737, 'grad_norm': 3.9878039360046387, 'learning_rate': 1.88e-05, 'epoch': 0.18}\n",
      "{'loss': 2.3288, 'grad_norm': 4.027113437652588, 'learning_rate': 1.8773333333333335e-05, 'epoch': 0.18}\n",
      "{'loss': 2.3363, 'grad_norm': 4.101515293121338, 'learning_rate': 1.8746666666666668e-05, 'epoch': 0.19}\n",
      "{'loss': 2.3512, 'grad_norm': 3.337411403656006, 'learning_rate': 1.8720000000000004e-05, 'epoch': 0.19}\n",
      "{'loss': 2.3319, 'grad_norm': 4.4273858070373535, 'learning_rate': 1.8693333333333333e-05, 'epoch': 0.2}\n",
      "{'loss': 2.351, 'grad_norm': 4.790252685546875, 'learning_rate': 1.866666666666667e-05, 'epoch': 0.2}\n",
      "{'loss': 2.3193, 'grad_norm': 3.8865747451782227, 'learning_rate': 1.864e-05, 'epoch': 0.2}\n",
      "{'loss': 2.318, 'grad_norm': 3.8202829360961914, 'learning_rate': 1.8613333333333334e-05, 'epoch': 0.21}\n",
      "{'loss': 2.2952, 'grad_norm': 4.100327968597412, 'learning_rate': 1.858666666666667e-05, 'epoch': 0.21}\n",
      "{'loss': 2.2916, 'grad_norm': 4.7096333503723145, 'learning_rate': 1.8560000000000002e-05, 'epoch': 0.22}\n",
      "{'loss': 2.2756, 'grad_norm': 4.740995407104492, 'learning_rate': 1.8533333333333334e-05, 'epoch': 0.22}\n",
      "{'loss': 2.245, 'grad_norm': 4.120840072631836, 'learning_rate': 1.8506666666666667e-05, 'epoch': 0.22}\n",
      "{'loss': 2.2457, 'grad_norm': 5.640446186065674, 'learning_rate': 1.8480000000000003e-05, 'epoch': 0.23}\n",
      "{'loss': 2.2031, 'grad_norm': 4.583353042602539, 'learning_rate': 1.8453333333333335e-05, 'epoch': 0.23}\n",
      "{'loss': 2.2287, 'grad_norm': 4.736678600311279, 'learning_rate': 1.8426666666666668e-05, 'epoch': 0.24}\n",
      "{'loss': 2.2028, 'grad_norm': 4.291195869445801, 'learning_rate': 1.8400000000000003e-05, 'epoch': 0.24}\n",
      "{'loss': 2.1838, 'grad_norm': 4.494003772735596, 'learning_rate': 1.8373333333333332e-05, 'epoch': 0.24}\n",
      "{'loss': 2.1917, 'grad_norm': 5.249692440032959, 'learning_rate': 1.834666666666667e-05, 'epoch': 0.25}\n",
      "{'loss': 2.1859, 'grad_norm': 6.34678840637207, 'learning_rate': 1.832e-05, 'epoch': 0.25}\n",
      "{'loss': 2.18, 'grad_norm': 3.755566358566284, 'learning_rate': 1.8293333333333333e-05, 'epoch': 0.26}\n",
      "{'loss': 2.1578, 'grad_norm': 3.9705982208251953, 'learning_rate': 1.826666666666667e-05, 'epoch': 0.26}\n",
      "{'loss': 2.1299, 'grad_norm': 3.8672051429748535, 'learning_rate': 1.824e-05, 'epoch': 0.26}\n",
      "{'loss': 2.135, 'grad_norm': 4.051077842712402, 'learning_rate': 1.8213333333333334e-05, 'epoch': 0.27}\n",
      "{'loss': 2.1485, 'grad_norm': 4.1293745040893555, 'learning_rate': 1.8186666666666666e-05, 'epoch': 0.27}\n",
      "{'loss': 2.1405, 'grad_norm': 4.3978447914123535, 'learning_rate': 1.8160000000000002e-05, 'epoch': 0.28}\n",
      "{'loss': 2.0964, 'grad_norm': 4.284893989562988, 'learning_rate': 1.8133333333333335e-05, 'epoch': 0.28}\n",
      "{'loss': 2.1127, 'grad_norm': 4.279170989990234, 'learning_rate': 1.8106666666666667e-05, 'epoch': 0.28}\n",
      "{'loss': 2.0883, 'grad_norm': 4.851828575134277, 'learning_rate': 1.8080000000000003e-05, 'epoch': 0.29}\n",
      "{'loss': 2.0883, 'grad_norm': 4.848843097686768, 'learning_rate': 1.8053333333333332e-05, 'epoch': 0.29}\n",
      "{'loss': 2.0612, 'grad_norm': 3.880239248275757, 'learning_rate': 1.8026666666666668e-05, 'epoch': 0.3}\n",
      "{'loss': 2.1044, 'grad_norm': 4.755860805511475, 'learning_rate': 1.8e-05, 'epoch': 0.3}\n",
      "{'loss': 2.0729, 'grad_norm': 5.247093200683594, 'learning_rate': 1.7973333333333333e-05, 'epoch': 0.3}\n",
      "{'loss': 2.0663, 'grad_norm': 3.7599937915802, 'learning_rate': 1.794666666666667e-05, 'epoch': 0.31}\n",
      "{'loss': 2.0807, 'grad_norm': 5.597867965698242, 'learning_rate': 1.792e-05, 'epoch': 0.31}\n",
      "{'loss': 2.0425, 'grad_norm': 4.121315002441406, 'learning_rate': 1.7893333333333337e-05, 'epoch': 0.32}\n",
      "{'loss': 2.0308, 'grad_norm': 4.863097190856934, 'learning_rate': 1.7866666666666666e-05, 'epoch': 0.32}\n",
      "{'loss': 2.0226, 'grad_norm': 4.105266094207764, 'learning_rate': 1.7840000000000002e-05, 'epoch': 0.32}\n",
      "{'loss': 2.0266, 'grad_norm': 4.675320148468018, 'learning_rate': 1.7813333333333334e-05, 'epoch': 0.33}\n",
      "{'loss': 2.0144, 'grad_norm': 3.7971577644348145, 'learning_rate': 1.7786666666666667e-05, 'epoch': 0.33}\n",
      "{'loss': 1.9673, 'grad_norm': 3.7700228691101074, 'learning_rate': 1.7760000000000003e-05, 'epoch': 0.34}\n",
      "{'loss': 1.9901, 'grad_norm': 5.112252235412598, 'learning_rate': 1.7733333333333335e-05, 'epoch': 0.34}\n",
      "{'loss': 2.005, 'grad_norm': 4.300159931182861, 'learning_rate': 1.7706666666666668e-05, 'epoch': 0.34}\n",
      "{'loss': 1.9939, 'grad_norm': 4.756731033325195, 'learning_rate': 1.768e-05, 'epoch': 0.35}\n",
      "{'loss': 2.0006, 'grad_norm': 4.653805255889893, 'learning_rate': 1.7653333333333336e-05, 'epoch': 0.35}\n",
      "{'loss': 1.9762, 'grad_norm': 5.227838516235352, 'learning_rate': 1.762666666666667e-05, 'epoch': 0.36}\n",
      "{'loss': 1.9577, 'grad_norm': 3.9574131965637207, 'learning_rate': 1.76e-05, 'epoch': 0.36}\n",
      "{'loss': 1.9656, 'grad_norm': 4.054873943328857, 'learning_rate': 1.7573333333333337e-05, 'epoch': 0.36}\n",
      "{'loss': 1.9308, 'grad_norm': 3.755815029144287, 'learning_rate': 1.7546666666666666e-05, 'epoch': 0.37}\n",
      "{'loss': 1.9169, 'grad_norm': 4.467961311340332, 'learning_rate': 1.752e-05, 'epoch': 0.37}\n",
      "{'loss': 1.9326, 'grad_norm': 4.252990245819092, 'learning_rate': 1.7493333333333334e-05, 'epoch': 0.38}\n",
      "{'loss': 1.9597, 'grad_norm': 4.6475677490234375, 'learning_rate': 1.7466666666666667e-05, 'epoch': 0.38}\n",
      "{'loss': 1.9184, 'grad_norm': 4.40748929977417, 'learning_rate': 1.7440000000000002e-05, 'epoch': 0.38}\n",
      "{'loss': 1.9114, 'grad_norm': 3.991245746612549, 'learning_rate': 1.7413333333333335e-05, 'epoch': 0.39}\n",
      "{'loss': 1.9078, 'grad_norm': 3.598215103149414, 'learning_rate': 1.7386666666666667e-05, 'epoch': 0.39}\n",
      "{'loss': 1.8758, 'grad_norm': 4.770265579223633, 'learning_rate': 1.736e-05, 'epoch': 0.4}\n",
      "{'loss': 1.9143, 'grad_norm': 5.4429402351379395, 'learning_rate': 1.7333333333333336e-05, 'epoch': 0.4}\n",
      "{'loss': 1.8872, 'grad_norm': 5.871974945068359, 'learning_rate': 1.7306666666666668e-05, 'epoch': 0.4}\n",
      "{'loss': 1.8697, 'grad_norm': 4.712128639221191, 'learning_rate': 1.728e-05, 'epoch': 0.41}\n",
      "{'loss': 1.8667, 'grad_norm': 5.339282512664795, 'learning_rate': 1.7253333333333336e-05, 'epoch': 0.41}\n",
      "{'loss': 1.8838, 'grad_norm': 4.503620624542236, 'learning_rate': 1.7226666666666665e-05, 'epoch': 0.42}\n",
      "{'loss': 1.8123, 'grad_norm': 4.579555988311768, 'learning_rate': 1.72e-05, 'epoch': 0.42}\n",
      "{'loss': 1.8549, 'grad_norm': 4.854654788970947, 'learning_rate': 1.7173333333333334e-05, 'epoch': 0.42}\n",
      "{'loss': 1.836, 'grad_norm': 3.013859272003174, 'learning_rate': 1.7146666666666666e-05, 'epoch': 0.43}\n",
      "{'loss': 1.8345, 'grad_norm': 5.1493024826049805, 'learning_rate': 1.7120000000000002e-05, 'epoch': 0.43}\n",
      "{'loss': 1.8515, 'grad_norm': 4.510061264038086, 'learning_rate': 1.7093333333333335e-05, 'epoch': 0.44}\n",
      "{'loss': 1.8438, 'grad_norm': 4.083684921264648, 'learning_rate': 1.706666666666667e-05, 'epoch': 0.44}\n",
      "{'loss': 1.8324, 'grad_norm': 5.101161003112793, 'learning_rate': 1.704e-05, 'epoch': 0.44}\n",
      "{'loss': 1.8429, 'grad_norm': 4.569437503814697, 'learning_rate': 1.7013333333333335e-05, 'epoch': 0.45}\n",
      "{'loss': 1.798, 'grad_norm': 4.017906188964844, 'learning_rate': 1.6986666666666668e-05, 'epoch': 0.45}\n",
      "{'loss': 1.8022, 'grad_norm': 4.2461066246032715, 'learning_rate': 1.696e-05, 'epoch': 0.46}\n",
      "{'loss': 1.8102, 'grad_norm': 3.458320379257202, 'learning_rate': 1.6933333333333336e-05, 'epoch': 0.46}\n",
      "{'loss': 1.8171, 'grad_norm': 4.049644947052002, 'learning_rate': 1.690666666666667e-05, 'epoch': 0.46}\n",
      "{'loss': 1.7867, 'grad_norm': 4.81636905670166, 'learning_rate': 1.688e-05, 'epoch': 0.47}\n",
      "{'loss': 1.7992, 'grad_norm': 5.507236957550049, 'learning_rate': 1.6853333333333333e-05, 'epoch': 0.47}\n",
      "{'loss': 1.8021, 'grad_norm': 4.467095375061035, 'learning_rate': 1.682666666666667e-05, 'epoch': 0.48}\n",
      "{'loss': 1.7651, 'grad_norm': 4.757768154144287, 'learning_rate': 1.6800000000000002e-05, 'epoch': 0.48}\n",
      "{'loss': 1.7629, 'grad_norm': 6.2038702964782715, 'learning_rate': 1.6773333333333334e-05, 'epoch': 0.48}\n",
      "{'loss': 1.7828, 'grad_norm': 5.566616535186768, 'learning_rate': 1.674666666666667e-05, 'epoch': 0.49}\n",
      "{'loss': 1.7597, 'grad_norm': 5.664967060089111, 'learning_rate': 1.672e-05, 'epoch': 0.49}\n",
      "{'loss': 1.7725, 'grad_norm': 4.541511058807373, 'learning_rate': 1.6693333333333335e-05, 'epoch': 0.5}\n",
      "{'loss': 1.7227, 'grad_norm': 4.16813325881958, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.5}\n",
      "{'loss': 1.7471, 'grad_norm': 4.219049453735352, 'learning_rate': 1.664e-05, 'epoch': 0.5}\n",
      "{'loss': 1.7448, 'grad_norm': 3.395292043685913, 'learning_rate': 1.6613333333333336e-05, 'epoch': 0.51}\n",
      "{'loss': 1.7522, 'grad_norm': 3.9869070053100586, 'learning_rate': 1.6586666666666668e-05, 'epoch': 0.51}\n",
      "{'loss': 1.7462, 'grad_norm': 5.479104518890381, 'learning_rate': 1.656e-05, 'epoch': 0.52}\n",
      "{'loss': 1.6953, 'grad_norm': 4.339037895202637, 'learning_rate': 1.6533333333333333e-05, 'epoch': 0.52}\n",
      "{'loss': 1.75, 'grad_norm': 5.469781398773193, 'learning_rate': 1.650666666666667e-05, 'epoch': 0.52}\n",
      "{'loss': 1.7155, 'grad_norm': 4.039904594421387, 'learning_rate': 1.648e-05, 'epoch': 0.53}\n",
      "{'loss': 1.685, 'grad_norm': 5.57533073425293, 'learning_rate': 1.6453333333333334e-05, 'epoch': 0.53}\n",
      "{'loss': 1.7076, 'grad_norm': 4.040968894958496, 'learning_rate': 1.642666666666667e-05, 'epoch': 0.54}\n",
      "{'loss': 1.6941, 'grad_norm': 3.716961145401001, 'learning_rate': 1.64e-05, 'epoch': 0.54}\n",
      "{'loss': 1.6854, 'grad_norm': 5.185647010803223, 'learning_rate': 1.6373333333333335e-05, 'epoch': 0.54}\n",
      "{'loss': 1.7079, 'grad_norm': 5.137222766876221, 'learning_rate': 1.6346666666666667e-05, 'epoch': 0.55}\n",
      "{'loss': 1.6651, 'grad_norm': 4.736074924468994, 'learning_rate': 1.632e-05, 'epoch': 0.55}\n",
      "{'loss': 1.6916, 'grad_norm': 5.652517795562744, 'learning_rate': 1.6293333333333335e-05, 'epoch': 0.56}\n",
      "{'loss': 1.6693, 'grad_norm': 4.027339935302734, 'learning_rate': 1.6266666666666668e-05, 'epoch': 0.56}\n",
      "{'loss': 1.7013, 'grad_norm': 4.200071334838867, 'learning_rate': 1.6240000000000004e-05, 'epoch': 0.56}\n",
      "{'loss': 1.6449, 'grad_norm': 6.623948097229004, 'learning_rate': 1.6213333333333333e-05, 'epoch': 0.57}\n",
      "{'loss': 1.6882, 'grad_norm': 4.384230613708496, 'learning_rate': 1.618666666666667e-05, 'epoch': 0.57}\n",
      "{'loss': 1.6387, 'grad_norm': 5.566612243652344, 'learning_rate': 1.616e-05, 'epoch': 0.58}\n",
      "{'loss': 1.6673, 'grad_norm': 4.374314785003662, 'learning_rate': 1.6133333333333334e-05, 'epoch': 0.58}\n",
      "{'loss': 1.6421, 'grad_norm': 5.820314407348633, 'learning_rate': 1.610666666666667e-05, 'epoch': 0.58}\n",
      "{'loss': 1.6126, 'grad_norm': 3.829059362411499, 'learning_rate': 1.6080000000000002e-05, 'epoch': 0.59}\n",
      "{'loss': 1.6397, 'grad_norm': 4.84096622467041, 'learning_rate': 1.6053333333333334e-05, 'epoch': 0.59}\n",
      "{'loss': 1.6207, 'grad_norm': 3.7155282497406006, 'learning_rate': 1.6026666666666667e-05, 'epoch': 0.6}\n",
      "{'loss': 1.6238, 'grad_norm': 4.619533538818359, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.6}\n",
      "{'loss': 1.6555, 'grad_norm': 4.901686668395996, 'learning_rate': 1.5973333333333335e-05, 'epoch': 0.6}\n",
      "{'loss': 1.6363, 'grad_norm': 5.062745094299316, 'learning_rate': 1.5946666666666668e-05, 'epoch': 0.61}\n",
      "{'loss': 1.6058, 'grad_norm': 5.866258144378662, 'learning_rate': 1.5920000000000003e-05, 'epoch': 0.61}\n",
      "{'loss': 1.592, 'grad_norm': 4.212147235870361, 'learning_rate': 1.5893333333333333e-05, 'epoch': 0.62}\n",
      "{'loss': 1.5863, 'grad_norm': 5.392477512359619, 'learning_rate': 1.586666666666667e-05, 'epoch': 0.62}\n",
      "{'loss': 1.585, 'grad_norm': 3.468573570251465, 'learning_rate': 1.584e-05, 'epoch': 0.62}\n",
      "{'loss': 1.6243, 'grad_norm': 4.483604907989502, 'learning_rate': 1.5813333333333333e-05, 'epoch': 0.63}\n",
      "{'loss': 1.5954, 'grad_norm': 5.072648525238037, 'learning_rate': 1.578666666666667e-05, 'epoch': 0.63}\n",
      "{'loss': 1.5723, 'grad_norm': 6.1488213539123535, 'learning_rate': 1.576e-05, 'epoch': 0.64}\n",
      "{'loss': 1.5734, 'grad_norm': 4.005717754364014, 'learning_rate': 1.5733333333333334e-05, 'epoch': 0.64}\n",
      "{'loss': 1.5844, 'grad_norm': 5.944024085998535, 'learning_rate': 1.5706666666666666e-05, 'epoch': 0.64}\n",
      "{'loss': 1.5801, 'grad_norm': 5.229593276977539, 'learning_rate': 1.5680000000000002e-05, 'epoch': 0.65}\n",
      "{'loss': 1.5869, 'grad_norm': 4.250185012817383, 'learning_rate': 1.5653333333333335e-05, 'epoch': 0.65}\n",
      "{'loss': 1.5644, 'grad_norm': 4.723194599151611, 'learning_rate': 1.5626666666666667e-05, 'epoch': 0.66}\n",
      "{'loss': 1.5489, 'grad_norm': 5.682969570159912, 'learning_rate': 1.5600000000000003e-05, 'epoch': 0.66}\n",
      "{'loss': 1.5818, 'grad_norm': 5.7580952644348145, 'learning_rate': 1.5573333333333332e-05, 'epoch': 0.66}\n",
      "{'loss': 1.5683, 'grad_norm': 4.201444149017334, 'learning_rate': 1.5546666666666668e-05, 'epoch': 0.67}\n",
      "{'loss': 1.5705, 'grad_norm': 5.161681652069092, 'learning_rate': 1.552e-05, 'epoch': 0.67}\n",
      "{'loss': 1.563, 'grad_norm': 6.033304214477539, 'learning_rate': 1.5493333333333333e-05, 'epoch': 0.68}\n",
      "{'loss': 1.5336, 'grad_norm': 5.640916347503662, 'learning_rate': 1.546666666666667e-05, 'epoch': 0.68}\n",
      "{'loss': 1.5307, 'grad_norm': 5.3477559089660645, 'learning_rate': 1.544e-05, 'epoch': 0.68}\n",
      "{'loss': 1.5668, 'grad_norm': 4.086909294128418, 'learning_rate': 1.5413333333333337e-05, 'epoch': 0.69}\n",
      "{'loss': 1.5374, 'grad_norm': 3.4374921321868896, 'learning_rate': 1.5386666666666666e-05, 'epoch': 0.69}\n",
      "{'loss': 1.5474, 'grad_norm': 4.485706329345703, 'learning_rate': 1.5360000000000002e-05, 'epoch': 0.7}\n",
      "{'loss': 1.5421, 'grad_norm': 4.226168155670166, 'learning_rate': 1.5333333333333334e-05, 'epoch': 0.7}\n",
      "{'loss': 1.5339, 'grad_norm': 5.01578950881958, 'learning_rate': 1.5306666666666667e-05, 'epoch': 0.7}\n",
      "{'loss': 1.5421, 'grad_norm': 4.911323070526123, 'learning_rate': 1.5280000000000003e-05, 'epoch': 0.71}\n",
      "{'loss': 1.5244, 'grad_norm': 4.778854846954346, 'learning_rate': 1.5253333333333335e-05, 'epoch': 0.71}\n",
      "{'loss': 1.5037, 'grad_norm': 6.449610710144043, 'learning_rate': 1.5226666666666668e-05, 'epoch': 0.72}\n",
      "{'loss': 1.5004, 'grad_norm': 6.922495365142822, 'learning_rate': 1.5200000000000002e-05, 'epoch': 0.72}\n",
      "{'loss': 1.5023, 'grad_norm': 4.623695373535156, 'learning_rate': 1.5173333333333336e-05, 'epoch': 0.72}\n",
      "{'loss': 1.4866, 'grad_norm': 4.397989749908447, 'learning_rate': 1.5146666666666667e-05, 'epoch': 0.73}\n",
      "{'loss': 1.5267, 'grad_norm': 5.944833278656006, 'learning_rate': 1.5120000000000001e-05, 'epoch': 0.73}\n",
      "{'loss': 1.5053, 'grad_norm': 3.3672542572021484, 'learning_rate': 1.5093333333333335e-05, 'epoch': 0.74}\n",
      "{'loss': 1.4588, 'grad_norm': 5.867831230163574, 'learning_rate': 1.5066666666666668e-05, 'epoch': 0.74}\n",
      "{'loss': 1.4509, 'grad_norm': 4.823091983795166, 'learning_rate': 1.5040000000000002e-05, 'epoch': 0.74}\n",
      "{'loss': 1.4699, 'grad_norm': 4.4469685554504395, 'learning_rate': 1.5013333333333336e-05, 'epoch': 0.75}\n",
      "{'loss': 1.5123, 'grad_norm': 4.978553771972656, 'learning_rate': 1.4986666666666667e-05, 'epoch': 0.75}\n",
      "{'loss': 1.4911, 'grad_norm': 4.308465003967285, 'learning_rate': 1.496e-05, 'epoch': 0.76}\n",
      "{'loss': 1.4681, 'grad_norm': 4.970894813537598, 'learning_rate': 1.4933333333333335e-05, 'epoch': 0.76}\n",
      "{'loss': 1.462, 'grad_norm': 4.434682846069336, 'learning_rate': 1.4906666666666667e-05, 'epoch': 0.76}\n",
      "{'loss': 1.4854, 'grad_norm': 4.14195442199707, 'learning_rate': 1.4880000000000002e-05, 'epoch': 0.77}\n",
      "{'loss': 1.4519, 'grad_norm': 4.776358604431152, 'learning_rate': 1.4853333333333336e-05, 'epoch': 0.77}\n",
      "{'loss': 1.502, 'grad_norm': 5.47219181060791, 'learning_rate': 1.4826666666666666e-05, 'epoch': 0.78}\n",
      "{'loss': 1.4694, 'grad_norm': 3.8730854988098145, 'learning_rate': 1.48e-05, 'epoch': 0.78}\n",
      "{'loss': 1.4618, 'grad_norm': 5.4443559646606445, 'learning_rate': 1.4773333333333335e-05, 'epoch': 0.78}\n",
      "{'loss': 1.4559, 'grad_norm': 6.437221050262451, 'learning_rate': 1.4746666666666667e-05, 'epoch': 0.79}\n",
      "{'loss': 1.4615, 'grad_norm': 3.712090492248535, 'learning_rate': 1.4720000000000001e-05, 'epoch': 0.79}\n",
      "{'loss': 1.4455, 'grad_norm': 6.034478187561035, 'learning_rate': 1.4693333333333336e-05, 'epoch': 0.8}\n",
      "{'loss': 1.4532, 'grad_norm': 5.268585681915283, 'learning_rate': 1.4666666666666666e-05, 'epoch': 0.8}\n",
      "{'loss': 1.41, 'grad_norm': 5.574986934661865, 'learning_rate': 1.464e-05, 'epoch': 0.8}\n",
      "{'loss': 1.4416, 'grad_norm': 5.178922176361084, 'learning_rate': 1.4613333333333335e-05, 'epoch': 0.81}\n",
      "{'loss': 1.4392, 'grad_norm': 4.9656453132629395, 'learning_rate': 1.4586666666666667e-05, 'epoch': 0.81}\n",
      "{'loss': 1.4018, 'grad_norm': 5.075153827667236, 'learning_rate': 1.4560000000000001e-05, 'epoch': 0.82}\n",
      "{'loss': 1.3984, 'grad_norm': 3.8705480098724365, 'learning_rate': 1.4533333333333335e-05, 'epoch': 0.82}\n",
      "{'loss': 1.4462, 'grad_norm': 4.746752738952637, 'learning_rate': 1.450666666666667e-05, 'epoch': 0.82}\n",
      "{'loss': 1.394, 'grad_norm': 6.511900901794434, 'learning_rate': 1.448e-05, 'epoch': 0.83}\n",
      "{'loss': 1.4098, 'grad_norm': 5.6507697105407715, 'learning_rate': 1.4453333333333334e-05, 'epoch': 0.83}\n",
      "{'loss': 1.4245, 'grad_norm': 5.4307332038879395, 'learning_rate': 1.4426666666666669e-05, 'epoch': 0.84}\n",
      "{'loss': 1.3955, 'grad_norm': 4.286299228668213, 'learning_rate': 1.4400000000000001e-05, 'epoch': 0.84}\n",
      "{'loss': 1.3858, 'grad_norm': 6.022514820098877, 'learning_rate': 1.4373333333333335e-05, 'epoch': 0.84}\n",
      "{'loss': 1.3979, 'grad_norm': 4.477996349334717, 'learning_rate': 1.434666666666667e-05, 'epoch': 0.85}\n",
      "{'loss': 1.4224, 'grad_norm': 5.690354347229004, 'learning_rate': 1.432e-05, 'epoch': 0.85}\n",
      "{'loss': 1.3899, 'grad_norm': 4.430185794830322, 'learning_rate': 1.4293333333333334e-05, 'epoch': 0.86}\n",
      "{'loss': 1.3943, 'grad_norm': 5.284982681274414, 'learning_rate': 1.4266666666666668e-05, 'epoch': 0.86}\n",
      "{'loss': 1.3724, 'grad_norm': 4.650676727294922, 'learning_rate': 1.4240000000000001e-05, 'epoch': 0.86}\n",
      "{'loss': 1.389, 'grad_norm': 5.612548828125, 'learning_rate': 1.4213333333333335e-05, 'epoch': 0.87}\n",
      "{'loss': 1.3638, 'grad_norm': 4.6834330558776855, 'learning_rate': 1.418666666666667e-05, 'epoch': 0.87}\n",
      "{'loss': 1.3675, 'grad_norm': 5.1242995262146, 'learning_rate': 1.416e-05, 'epoch': 0.88}\n",
      "{'loss': 1.3923, 'grad_norm': 4.613930702209473, 'learning_rate': 1.4133333333333334e-05, 'epoch': 0.88}\n",
      "{'loss': 1.3641, 'grad_norm': 4.765722274780273, 'learning_rate': 1.4106666666666668e-05, 'epoch': 0.88}\n",
      "{'loss': 1.3635, 'grad_norm': 5.2508745193481445, 'learning_rate': 1.408e-05, 'epoch': 0.89}\n",
      "{'loss': 1.3756, 'grad_norm': 5.47445821762085, 'learning_rate': 1.4053333333333335e-05, 'epoch': 0.89}\n",
      "{'loss': 1.3594, 'grad_norm': 5.112887382507324, 'learning_rate': 1.4026666666666669e-05, 'epoch': 0.9}\n",
      "{'loss': 1.3898, 'grad_norm': 4.751089572906494, 'learning_rate': 1.4e-05, 'epoch': 0.9}\n",
      "{'loss': 1.335, 'grad_norm': 4.565461158752441, 'learning_rate': 1.3973333333333334e-05, 'epoch': 0.9}\n",
      "{'loss': 1.3436, 'grad_norm': 4.844635009765625, 'learning_rate': 1.3946666666666668e-05, 'epoch': 0.91}\n",
      "{'loss': 1.3373, 'grad_norm': 4.838853359222412, 'learning_rate': 1.392e-05, 'epoch': 0.91}\n",
      "{'loss': 1.3432, 'grad_norm': 6.410946846008301, 'learning_rate': 1.3893333333333335e-05, 'epoch': 0.92}\n",
      "{'loss': 1.3334, 'grad_norm': 4.799595355987549, 'learning_rate': 1.3866666666666669e-05, 'epoch': 0.92}\n",
      "{'loss': 1.3131, 'grad_norm': 3.969371795654297, 'learning_rate': 1.384e-05, 'epoch': 0.92}\n",
      "{'loss': 1.3431, 'grad_norm': 5.632304668426514, 'learning_rate': 1.3813333333333334e-05, 'epoch': 0.93}\n",
      "{'loss': 1.3147, 'grad_norm': 4.481265544891357, 'learning_rate': 1.3786666666666668e-05, 'epoch': 0.93}\n",
      "{'loss': 1.3532, 'grad_norm': 4.494072437286377, 'learning_rate': 1.376e-05, 'epoch': 0.94}\n",
      "{'loss': 1.3103, 'grad_norm': 5.0802001953125, 'learning_rate': 1.3733333333333335e-05, 'epoch': 0.94}\n",
      "{'loss': 1.3294, 'grad_norm': 5.577124118804932, 'learning_rate': 1.3706666666666669e-05, 'epoch': 0.94}\n",
      "{'loss': 1.3163, 'grad_norm': 4.937932968139648, 'learning_rate': 1.3680000000000003e-05, 'epoch': 0.95}\n",
      "{'loss': 1.3084, 'grad_norm': 3.661999225616455, 'learning_rate': 1.3653333333333334e-05, 'epoch': 0.95}\n",
      "{'loss': 1.3198, 'grad_norm': 4.0246782302856445, 'learning_rate': 1.3626666666666668e-05, 'epoch': 0.96}\n",
      "{'loss': 1.3545, 'grad_norm': 6.430075645446777, 'learning_rate': 1.3600000000000002e-05, 'epoch': 0.96}\n",
      "{'loss': 1.2991, 'grad_norm': 5.2123823165893555, 'learning_rate': 1.3573333333333334e-05, 'epoch': 0.96}\n",
      "{'loss': 1.3004, 'grad_norm': 4.058746337890625, 'learning_rate': 1.3546666666666669e-05, 'epoch': 0.97}\n",
      "{'loss': 1.3153, 'grad_norm': 3.729759454727173, 'learning_rate': 1.3520000000000003e-05, 'epoch': 0.97}\n",
      "{'loss': 1.3218, 'grad_norm': 5.34182596206665, 'learning_rate': 1.3493333333333333e-05, 'epoch': 0.98}\n",
      "{'loss': 1.2767, 'grad_norm': 5.143995761871338, 'learning_rate': 1.3466666666666668e-05, 'epoch': 0.98}\n",
      "{'loss': 1.2884, 'grad_norm': 6.0250983238220215, 'learning_rate': 1.3440000000000002e-05, 'epoch': 0.98}\n",
      "{'loss': 1.2921, 'grad_norm': 5.330780506134033, 'learning_rate': 1.3413333333333334e-05, 'epoch': 0.99}\n",
      "{'loss': 1.2755, 'grad_norm': 5.035428524017334, 'learning_rate': 1.3386666666666668e-05, 'epoch': 0.99}\n",
      "{'loss': 1.253, 'grad_norm': 5.637801647186279, 'learning_rate': 1.3360000000000003e-05, 'epoch': 1.0}\n",
      "{'loss': 1.2703, 'grad_norm': 6.51718807220459, 'learning_rate': 1.3333333333333333e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/j/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db666eb08b574635940e28efbe898034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9471283555030823, 'eval_bleu': 34.1513, 'eval_gen_len': 12.7709, 'eval_runtime': 10288.2974, 'eval_samples_per_second': 9.72, 'eval_steps_per_second': 1.215, 'epoch': 1.0}\n",
      "{'loss': 1.237, 'grad_norm': 4.952690601348877, 'learning_rate': 1.3306666666666667e-05, 'epoch': 1.0}\n",
      "{'loss': 1.2496, 'grad_norm': 5.2980546951293945, 'learning_rate': 1.3280000000000002e-05, 'epoch': 1.01}\n",
      "{'loss': 1.2195, 'grad_norm': 4.0981292724609375, 'learning_rate': 1.3253333333333334e-05, 'epoch': 1.01}\n",
      "{'loss': 1.2483, 'grad_norm': 6.4036431312561035, 'learning_rate': 1.3226666666666668e-05, 'epoch': 1.02}\n",
      "{'loss': 1.2435, 'grad_norm': 4.18477201461792, 'learning_rate': 1.3200000000000002e-05, 'epoch': 1.02}\n",
      "{'loss': 1.2049, 'grad_norm': 4.696059703826904, 'learning_rate': 1.3173333333333333e-05, 'epoch': 1.02}\n",
      "{'loss': 1.2498, 'grad_norm': 4.632524013519287, 'learning_rate': 1.3146666666666667e-05, 'epoch': 1.03}\n",
      "{'loss': 1.2377, 'grad_norm': 4.924367904663086, 'learning_rate': 1.3120000000000001e-05, 'epoch': 1.03}\n",
      "{'loss': 1.2106, 'grad_norm': 5.236825942993164, 'learning_rate': 1.3093333333333334e-05, 'epoch': 1.04}\n",
      "{'loss': 1.2258, 'grad_norm': 5.148009300231934, 'learning_rate': 1.3066666666666668e-05, 'epoch': 1.04}\n",
      "{'loss': 1.1923, 'grad_norm': 4.673605442047119, 'learning_rate': 1.3040000000000002e-05, 'epoch': 1.04}\n",
      "{'loss': 1.2424, 'grad_norm': 5.120540618896484, 'learning_rate': 1.3013333333333333e-05, 'epoch': 1.05}\n",
      "{'loss': 1.22, 'grad_norm': 5.006062984466553, 'learning_rate': 1.2986666666666667e-05, 'epoch': 1.05}\n",
      "{'loss': 1.2136, 'grad_norm': 5.043941974639893, 'learning_rate': 1.2960000000000001e-05, 'epoch': 1.06}\n",
      "{'loss': 1.2319, 'grad_norm': 4.743189334869385, 'learning_rate': 1.2933333333333334e-05, 'epoch': 1.06}\n",
      "{'loss': 1.2204, 'grad_norm': 5.799910545349121, 'learning_rate': 1.2906666666666668e-05, 'epoch': 1.06}\n",
      "{'loss': 1.1876, 'grad_norm': 5.146975994110107, 'learning_rate': 1.2880000000000002e-05, 'epoch': 1.07}\n",
      "{'loss': 1.212, 'grad_norm': 5.5836639404296875, 'learning_rate': 1.2853333333333336e-05, 'epoch': 1.07}\n",
      "{'loss': 1.2134, 'grad_norm': 4.637167930603027, 'learning_rate': 1.2826666666666667e-05, 'epoch': 1.08}\n",
      "{'loss': 1.1961, 'grad_norm': 4.953854084014893, 'learning_rate': 1.2800000000000001e-05, 'epoch': 1.08}\n",
      "{'loss': 1.1852, 'grad_norm': 5.8683390617370605, 'learning_rate': 1.2773333333333335e-05, 'epoch': 1.08}\n",
      "{'loss': 1.218, 'grad_norm': 4.9324846267700195, 'learning_rate': 1.2746666666666668e-05, 'epoch': 1.09}\n",
      "{'loss': 1.201, 'grad_norm': 5.506784915924072, 'learning_rate': 1.2720000000000002e-05, 'epoch': 1.09}\n",
      "{'loss': 1.1747, 'grad_norm': 5.36843204498291, 'learning_rate': 1.2693333333333336e-05, 'epoch': 1.1}\n",
      "{'loss': 1.1974, 'grad_norm': 5.335346221923828, 'learning_rate': 1.2666666666666667e-05, 'epoch': 1.1}\n",
      "{'loss': 1.1742, 'grad_norm': 6.6619038581848145, 'learning_rate': 1.2640000000000001e-05, 'epoch': 1.1}\n",
      "{'loss': 1.1862, 'grad_norm': 5.221574306488037, 'learning_rate': 1.2613333333333335e-05, 'epoch': 1.11}\n",
      "{'loss': 1.1858, 'grad_norm': 6.607265472412109, 'learning_rate': 1.2586666666666668e-05, 'epoch': 1.11}\n",
      "{'loss': 1.1936, 'grad_norm': 5.459232330322266, 'learning_rate': 1.2560000000000002e-05, 'epoch': 1.12}\n",
      "{'loss': 1.1943, 'grad_norm': 4.929943561553955, 'learning_rate': 1.2533333333333336e-05, 'epoch': 1.12}\n",
      "{'loss': 1.1859, 'grad_norm': 3.8146562576293945, 'learning_rate': 1.2506666666666667e-05, 'epoch': 1.12}\n",
      "{'loss': 1.192, 'grad_norm': 6.490721702575684, 'learning_rate': 1.248e-05, 'epoch': 1.13}\n",
      "{'loss': 1.179, 'grad_norm': 5.061293125152588, 'learning_rate': 1.2453333333333335e-05, 'epoch': 1.13}\n",
      "{'loss': 1.1656, 'grad_norm': 4.806419372558594, 'learning_rate': 1.2426666666666667e-05, 'epoch': 1.14}\n",
      "{'loss': 1.1951, 'grad_norm': 6.854770183563232, 'learning_rate': 1.2400000000000002e-05, 'epoch': 1.14}\n",
      "{'loss': 1.1636, 'grad_norm': 3.865685224533081, 'learning_rate': 1.2373333333333336e-05, 'epoch': 1.14}\n",
      "{'loss': 1.1692, 'grad_norm': 4.707239151000977, 'learning_rate': 1.2346666666666666e-05, 'epoch': 1.15}\n",
      "{'loss': 1.1446, 'grad_norm': 4.861900806427002, 'learning_rate': 1.232e-05, 'epoch': 1.15}\n",
      "{'loss': 1.1799, 'grad_norm': 7.333686351776123, 'learning_rate': 1.2293333333333335e-05, 'epoch': 1.16}\n",
      "{'loss': 1.1526, 'grad_norm': 5.380692481994629, 'learning_rate': 1.2266666666666667e-05, 'epoch': 1.16}\n",
      "{'loss': 1.1591, 'grad_norm': 4.5051469802856445, 'learning_rate': 1.2240000000000001e-05, 'epoch': 1.16}\n",
      "{'loss': 1.1618, 'grad_norm': 4.712071418762207, 'learning_rate': 1.2213333333333336e-05, 'epoch': 1.17}\n",
      "{'loss': 1.144, 'grad_norm': 5.524512767791748, 'learning_rate': 1.2186666666666666e-05, 'epoch': 1.17}\n",
      "{'loss': 1.1328, 'grad_norm': 6.034078598022461, 'learning_rate': 1.216e-05, 'epoch': 1.18}\n",
      "{'loss': 1.1661, 'grad_norm': 6.055247783660889, 'learning_rate': 1.2133333333333335e-05, 'epoch': 1.18}\n",
      "{'loss': 1.151, 'grad_norm': 4.406457424163818, 'learning_rate': 1.2106666666666667e-05, 'epoch': 1.18}\n",
      "{'loss': 1.1662, 'grad_norm': 5.931417942047119, 'learning_rate': 1.2080000000000001e-05, 'epoch': 1.19}\n",
      "{'loss': 1.1282, 'grad_norm': 5.309990882873535, 'learning_rate': 1.2053333333333335e-05, 'epoch': 1.19}\n",
      "{'loss': 1.1371, 'grad_norm': 6.399430274963379, 'learning_rate': 1.202666666666667e-05, 'epoch': 1.2}\n",
      "{'loss': 1.1263, 'grad_norm': 5.729827880859375, 'learning_rate': 1.2e-05, 'epoch': 1.2}\n",
      "{'loss': 1.133, 'grad_norm': 6.403941631317139, 'learning_rate': 1.1973333333333334e-05, 'epoch': 1.2}\n",
      "{'loss': 1.1499, 'grad_norm': 6.688885688781738, 'learning_rate': 1.1946666666666669e-05, 'epoch': 1.21}\n",
      "{'loss': 1.1412, 'grad_norm': 5.238432884216309, 'learning_rate': 1.1920000000000001e-05, 'epoch': 1.21}\n",
      "{'loss': 1.1209, 'grad_norm': 6.522316932678223, 'learning_rate': 1.1893333333333335e-05, 'epoch': 1.22}\n",
      "{'loss': 1.1375, 'grad_norm': 4.560640811920166, 'learning_rate': 1.186666666666667e-05, 'epoch': 1.22}\n",
      "{'loss': 1.1464, 'grad_norm': 4.184454441070557, 'learning_rate': 1.184e-05, 'epoch': 1.22}\n",
      "{'loss': 1.1209, 'grad_norm': 6.53789758682251, 'learning_rate': 1.1813333333333334e-05, 'epoch': 1.23}\n",
      "{'loss': 1.1205, 'grad_norm': 4.551273822784424, 'learning_rate': 1.1786666666666668e-05, 'epoch': 1.23}\n",
      "{'loss': 1.1192, 'grad_norm': 5.885697364807129, 'learning_rate': 1.1760000000000001e-05, 'epoch': 1.24}\n",
      "{'loss': 1.1289, 'grad_norm': 4.288736343383789, 'learning_rate': 1.1733333333333335e-05, 'epoch': 1.24}\n",
      "{'loss': 1.1281, 'grad_norm': 5.786793231964111, 'learning_rate': 1.170666666666667e-05, 'epoch': 1.24}\n",
      "{'loss': 1.1157, 'grad_norm': 5.7318596839904785, 'learning_rate': 1.168e-05, 'epoch': 1.25}\n",
      "{'loss': 1.122, 'grad_norm': 6.697490692138672, 'learning_rate': 1.1653333333333334e-05, 'epoch': 1.25}\n",
      "{'loss': 1.1185, 'grad_norm': 6.538825511932373, 'learning_rate': 1.1626666666666668e-05, 'epoch': 1.26}\n",
      "{'loss': 1.1291, 'grad_norm': 5.925288200378418, 'learning_rate': 1.16e-05, 'epoch': 1.26}\n",
      "{'loss': 1.0933, 'grad_norm': 5.098021507263184, 'learning_rate': 1.1573333333333335e-05, 'epoch': 1.26}\n",
      "{'loss': 1.1261, 'grad_norm': 4.001110553741455, 'learning_rate': 1.1546666666666669e-05, 'epoch': 1.27}\n",
      "{'loss': 1.1025, 'grad_norm': 4.940229415893555, 'learning_rate': 1.152e-05, 'epoch': 1.27}\n",
      "{'loss': 1.0913, 'grad_norm': 4.856192111968994, 'learning_rate': 1.1493333333333334e-05, 'epoch': 1.28}\n",
      "{'loss': 1.1133, 'grad_norm': 5.445503234863281, 'learning_rate': 1.1466666666666668e-05, 'epoch': 1.28}\n",
      "{'loss': 1.1125, 'grad_norm': 4.426697731018066, 'learning_rate': 1.144e-05, 'epoch': 1.28}\n",
      "{'loss': 1.0812, 'grad_norm': 3.881870746612549, 'learning_rate': 1.1413333333333335e-05, 'epoch': 1.29}\n",
      "{'loss': 1.0821, 'grad_norm': 7.440357685089111, 'learning_rate': 1.1386666666666669e-05, 'epoch': 1.29}\n",
      "{'loss': 1.1074, 'grad_norm': 5.134015083312988, 'learning_rate': 1.136e-05, 'epoch': 1.3}\n",
      "{'loss': 1.0539, 'grad_norm': 7.026675701141357, 'learning_rate': 1.1333333333333334e-05, 'epoch': 1.3}\n",
      "{'loss': 1.1225, 'grad_norm': 7.082213401794434, 'learning_rate': 1.1306666666666668e-05, 'epoch': 1.3}\n",
      "{'loss': 1.1114, 'grad_norm': 4.270411014556885, 'learning_rate': 1.128e-05, 'epoch': 1.31}\n",
      "{'loss': 1.1055, 'grad_norm': 4.992194652557373, 'learning_rate': 1.1253333333333335e-05, 'epoch': 1.31}\n",
      "{'loss': 1.0806, 'grad_norm': 5.021388053894043, 'learning_rate': 1.1226666666666669e-05, 'epoch': 1.32}\n",
      "{'loss': 1.0854, 'grad_norm': 4.383241176605225, 'learning_rate': 1.1200000000000001e-05, 'epoch': 1.32}\n",
      "{'loss': 1.0515, 'grad_norm': 5.824967861175537, 'learning_rate': 1.1173333333333334e-05, 'epoch': 1.32}\n",
      "{'loss': 1.0812, 'grad_norm': 5.08641242980957, 'learning_rate': 1.1146666666666668e-05, 'epoch': 1.33}\n",
      "{'loss': 1.0761, 'grad_norm': 7.054433345794678, 'learning_rate': 1.1120000000000002e-05, 'epoch': 1.33}\n",
      "{'loss': 1.097, 'grad_norm': 7.272981643676758, 'learning_rate': 1.1093333333333334e-05, 'epoch': 1.34}\n",
      "{'loss': 1.0577, 'grad_norm': 7.04998254776001, 'learning_rate': 1.1066666666666669e-05, 'epoch': 1.34}\n",
      "{'loss': 1.075, 'grad_norm': 5.277769088745117, 'learning_rate': 1.1040000000000001e-05, 'epoch': 1.34}\n",
      "{'loss': 1.0736, 'grad_norm': 6.414579391479492, 'learning_rate': 1.1013333333333333e-05, 'epoch': 1.35}\n",
      "{'loss': 1.0783, 'grad_norm': 5.717733860015869, 'learning_rate': 1.0986666666666668e-05, 'epoch': 1.35}\n",
      "{'loss': 1.0827, 'grad_norm': 4.4212517738342285, 'learning_rate': 1.0960000000000002e-05, 'epoch': 1.36}\n",
      "{'loss': 1.0761, 'grad_norm': 5.6145453453063965, 'learning_rate': 1.0933333333333334e-05, 'epoch': 1.36}\n",
      "{'loss': 1.0793, 'grad_norm': 5.8741960525512695, 'learning_rate': 1.0906666666666668e-05, 'epoch': 1.36}\n",
      "{'loss': 1.0628, 'grad_norm': 4.641928672790527, 'learning_rate': 1.0880000000000001e-05, 'epoch': 1.37}\n",
      "{'loss': 1.0563, 'grad_norm': 4.854160785675049, 'learning_rate': 1.0853333333333333e-05, 'epoch': 1.37}\n",
      "{'loss': 1.0497, 'grad_norm': 4.055429458618164, 'learning_rate': 1.0826666666666667e-05, 'epoch': 1.38}\n",
      "{'loss': 1.0476, 'grad_norm': 4.539126873016357, 'learning_rate': 1.0800000000000002e-05, 'epoch': 1.38}\n",
      "{'loss': 1.0431, 'grad_norm': 4.050774574279785, 'learning_rate': 1.0773333333333334e-05, 'epoch': 1.38}\n",
      "{'loss': 1.0523, 'grad_norm': 3.807048797607422, 'learning_rate': 1.0746666666666668e-05, 'epoch': 1.39}\n",
      "{'loss': 1.0435, 'grad_norm': 6.2432146072387695, 'learning_rate': 1.072e-05, 'epoch': 1.39}\n",
      "{'loss': 1.0304, 'grad_norm': 5.113694667816162, 'learning_rate': 1.0693333333333333e-05, 'epoch': 1.4}\n",
      "{'loss': 1.0496, 'grad_norm': 5.628899097442627, 'learning_rate': 1.0666666666666667e-05, 'epoch': 1.4}\n",
      "{'loss': 1.0409, 'grad_norm': 4.548761367797852, 'learning_rate': 1.0640000000000001e-05, 'epoch': 1.4}\n",
      "{'loss': 1.0342, 'grad_norm': 5.147828102111816, 'learning_rate': 1.0613333333333334e-05, 'epoch': 1.41}\n",
      "{'loss': 1.0661, 'grad_norm': 5.128162384033203, 'learning_rate': 1.0586666666666668e-05, 'epoch': 1.41}\n",
      "{'loss': 1.0355, 'grad_norm': 6.2228779792785645, 'learning_rate': 1.056e-05, 'epoch': 1.42}\n",
      "{'loss': 1.0371, 'grad_norm': 5.893404960632324, 'learning_rate': 1.0533333333333333e-05, 'epoch': 1.42}\n",
      "{'loss': 1.0478, 'grad_norm': 5.700410842895508, 'learning_rate': 1.0506666666666667e-05, 'epoch': 1.42}\n",
      "{'loss': 1.0509, 'grad_norm': 3.942267656326294, 'learning_rate': 1.0480000000000001e-05, 'epoch': 1.43}\n",
      "{'loss': 1.0565, 'grad_norm': 5.846121788024902, 'learning_rate': 1.0453333333333334e-05, 'epoch': 1.43}\n",
      "{'loss': 1.0643, 'grad_norm': 4.4980950355529785, 'learning_rate': 1.0426666666666668e-05, 'epoch': 1.44}\n",
      "{'loss': 1.0327, 'grad_norm': 7.152950763702393, 'learning_rate': 1.04e-05, 'epoch': 1.44}\n",
      "{'loss': 1.0428, 'grad_norm': 4.600951671600342, 'learning_rate': 1.0373333333333335e-05, 'epoch': 1.44}\n",
      "{'loss': 1.04, 'grad_norm': 4.514039516448975, 'learning_rate': 1.0346666666666667e-05, 'epoch': 1.45}\n",
      "{'loss': 1.0475, 'grad_norm': 5.18869161605835, 'learning_rate': 1.0320000000000001e-05, 'epoch': 1.45}\n",
      "{'loss': 1.0181, 'grad_norm': 8.30551815032959, 'learning_rate': 1.0293333333333335e-05, 'epoch': 1.46}\n",
      "{'loss': 1.0071, 'grad_norm': 4.375584602355957, 'learning_rate': 1.0266666666666668e-05, 'epoch': 1.46}\n",
      "{'loss': 1.0148, 'grad_norm': 4.654742240905762, 'learning_rate': 1.024e-05, 'epoch': 1.46}\n",
      "{'loss': 1.0152, 'grad_norm': 7.2547502517700195, 'learning_rate': 1.0213333333333334e-05, 'epoch': 1.47}\n",
      "{'loss': 1.0217, 'grad_norm': 5.584929943084717, 'learning_rate': 1.0186666666666667e-05, 'epoch': 1.47}\n",
      "{'loss': 1.0365, 'grad_norm': 4.703271389007568, 'learning_rate': 1.0160000000000001e-05, 'epoch': 1.48}\n",
      "{'loss': 1.0175, 'grad_norm': 4.700591087341309, 'learning_rate': 1.0133333333333335e-05, 'epoch': 1.48}\n",
      "{'loss': 0.9988, 'grad_norm': 5.258352279663086, 'learning_rate': 1.0106666666666668e-05, 'epoch': 1.48}\n",
      "{'loss': 1.0422, 'grad_norm': 6.543247222900391, 'learning_rate': 1.008e-05, 'epoch': 1.49}\n",
      "{'loss': 1.0277, 'grad_norm': 5.165779113769531, 'learning_rate': 1.0053333333333334e-05, 'epoch': 1.49}\n",
      "{'loss': 1.0186, 'grad_norm': 6.1042375564575195, 'learning_rate': 1.0026666666666667e-05, 'epoch': 1.5}\n",
      "{'loss': 1.013, 'grad_norm': 5.21222448348999, 'learning_rate': 1e-05, 'epoch': 1.5}\n",
      "{'loss': 1.0046, 'grad_norm': 4.818711280822754, 'learning_rate': 9.973333333333333e-06, 'epoch': 1.5}\n",
      "{'loss': 1.0231, 'grad_norm': 5.6934590339660645, 'learning_rate': 9.946666666666667e-06, 'epoch': 1.51}\n",
      "{'loss': 0.9872, 'grad_norm': 5.40195369720459, 'learning_rate': 9.920000000000002e-06, 'epoch': 1.51}\n",
      "{'loss': 0.9921, 'grad_norm': 4.458526134490967, 'learning_rate': 9.893333333333334e-06, 'epoch': 1.52}\n",
      "{'loss': 0.9591, 'grad_norm': 6.321436405181885, 'learning_rate': 9.866666666666668e-06, 'epoch': 1.52}\n",
      "{'loss': 1.0047, 'grad_norm': 4.187961578369141, 'learning_rate': 9.84e-06, 'epoch': 1.52}\n",
      "{'loss': 1.0055, 'grad_norm': 4.664939880371094, 'learning_rate': 9.813333333333333e-06, 'epoch': 1.53}\n",
      "{'loss': 0.9829, 'grad_norm': 5.987695693969727, 'learning_rate': 9.786666666666667e-06, 'epoch': 1.53}\n",
      "{'loss': 0.9842, 'grad_norm': 7.379696369171143, 'learning_rate': 9.760000000000001e-06, 'epoch': 1.54}\n",
      "{'loss': 1.0002, 'grad_norm': 5.429885387420654, 'learning_rate': 9.733333333333334e-06, 'epoch': 1.54}\n",
      "{'loss': 1.009, 'grad_norm': 5.882134914398193, 'learning_rate': 9.706666666666668e-06, 'epoch': 1.54}\n",
      "{'loss': 0.9671, 'grad_norm': 4.482456207275391, 'learning_rate': 9.68e-06, 'epoch': 1.55}\n",
      "{'loss': 0.9713, 'grad_norm': 6.779973030090332, 'learning_rate': 9.653333333333335e-06, 'epoch': 1.55}\n",
      "{'loss': 0.9806, 'grad_norm': 5.085923671722412, 'learning_rate': 9.626666666666667e-06, 'epoch': 1.56}\n",
      "{'loss': 0.9725, 'grad_norm': 6.175094127655029, 'learning_rate': 9.600000000000001e-06, 'epoch': 1.56}\n",
      "{'loss': 0.9718, 'grad_norm': 5.3859076499938965, 'learning_rate': 9.573333333333334e-06, 'epoch': 1.56}\n",
      "{'loss': 0.9867, 'grad_norm': 5.864695072174072, 'learning_rate': 9.546666666666668e-06, 'epoch': 1.57}\n",
      "{'loss': 0.9779, 'grad_norm': 5.504334926605225, 'learning_rate': 9.52e-06, 'epoch': 1.57}\n",
      "{'loss': 0.986, 'grad_norm': 4.910393238067627, 'learning_rate': 9.493333333333334e-06, 'epoch': 1.58}\n",
      "{'loss': 0.9683, 'grad_norm': 5.260709285736084, 'learning_rate': 9.466666666666667e-06, 'epoch': 1.58}\n",
      "{'loss': 0.9867, 'grad_norm': 5.238097667694092, 'learning_rate': 9.440000000000001e-06, 'epoch': 1.58}\n",
      "{'loss': 0.9559, 'grad_norm': 6.25791597366333, 'learning_rate': 9.413333333333334e-06, 'epoch': 1.59}\n",
      "{'loss': 0.9672, 'grad_norm': 3.9090869426727295, 'learning_rate': 9.386666666666668e-06, 'epoch': 1.59}\n",
      "{'loss': 0.9598, 'grad_norm': 4.074251174926758, 'learning_rate': 9.360000000000002e-06, 'epoch': 1.6}\n",
      "{'loss': 0.9821, 'grad_norm': 6.233819484710693, 'learning_rate': 9.333333333333334e-06, 'epoch': 1.6}\n",
      "{'loss': 0.9838, 'grad_norm': 6.200937271118164, 'learning_rate': 9.306666666666667e-06, 'epoch': 1.6}\n",
      "{'loss': 0.9598, 'grad_norm': 4.486928939819336, 'learning_rate': 9.280000000000001e-06, 'epoch': 1.61}\n",
      "{'loss': 0.9834, 'grad_norm': 5.2642388343811035, 'learning_rate': 9.253333333333333e-06, 'epoch': 1.61}\n",
      "{'loss': 0.9914, 'grad_norm': 4.635622501373291, 'learning_rate': 9.226666666666668e-06, 'epoch': 1.62}\n",
      "{'loss': 0.959, 'grad_norm': 5.272834777832031, 'learning_rate': 9.200000000000002e-06, 'epoch': 1.62}\n",
      "{'loss': 0.9605, 'grad_norm': 5.921648979187012, 'learning_rate': 9.173333333333334e-06, 'epoch': 1.62}\n",
      "{'loss': 0.9649, 'grad_norm': 4.844274997711182, 'learning_rate': 9.146666666666667e-06, 'epoch': 1.63}\n",
      "{'loss': 0.9834, 'grad_norm': 4.306334495544434, 'learning_rate': 9.12e-06, 'epoch': 1.63}\n",
      "{'loss': 0.9529, 'grad_norm': 4.684047698974609, 'learning_rate': 9.093333333333333e-06, 'epoch': 1.64}\n",
      "{'loss': 0.9613, 'grad_norm': 5.477334499359131, 'learning_rate': 9.066666666666667e-06, 'epoch': 1.64}\n",
      "{'loss': 0.9312, 'grad_norm': 4.556576251983643, 'learning_rate': 9.040000000000002e-06, 'epoch': 1.64}\n",
      "{'loss': 0.9686, 'grad_norm': 5.159435272216797, 'learning_rate': 9.013333333333334e-06, 'epoch': 1.65}\n",
      "{'loss': 0.9546, 'grad_norm': 5.561290264129639, 'learning_rate': 8.986666666666666e-06, 'epoch': 1.65}\n",
      "{'loss': 0.9812, 'grad_norm': 3.2083706855773926, 'learning_rate': 8.96e-06, 'epoch': 1.66}\n",
      "{'loss': 0.951, 'grad_norm': 4.267024517059326, 'learning_rate': 8.933333333333333e-06, 'epoch': 1.66}\n",
      "{'loss': 0.9438, 'grad_norm': 5.237709045410156, 'learning_rate': 8.906666666666667e-06, 'epoch': 1.66}\n",
      "{'loss': 0.9343, 'grad_norm': 5.1938090324401855, 'learning_rate': 8.880000000000001e-06, 'epoch': 1.67}\n",
      "{'loss': 0.9206, 'grad_norm': 5.895941257476807, 'learning_rate': 8.853333333333334e-06, 'epoch': 1.67}\n",
      "{'loss': 0.9369, 'grad_norm': 5.651164531707764, 'learning_rate': 8.826666666666668e-06, 'epoch': 1.68}\n",
      "{'loss': 0.9596, 'grad_norm': 4.387856483459473, 'learning_rate': 8.8e-06, 'epoch': 1.68}\n",
      "{'loss': 0.9319, 'grad_norm': 6.896890640258789, 'learning_rate': 8.773333333333333e-06, 'epoch': 1.68}\n",
      "{'loss': 0.9209, 'grad_norm': 4.904778003692627, 'learning_rate': 8.746666666666667e-06, 'epoch': 1.69}\n",
      "{'loss': 0.9536, 'grad_norm': 4.686452865600586, 'learning_rate': 8.720000000000001e-06, 'epoch': 1.69}\n",
      "{'loss': 0.957, 'grad_norm': 4.479708194732666, 'learning_rate': 8.693333333333334e-06, 'epoch': 1.7}\n",
      "{'loss': 0.9482, 'grad_norm': 5.823206901550293, 'learning_rate': 8.666666666666668e-06, 'epoch': 1.7}\n",
      "{'loss': 0.9242, 'grad_norm': 6.89825963973999, 'learning_rate': 8.64e-06, 'epoch': 1.7}\n",
      "{'loss': 0.9737, 'grad_norm': 7.971001148223877, 'learning_rate': 8.613333333333333e-06, 'epoch': 1.71}\n",
      "{'loss': 0.9156, 'grad_norm': 6.701475143432617, 'learning_rate': 8.586666666666667e-06, 'epoch': 1.71}\n",
      "{'loss': 0.9175, 'grad_norm': 4.304960250854492, 'learning_rate': 8.560000000000001e-06, 'epoch': 1.72}\n",
      "{'loss': 0.9284, 'grad_norm': 5.166210174560547, 'learning_rate': 8.533333333333335e-06, 'epoch': 1.72}\n",
      "{'loss': 0.9357, 'grad_norm': 6.344905853271484, 'learning_rate': 8.506666666666668e-06, 'epoch': 1.72}\n",
      "{'loss': 0.9321, 'grad_norm': 5.889739036560059, 'learning_rate': 8.48e-06, 'epoch': 1.73}\n",
      "{'loss': 0.917, 'grad_norm': 5.474653244018555, 'learning_rate': 8.453333333333334e-06, 'epoch': 1.73}\n",
      "{'loss': 0.9274, 'grad_norm': 7.878226280212402, 'learning_rate': 8.426666666666667e-06, 'epoch': 1.74}\n",
      "{'loss': 0.9093, 'grad_norm': 4.063549041748047, 'learning_rate': 8.400000000000001e-06, 'epoch': 1.74}\n",
      "{'loss': 0.9307, 'grad_norm': 3.9483225345611572, 'learning_rate': 8.373333333333335e-06, 'epoch': 1.74}\n",
      "{'loss': 0.9184, 'grad_norm': 3.5902903079986572, 'learning_rate': 8.346666666666668e-06, 'epoch': 1.75}\n",
      "{'loss': 0.9202, 'grad_norm': 5.69042444229126, 'learning_rate': 8.32e-06, 'epoch': 1.75}\n",
      "{'loss': 0.9053, 'grad_norm': 8.255441665649414, 'learning_rate': 8.293333333333334e-06, 'epoch': 1.76}\n",
      "{'loss': 0.9232, 'grad_norm': 3.9216017723083496, 'learning_rate': 8.266666666666667e-06, 'epoch': 1.76}\n",
      "{'loss': 0.9307, 'grad_norm': 4.3100361824035645, 'learning_rate': 8.24e-06, 'epoch': 1.76}\n",
      "{'loss': 0.9316, 'grad_norm': 10.22313404083252, 'learning_rate': 8.213333333333335e-06, 'epoch': 1.77}\n",
      "{'loss': 0.942, 'grad_norm': 4.548234939575195, 'learning_rate': 8.186666666666667e-06, 'epoch': 1.77}\n",
      "{'loss': 0.9061, 'grad_norm': 4.397218227386475, 'learning_rate': 8.16e-06, 'epoch': 1.78}\n",
      "{'loss': 0.8982, 'grad_norm': 4.154665946960449, 'learning_rate': 8.133333333333334e-06, 'epoch': 1.78}\n",
      "{'loss': 0.9076, 'grad_norm': 5.3851470947265625, 'learning_rate': 8.106666666666666e-06, 'epoch': 1.78}\n",
      "{'loss': 0.9078, 'grad_norm': 6.113775730133057, 'learning_rate': 8.08e-06, 'epoch': 1.79}\n",
      "{'loss': 0.9098, 'grad_norm': 5.291996955871582, 'learning_rate': 8.053333333333335e-06, 'epoch': 1.79}\n",
      "{'loss': 0.9365, 'grad_norm': 4.72433614730835, 'learning_rate': 8.026666666666667e-06, 'epoch': 1.8}\n",
      "{'loss': 0.9055, 'grad_norm': 7.449630260467529, 'learning_rate': 8.000000000000001e-06, 'epoch': 1.8}\n",
      "{'loss': 0.8668, 'grad_norm': 6.377233982086182, 'learning_rate': 7.973333333333334e-06, 'epoch': 1.8}\n",
      "{'loss': 0.9059, 'grad_norm': 5.624881744384766, 'learning_rate': 7.946666666666666e-06, 'epoch': 1.81}\n",
      "{'loss': 0.8959, 'grad_norm': 7.027182579040527, 'learning_rate': 7.92e-06, 'epoch': 1.81}\n",
      "{'loss': 0.924, 'grad_norm': 6.01360559463501, 'learning_rate': 7.893333333333335e-06, 'epoch': 1.82}\n",
      "{'loss': 0.8922, 'grad_norm': 6.579562664031982, 'learning_rate': 7.866666666666667e-06, 'epoch': 1.82}\n",
      "{'loss': 0.92, 'grad_norm': 5.3849687576293945, 'learning_rate': 7.840000000000001e-06, 'epoch': 1.82}\n",
      "{'loss': 0.9047, 'grad_norm': 6.577239513397217, 'learning_rate': 7.813333333333334e-06, 'epoch': 1.83}\n",
      "{'loss': 0.9091, 'grad_norm': 5.164828300476074, 'learning_rate': 7.786666666666666e-06, 'epoch': 1.83}\n",
      "{'loss': 0.8933, 'grad_norm': 4.467525005340576, 'learning_rate': 7.76e-06, 'epoch': 1.84}\n",
      "{'loss': 0.8859, 'grad_norm': 5.269558429718018, 'learning_rate': 7.733333333333334e-06, 'epoch': 1.84}\n",
      "{'loss': 0.9011, 'grad_norm': 7.3242411613464355, 'learning_rate': 7.706666666666669e-06, 'epoch': 1.84}\n",
      "{'loss': 0.8836, 'grad_norm': 6.070625305175781, 'learning_rate': 7.680000000000001e-06, 'epoch': 1.85}\n",
      "{'loss': 0.8763, 'grad_norm': 6.052608489990234, 'learning_rate': 7.653333333333333e-06, 'epoch': 1.85}\n",
      "{'loss': 0.9167, 'grad_norm': 5.623348712921143, 'learning_rate': 7.626666666666668e-06, 'epoch': 1.86}\n",
      "{'loss': 0.8811, 'grad_norm': 4.629504680633545, 'learning_rate': 7.600000000000001e-06, 'epoch': 1.86}\n",
      "{'loss': 0.8863, 'grad_norm': 4.5911760330200195, 'learning_rate': 7.573333333333333e-06, 'epoch': 1.86}\n",
      "{'loss': 0.8906, 'grad_norm': 5.900899410247803, 'learning_rate': 7.5466666666666675e-06, 'epoch': 1.87}\n",
      "{'loss': 0.8674, 'grad_norm': 5.764914512634277, 'learning_rate': 7.520000000000001e-06, 'epoch': 1.87}\n",
      "{'loss': 0.8647, 'grad_norm': 4.120696544647217, 'learning_rate': 7.493333333333333e-06, 'epoch': 1.88}\n",
      "{'loss': 0.8748, 'grad_norm': 6.966409683227539, 'learning_rate': 7.4666666666666675e-06, 'epoch': 1.88}\n",
      "{'loss': 0.8986, 'grad_norm': 3.4282546043395996, 'learning_rate': 7.440000000000001e-06, 'epoch': 1.88}\n",
      "{'loss': 0.846, 'grad_norm': 6.13659143447876, 'learning_rate': 7.413333333333333e-06, 'epoch': 1.89}\n",
      "{'loss': 0.8909, 'grad_norm': 4.2501325607299805, 'learning_rate': 7.386666666666667e-06, 'epoch': 1.89}\n",
      "{'loss': 0.8583, 'grad_norm': 5.707406044006348, 'learning_rate': 7.360000000000001e-06, 'epoch': 1.9}\n",
      "{'loss': 0.8704, 'grad_norm': 5.052910327911377, 'learning_rate': 7.333333333333333e-06, 'epoch': 1.9}\n",
      "{'loss': 0.8887, 'grad_norm': 6.121242523193359, 'learning_rate': 7.306666666666667e-06, 'epoch': 1.9}\n",
      "{'loss': 0.8729, 'grad_norm': 5.324057579040527, 'learning_rate': 7.280000000000001e-06, 'epoch': 1.91}\n",
      "{'loss': 0.8819, 'grad_norm': 6.787919998168945, 'learning_rate': 7.253333333333335e-06, 'epoch': 1.91}\n",
      "{'loss': 0.8757, 'grad_norm': 5.759115219116211, 'learning_rate': 7.226666666666667e-06, 'epoch': 1.92}\n",
      "{'loss': 0.8501, 'grad_norm': 6.082603454589844, 'learning_rate': 7.2000000000000005e-06, 'epoch': 1.92}\n",
      "{'loss': 0.8744, 'grad_norm': 3.7050299644470215, 'learning_rate': 7.173333333333335e-06, 'epoch': 1.92}\n",
      "{'loss': 0.8518, 'grad_norm': 6.975005149841309, 'learning_rate': 7.146666666666667e-06, 'epoch': 1.93}\n",
      "{'loss': 0.8604, 'grad_norm': 5.860748767852783, 'learning_rate': 7.1200000000000004e-06, 'epoch': 1.93}\n",
      "{'loss': 0.859, 'grad_norm': 5.970961570739746, 'learning_rate': 7.093333333333335e-06, 'epoch': 1.94}\n",
      "{'loss': 0.8881, 'grad_norm': 4.863336086273193, 'learning_rate': 7.066666666666667e-06, 'epoch': 1.94}\n",
      "{'loss': 0.8692, 'grad_norm': 6.606015205383301, 'learning_rate': 7.04e-06, 'epoch': 1.94}\n",
      "{'loss': 0.8561, 'grad_norm': 6.2867960929870605, 'learning_rate': 7.0133333333333345e-06, 'epoch': 1.95}\n",
      "{'loss': 0.8722, 'grad_norm': 4.890870094299316, 'learning_rate': 6.986666666666667e-06, 'epoch': 1.95}\n",
      "{'loss': 0.842, 'grad_norm': 5.438060283660889, 'learning_rate': 6.96e-06, 'epoch': 1.96}\n",
      "{'loss': 0.8474, 'grad_norm': 5.637077331542969, 'learning_rate': 6.9333333333333344e-06, 'epoch': 1.96}\n",
      "{'loss': 0.8606, 'grad_norm': 5.654510498046875, 'learning_rate': 6.906666666666667e-06, 'epoch': 1.96}\n",
      "{'loss': 0.8406, 'grad_norm': 5.772707462310791, 'learning_rate': 6.88e-06, 'epoch': 1.97}\n",
      "{'loss': 0.8833, 'grad_norm': 6.874543190002441, 'learning_rate': 6.853333333333334e-06, 'epoch': 1.97}\n",
      "{'loss': 0.8473, 'grad_norm': 6.149889945983887, 'learning_rate': 6.826666666666667e-06, 'epoch': 1.98}\n",
      "{'loss': 0.8527, 'grad_norm': 6.100377559661865, 'learning_rate': 6.800000000000001e-06, 'epoch': 1.98}\n",
      "{'loss': 0.8392, 'grad_norm': 5.038175582885742, 'learning_rate': 6.773333333333334e-06, 'epoch': 1.98}\n",
      "{'loss': 0.8401, 'grad_norm': 5.4986138343811035, 'learning_rate': 6.746666666666667e-06, 'epoch': 1.99}\n",
      "{'loss': 0.8398, 'grad_norm': 5.285472869873047, 'learning_rate': 6.720000000000001e-06, 'epoch': 1.99}\n",
      "{'loss': 0.8579, 'grad_norm': 4.709151268005371, 'learning_rate': 6.693333333333334e-06, 'epoch': 2.0}\n",
      "{'loss': 0.8706, 'grad_norm': 6.4673357009887695, 'learning_rate': 6.666666666666667e-06, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/j/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b08386b889845b5acb55237c319e7a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5441192984580994, 'eval_bleu': 50.5472, 'eval_gen_len': 12.8646, 'eval_runtime': 10311.6134, 'eval_samples_per_second': 9.698, 'eval_steps_per_second': 1.212, 'epoch': 2.0}\n",
      "{'loss': 0.8139, 'grad_norm': 5.939826011657715, 'learning_rate': 6.640000000000001e-06, 'epoch': 2.0}\n",
      "{'loss': 0.8128, 'grad_norm': 5.081154823303223, 'learning_rate': 6.613333333333334e-06, 'epoch': 2.01}\n",
      "{'loss': 0.8308, 'grad_norm': 6.368315696716309, 'learning_rate': 6.5866666666666666e-06, 'epoch': 2.01}\n",
      "{'loss': 0.8308, 'grad_norm': 4.87898063659668, 'learning_rate': 6.560000000000001e-06, 'epoch': 2.02}\n",
      "{'loss': 0.8281, 'grad_norm': 6.912765979766846, 'learning_rate': 6.533333333333334e-06, 'epoch': 2.02}\n",
      "{'loss': 0.809, 'grad_norm': 5.473793029785156, 'learning_rate': 6.5066666666666665e-06, 'epoch': 2.02}\n",
      "{'loss': 0.8124, 'grad_norm': 6.679011344909668, 'learning_rate': 6.480000000000001e-06, 'epoch': 2.03}\n",
      "{'loss': 0.8252, 'grad_norm': 4.134126663208008, 'learning_rate': 6.453333333333334e-06, 'epoch': 2.03}\n",
      "{'loss': 0.809, 'grad_norm': 6.278046131134033, 'learning_rate': 6.426666666666668e-06, 'epoch': 2.04}\n",
      "{'loss': 0.8113, 'grad_norm': 4.081794261932373, 'learning_rate': 6.4000000000000006e-06, 'epoch': 2.04}\n",
      "{'loss': 0.8163, 'grad_norm': 5.127120494842529, 'learning_rate': 6.373333333333334e-06, 'epoch': 2.04}\n",
      "{'loss': 0.8092, 'grad_norm': 4.194354057312012, 'learning_rate': 6.346666666666668e-06, 'epoch': 2.05}\n",
      "{'loss': 0.8146, 'grad_norm': 6.55255126953125, 'learning_rate': 6.3200000000000005e-06, 'epoch': 2.05}\n",
      "{'loss': 0.8192, 'grad_norm': 3.3643484115600586, 'learning_rate': 6.293333333333334e-06, 'epoch': 2.06}\n",
      "{'loss': 0.828, 'grad_norm': 5.679569244384766, 'learning_rate': 6.266666666666668e-06, 'epoch': 2.06}\n",
      "{'loss': 0.8111, 'grad_norm': 6.182243824005127, 'learning_rate': 6.24e-06, 'epoch': 2.06}\n",
      "{'loss': 0.8159, 'grad_norm': 4.458418846130371, 'learning_rate': 6.213333333333334e-06, 'epoch': 2.07}\n",
      "{'loss': 0.8151, 'grad_norm': 5.790682315826416, 'learning_rate': 6.186666666666668e-06, 'epoch': 2.07}\n",
      "{'loss': 0.7875, 'grad_norm': 7.676088333129883, 'learning_rate': 6.16e-06, 'epoch': 2.08}\n",
      "{'loss': 0.8166, 'grad_norm': 4.1050543785095215, 'learning_rate': 6.133333333333334e-06, 'epoch': 2.08}\n",
      "{'loss': 0.8221, 'grad_norm': 7.592830181121826, 'learning_rate': 6.106666666666668e-06, 'epoch': 2.08}\n",
      "{'loss': 0.8163, 'grad_norm': 6.224259376525879, 'learning_rate': 6.08e-06, 'epoch': 2.09}\n",
      "{'loss': 0.8114, 'grad_norm': 4.050644397735596, 'learning_rate': 6.0533333333333335e-06, 'epoch': 2.09}\n",
      "{'loss': 0.8029, 'grad_norm': 4.662412166595459, 'learning_rate': 6.026666666666668e-06, 'epoch': 2.1}\n",
      "{'loss': 0.7966, 'grad_norm': 5.125978469848633, 'learning_rate': 6e-06, 'epoch': 2.1}\n",
      "{'loss': 0.8058, 'grad_norm': 7.652119159698486, 'learning_rate': 5.973333333333334e-06, 'epoch': 2.1}\n",
      "{'loss': 0.8207, 'grad_norm': 5.821317672729492, 'learning_rate': 5.946666666666668e-06, 'epoch': 2.11}\n",
      "{'loss': 0.8183, 'grad_norm': 3.106475353240967, 'learning_rate': 5.92e-06, 'epoch': 2.11}\n",
      "{'loss': 0.8115, 'grad_norm': 6.256798267364502, 'learning_rate': 5.893333333333334e-06, 'epoch': 2.12}\n",
      "{'loss': 0.785, 'grad_norm': 6.997045040130615, 'learning_rate': 5.8666666666666675e-06, 'epoch': 2.12}\n",
      "{'loss': 0.7868, 'grad_norm': 4.354738712310791, 'learning_rate': 5.84e-06, 'epoch': 2.12}\n",
      "{'loss': 0.7981, 'grad_norm': 5.227923393249512, 'learning_rate': 5.813333333333334e-06, 'epoch': 2.13}\n",
      "{'loss': 0.8091, 'grad_norm': 3.983598232269287, 'learning_rate': 5.7866666666666674e-06, 'epoch': 2.13}\n",
      "{'loss': 0.7916, 'grad_norm': 5.422523498535156, 'learning_rate': 5.76e-06, 'epoch': 2.14}\n",
      "{'loss': 0.7821, 'grad_norm': 5.007540225982666, 'learning_rate': 5.733333333333334e-06, 'epoch': 2.14}\n",
      "{'loss': 0.8324, 'grad_norm': 5.6525468826293945, 'learning_rate': 5.706666666666667e-06, 'epoch': 2.14}\n",
      "{'loss': 0.8331, 'grad_norm': 6.808152198791504, 'learning_rate': 5.68e-06, 'epoch': 2.15}\n",
      "{'loss': 0.7781, 'grad_norm': 4.277064800262451, 'learning_rate': 5.653333333333334e-06, 'epoch': 2.15}\n",
      "{'loss': 0.8073, 'grad_norm': 5.65535831451416, 'learning_rate': 5.626666666666667e-06, 'epoch': 2.16}\n",
      "{'loss': 0.8227, 'grad_norm': 3.9794821739196777, 'learning_rate': 5.600000000000001e-06, 'epoch': 2.16}\n",
      "{'loss': 0.7953, 'grad_norm': 6.468679904937744, 'learning_rate': 5.573333333333334e-06, 'epoch': 2.16}\n",
      "{'loss': 0.8073, 'grad_norm': 4.540911674499512, 'learning_rate': 5.546666666666667e-06, 'epoch': 2.17}\n",
      "{'loss': 0.7791, 'grad_norm': 5.209924697875977, 'learning_rate': 5.5200000000000005e-06, 'epoch': 2.17}\n",
      "{'loss': 0.7897, 'grad_norm': 8.804487228393555, 'learning_rate': 5.493333333333334e-06, 'epoch': 2.18}\n",
      "{'loss': 0.7817, 'grad_norm': 5.201872825622559, 'learning_rate': 5.466666666666667e-06, 'epoch': 2.18}\n",
      "{'loss': 0.8025, 'grad_norm': 5.140503406524658, 'learning_rate': 5.4400000000000004e-06, 'epoch': 2.18}\n",
      "{'loss': 0.7827, 'grad_norm': 4.390190601348877, 'learning_rate': 5.413333333333334e-06, 'epoch': 2.19}\n",
      "{'loss': 0.8069, 'grad_norm': 5.620079517364502, 'learning_rate': 5.386666666666667e-06, 'epoch': 2.19}\n",
      "{'loss': 0.7867, 'grad_norm': 8.980450630187988, 'learning_rate': 5.36e-06, 'epoch': 2.2}\n",
      "{'loss': 0.7908, 'grad_norm': 7.4569525718688965, 'learning_rate': 5.333333333333334e-06, 'epoch': 2.2}\n",
      "{'loss': 0.7928, 'grad_norm': 6.056569576263428, 'learning_rate': 5.306666666666667e-06, 'epoch': 2.2}\n",
      "{'loss': 0.8007, 'grad_norm': 4.540526390075684, 'learning_rate': 5.28e-06, 'epoch': 2.21}\n",
      "{'loss': 0.8007, 'grad_norm': 8.184163093566895, 'learning_rate': 5.2533333333333336e-06, 'epoch': 2.21}\n",
      "{'loss': 0.7826, 'grad_norm': 4.410780906677246, 'learning_rate': 5.226666666666667e-06, 'epoch': 2.22}\n",
      "{'loss': 0.7911, 'grad_norm': 7.978900909423828, 'learning_rate': 5.2e-06, 'epoch': 2.22}\n",
      "{'loss': 0.7788, 'grad_norm': 7.641005039215088, 'learning_rate': 5.1733333333333335e-06, 'epoch': 2.22}\n",
      "{'loss': 0.7728, 'grad_norm': 7.403506278991699, 'learning_rate': 5.146666666666668e-06, 'epoch': 2.23}\n",
      "{'loss': 0.8006, 'grad_norm': 4.99014139175415, 'learning_rate': 5.12e-06, 'epoch': 2.23}\n",
      "{'loss': 0.7776, 'grad_norm': 5.586296558380127, 'learning_rate': 5.093333333333333e-06, 'epoch': 2.24}\n",
      "{'loss': 0.7746, 'grad_norm': 5.02664041519165, 'learning_rate': 5.0666666666666676e-06, 'epoch': 2.24}\n",
      "{'loss': 0.7898, 'grad_norm': 4.337623596191406, 'learning_rate': 5.04e-06, 'epoch': 2.24}\n",
      "{'loss': 0.7884, 'grad_norm': 4.358364582061768, 'learning_rate': 5.013333333333333e-06, 'epoch': 2.25}\n",
      "{'loss': 0.789, 'grad_norm': 5.064331531524658, 'learning_rate': 4.986666666666667e-06, 'epoch': 2.25}\n",
      "{'loss': 0.7883, 'grad_norm': 5.618279457092285, 'learning_rate': 4.960000000000001e-06, 'epoch': 2.26}\n",
      "{'loss': 0.7812, 'grad_norm': 5.139379501342773, 'learning_rate': 4.933333333333334e-06, 'epoch': 2.26}\n",
      "{'loss': 0.7682, 'grad_norm': 5.061566352844238, 'learning_rate': 4.9066666666666666e-06, 'epoch': 2.26}\n",
      "{'loss': 0.7617, 'grad_norm': 5.974774360656738, 'learning_rate': 4.880000000000001e-06, 'epoch': 2.27}\n",
      "{'loss': 0.7593, 'grad_norm': 5.383410930633545, 'learning_rate': 4.853333333333334e-06, 'epoch': 2.27}\n",
      "{'loss': 0.795, 'grad_norm': 3.866131544113159, 'learning_rate': 4.826666666666667e-06, 'epoch': 2.28}\n",
      "{'loss': 0.78, 'grad_norm': 5.151506423950195, 'learning_rate': 4.800000000000001e-06, 'epoch': 2.28}\n",
      "{'loss': 0.7579, 'grad_norm': 4.673460483551025, 'learning_rate': 4.773333333333334e-06, 'epoch': 2.28}\n",
      "{'loss': 0.7816, 'grad_norm': 8.342827796936035, 'learning_rate': 4.746666666666667e-06, 'epoch': 2.29}\n",
      "{'loss': 0.7854, 'grad_norm': 4.503775119781494, 'learning_rate': 4.7200000000000005e-06, 'epoch': 2.29}\n",
      "{'loss': 0.7923, 'grad_norm': 7.220881462097168, 'learning_rate': 4.693333333333334e-06, 'epoch': 2.3}\n",
      "{'loss': 0.7886, 'grad_norm': 7.444543361663818, 'learning_rate': 4.666666666666667e-06, 'epoch': 2.3}\n",
      "{'loss': 0.7978, 'grad_norm': 5.562453746795654, 'learning_rate': 4.6400000000000005e-06, 'epoch': 2.3}\n",
      "{'loss': 0.7409, 'grad_norm': 5.920368194580078, 'learning_rate': 4.613333333333334e-06, 'epoch': 2.31}\n",
      "{'loss': 0.7915, 'grad_norm': 5.0471415519714355, 'learning_rate': 4.586666666666667e-06, 'epoch': 2.31}\n",
      "{'loss': 0.7489, 'grad_norm': 3.548910140991211, 'learning_rate': 4.56e-06, 'epoch': 2.32}\n",
      "{'loss': 0.7806, 'grad_norm': 6.6747822761535645, 'learning_rate': 4.533333333333334e-06, 'epoch': 2.32}\n",
      "{'loss': 0.7656, 'grad_norm': 6.807905673980713, 'learning_rate': 4.506666666666667e-06, 'epoch': 2.32}\n",
      "{'loss': 0.7984, 'grad_norm': 4.803267955780029, 'learning_rate': 4.48e-06, 'epoch': 2.33}\n",
      "{'loss': 0.7912, 'grad_norm': 3.826158046722412, 'learning_rate': 4.453333333333334e-06, 'epoch': 2.33}\n",
      "{'loss': 0.7594, 'grad_norm': 4.28153133392334, 'learning_rate': 4.426666666666667e-06, 'epoch': 2.34}\n",
      "{'loss': 0.7376, 'grad_norm': 3.4467155933380127, 'learning_rate': 4.4e-06, 'epoch': 2.34}\n",
      "{'loss': 0.7704, 'grad_norm': 5.808113098144531, 'learning_rate': 4.3733333333333335e-06, 'epoch': 2.34}\n",
      "{'loss': 0.7673, 'grad_norm': 5.127099990844727, 'learning_rate': 4.346666666666667e-06, 'epoch': 2.35}\n",
      "{'loss': 0.7622, 'grad_norm': 3.747908592224121, 'learning_rate': 4.32e-06, 'epoch': 2.35}\n",
      "{'loss': 0.7623, 'grad_norm': 6.153215408325195, 'learning_rate': 4.2933333333333334e-06, 'epoch': 2.36}\n",
      "{'loss': 0.7647, 'grad_norm': 5.076345920562744, 'learning_rate': 4.266666666666668e-06, 'epoch': 2.36}\n",
      "{'loss': 0.7312, 'grad_norm': 3.280022382736206, 'learning_rate': 4.24e-06, 'epoch': 2.36}\n",
      "{'loss': 0.7759, 'grad_norm': 7.538313865661621, 'learning_rate': 4.213333333333333e-06, 'epoch': 2.37}\n",
      "{'loss': 0.7792, 'grad_norm': 3.1705777645111084, 'learning_rate': 4.1866666666666675e-06, 'epoch': 2.37}\n",
      "{'loss': 0.7624, 'grad_norm': 6.719393730163574, 'learning_rate': 4.16e-06, 'epoch': 2.38}\n",
      "{'loss': 0.7651, 'grad_norm': 5.5149102210998535, 'learning_rate': 4.133333333333333e-06, 'epoch': 2.38}\n",
      "{'loss': 0.7782, 'grad_norm': 4.176118850708008, 'learning_rate': 4.1066666666666674e-06, 'epoch': 2.38}\n",
      "{'loss': 0.7575, 'grad_norm': 4.850914001464844, 'learning_rate': 4.08e-06, 'epoch': 2.39}\n",
      "{'loss': 0.7556, 'grad_norm': 5.101078987121582, 'learning_rate': 4.053333333333333e-06, 'epoch': 2.39}\n",
      "{'loss': 0.7608, 'grad_norm': 6.2856974601745605, 'learning_rate': 4.026666666666667e-06, 'epoch': 2.4}\n",
      "{'loss': 0.7785, 'grad_norm': 4.96531867980957, 'learning_rate': 4.000000000000001e-06, 'epoch': 2.4}\n",
      "{'loss': 0.7615, 'grad_norm': 3.832153081893921, 'learning_rate': 3.973333333333333e-06, 'epoch': 2.4}\n",
      "{'loss': 0.7537, 'grad_norm': 4.768495082855225, 'learning_rate': 3.946666666666667e-06, 'epoch': 2.41}\n",
      "{'loss': 0.7315, 'grad_norm': 6.775916576385498, 'learning_rate': 3.920000000000001e-06, 'epoch': 2.41}\n",
      "{'loss': 0.7475, 'grad_norm': 4.431570529937744, 'learning_rate': 3.893333333333333e-06, 'epoch': 2.42}\n",
      "{'loss': 0.7561, 'grad_norm': 5.92779541015625, 'learning_rate': 3.866666666666667e-06, 'epoch': 2.42}\n",
      "{'loss': 0.7697, 'grad_norm': 6.427252769470215, 'learning_rate': 3.8400000000000005e-06, 'epoch': 2.42}\n",
      "{'loss': 0.757, 'grad_norm': 6.9788432121276855, 'learning_rate': 3.813333333333334e-06, 'epoch': 2.43}\n",
      "{'loss': 0.7544, 'grad_norm': 5.527799606323242, 'learning_rate': 3.7866666666666667e-06, 'epoch': 2.43}\n",
      "{'loss': 0.7536, 'grad_norm': 5.211334228515625, 'learning_rate': 3.7600000000000004e-06, 'epoch': 2.44}\n",
      "{'loss': 0.7516, 'grad_norm': 5.348696708679199, 'learning_rate': 3.7333333333333337e-06, 'epoch': 2.44}\n",
      "{'loss': 0.7723, 'grad_norm': 6.719923496246338, 'learning_rate': 3.7066666666666666e-06, 'epoch': 2.44}\n",
      "{'loss': 0.7487, 'grad_norm': 6.188938617706299, 'learning_rate': 3.6800000000000003e-06, 'epoch': 2.45}\n",
      "{'loss': 0.773, 'grad_norm': 5.5116400718688965, 'learning_rate': 3.6533333333333336e-06, 'epoch': 2.45}\n",
      "{'loss': 0.7465, 'grad_norm': 4.59160852432251, 'learning_rate': 3.6266666666666674e-06, 'epoch': 2.46}\n",
      "{'loss': 0.7522, 'grad_norm': 4.8277716636657715, 'learning_rate': 3.6000000000000003e-06, 'epoch': 2.46}\n",
      "{'loss': 0.7574, 'grad_norm': 3.325899362564087, 'learning_rate': 3.5733333333333336e-06, 'epoch': 2.46}\n",
      "{'loss': 0.7507, 'grad_norm': 6.6043620109558105, 'learning_rate': 3.5466666666666673e-06, 'epoch': 2.47}\n",
      "{'loss': 0.7275, 'grad_norm': 7.292253494262695, 'learning_rate': 3.52e-06, 'epoch': 2.47}\n",
      "{'loss': 0.7542, 'grad_norm': 5.582675933837891, 'learning_rate': 3.4933333333333335e-06, 'epoch': 2.48}\n",
      "{'loss': 0.7686, 'grad_norm': 6.334952354431152, 'learning_rate': 3.4666666666666672e-06, 'epoch': 2.48}\n",
      "{'loss': 0.751, 'grad_norm': 5.945252895355225, 'learning_rate': 3.44e-06, 'epoch': 2.48}\n",
      "{'loss': 0.7438, 'grad_norm': 6.6498308181762695, 'learning_rate': 3.4133333333333334e-06, 'epoch': 2.49}\n",
      "{'loss': 0.7781, 'grad_norm': 6.924722194671631, 'learning_rate': 3.386666666666667e-06, 'epoch': 2.49}\n",
      "{'loss': 0.7754, 'grad_norm': 6.158052444458008, 'learning_rate': 3.3600000000000004e-06, 'epoch': 2.5}\n",
      "{'loss': 0.7203, 'grad_norm': 6.196048736572266, 'learning_rate': 3.3333333333333333e-06, 'epoch': 2.5}\n",
      "{'loss': 0.7558, 'grad_norm': 4.394432067871094, 'learning_rate': 3.306666666666667e-06, 'epoch': 2.5}\n",
      "{'loss': 0.7341, 'grad_norm': 7.9226765632629395, 'learning_rate': 3.2800000000000004e-06, 'epoch': 2.51}\n",
      "{'loss': 0.7762, 'grad_norm': 5.180098056793213, 'learning_rate': 3.2533333333333332e-06, 'epoch': 2.51}\n",
      "{'loss': 0.7595, 'grad_norm': 6.031350135803223, 'learning_rate': 3.226666666666667e-06, 'epoch': 2.52}\n",
      "{'loss': 0.7558, 'grad_norm': 7.264082908630371, 'learning_rate': 3.2000000000000003e-06, 'epoch': 2.52}\n",
      "{'loss': 0.7448, 'grad_norm': 4.5388288497924805, 'learning_rate': 3.173333333333334e-06, 'epoch': 2.52}\n",
      "{'loss': 0.7395, 'grad_norm': 5.0872602462768555, 'learning_rate': 3.146666666666667e-06, 'epoch': 2.53}\n",
      "{'loss': 0.7272, 'grad_norm': 3.563272714614868, 'learning_rate': 3.12e-06, 'epoch': 2.53}\n",
      "{'loss': 0.7388, 'grad_norm': 5.432300090789795, 'learning_rate': 3.093333333333334e-06, 'epoch': 2.54}\n",
      "{'loss': 0.7257, 'grad_norm': 4.463650703430176, 'learning_rate': 3.066666666666667e-06, 'epoch': 2.54}\n",
      "{'loss': 0.7741, 'grad_norm': 5.715510368347168, 'learning_rate': 3.04e-06, 'epoch': 2.54}\n",
      "{'loss': 0.7552, 'grad_norm': 6.603282451629639, 'learning_rate': 3.013333333333334e-06, 'epoch': 2.55}\n",
      "{'loss': 0.7547, 'grad_norm': 5.360200881958008, 'learning_rate': 2.986666666666667e-06, 'epoch': 2.55}\n",
      "{'loss': 0.756, 'grad_norm': 4.199305057525635, 'learning_rate': 2.96e-06, 'epoch': 2.56}\n",
      "{'loss': 0.7501, 'grad_norm': 4.192251205444336, 'learning_rate': 2.9333333333333338e-06, 'epoch': 2.56}\n",
      "{'loss': 0.7342, 'grad_norm': 7.441158294677734, 'learning_rate': 2.906666666666667e-06, 'epoch': 2.56}\n",
      "{'loss': 0.7436, 'grad_norm': 5.100959777832031, 'learning_rate': 2.88e-06, 'epoch': 2.57}\n",
      "{'loss': 0.7532, 'grad_norm': 5.968235969543457, 'learning_rate': 2.8533333333333337e-06, 'epoch': 2.57}\n",
      "{'loss': 0.7334, 'grad_norm': 8.234203338623047, 'learning_rate': 2.826666666666667e-06, 'epoch': 2.58}\n",
      "{'loss': 0.7271, 'grad_norm': 7.030989646911621, 'learning_rate': 2.8000000000000003e-06, 'epoch': 2.58}\n",
      "{'loss': 0.7537, 'grad_norm': 7.2339348793029785, 'learning_rate': 2.7733333333333336e-06, 'epoch': 2.58}\n",
      "{'loss': 0.7255, 'grad_norm': 3.098910331726074, 'learning_rate': 2.746666666666667e-06, 'epoch': 2.59}\n",
      "{'loss': 0.7289, 'grad_norm': 3.905364513397217, 'learning_rate': 2.7200000000000002e-06, 'epoch': 2.59}\n",
      "{'loss': 0.7454, 'grad_norm': 7.25032901763916, 'learning_rate': 2.6933333333333335e-06, 'epoch': 2.6}\n",
      "{'loss': 0.7503, 'grad_norm': 4.78884744644165, 'learning_rate': 2.666666666666667e-06, 'epoch': 2.6}\n",
      "{'loss': 0.7386, 'grad_norm': 4.767168045043945, 'learning_rate': 2.64e-06, 'epoch': 2.6}\n",
      "{'loss': 0.7298, 'grad_norm': 5.2053399085998535, 'learning_rate': 2.6133333333333334e-06, 'epoch': 2.61}\n",
      "{'loss': 0.7625, 'grad_norm': 5.670190334320068, 'learning_rate': 2.5866666666666667e-06, 'epoch': 2.61}\n",
      "{'loss': 0.7115, 'grad_norm': 6.945855617523193, 'learning_rate': 2.56e-06, 'epoch': 2.62}\n",
      "{'loss': 0.7185, 'grad_norm': 5.143970966339111, 'learning_rate': 2.5333333333333338e-06, 'epoch': 2.62}\n",
      "{'loss': 0.7471, 'grad_norm': 9.284689903259277, 'learning_rate': 2.5066666666666667e-06, 'epoch': 2.62}\n",
      "{'loss': 0.7547, 'grad_norm': 5.535310745239258, 'learning_rate': 2.4800000000000004e-06, 'epoch': 2.63}\n",
      "{'loss': 0.7295, 'grad_norm': 5.5661234855651855, 'learning_rate': 2.4533333333333333e-06, 'epoch': 2.63}\n",
      "{'loss': 0.7347, 'grad_norm': 7.487738609313965, 'learning_rate': 2.426666666666667e-06, 'epoch': 2.64}\n",
      "{'loss': 0.7501, 'grad_norm': 5.547936916351318, 'learning_rate': 2.4000000000000003e-06, 'epoch': 2.64}\n",
      "{'loss': 0.7226, 'grad_norm': 4.998528957366943, 'learning_rate': 2.3733333333333336e-06, 'epoch': 2.64}\n",
      "{'loss': 0.7404, 'grad_norm': 4.981985092163086, 'learning_rate': 2.346666666666667e-06, 'epoch': 2.65}\n",
      "{'loss': 0.7355, 'grad_norm': 6.15158748626709, 'learning_rate': 2.3200000000000002e-06, 'epoch': 2.65}\n",
      "{'loss': 0.7188, 'grad_norm': 5.690191268920898, 'learning_rate': 2.2933333333333335e-06, 'epoch': 2.66}\n",
      "{'loss': 0.7261, 'grad_norm': 6.090028762817383, 'learning_rate': 2.266666666666667e-06, 'epoch': 2.66}\n",
      "{'loss': 0.7213, 'grad_norm': 5.103407382965088, 'learning_rate': 2.24e-06, 'epoch': 2.66}\n",
      "{'loss': 0.7161, 'grad_norm': 6.417116165161133, 'learning_rate': 2.2133333333333335e-06, 'epoch': 2.67}\n",
      "{'loss': 0.7473, 'grad_norm': 3.195674180984497, 'learning_rate': 2.1866666666666668e-06, 'epoch': 2.67}\n",
      "{'loss': 0.7307, 'grad_norm': 4.372088432312012, 'learning_rate': 2.16e-06, 'epoch': 2.68}\n",
      "{'loss': 0.7288, 'grad_norm': 3.151176929473877, 'learning_rate': 2.133333333333334e-06, 'epoch': 2.68}\n",
      "{'loss': 0.726, 'grad_norm': 6.6459479331970215, 'learning_rate': 2.1066666666666667e-06, 'epoch': 2.68}\n",
      "{'loss': 0.718, 'grad_norm': 5.509664058685303, 'learning_rate': 2.08e-06, 'epoch': 2.69}\n",
      "{'loss': 0.7286, 'grad_norm': 3.927396535873413, 'learning_rate': 2.0533333333333337e-06, 'epoch': 2.69}\n",
      "{'loss': 0.7381, 'grad_norm': 5.867302894592285, 'learning_rate': 2.0266666666666666e-06, 'epoch': 2.7}\n",
      "{'loss': 0.7486, 'grad_norm': 7.152177333831787, 'learning_rate': 2.0000000000000003e-06, 'epoch': 2.7}\n",
      "{'loss': 0.7276, 'grad_norm': 4.485372066497803, 'learning_rate': 1.9733333333333336e-06, 'epoch': 2.7}\n",
      "{'loss': 0.7168, 'grad_norm': 7.125770568847656, 'learning_rate': 1.9466666666666665e-06, 'epoch': 2.71}\n",
      "{'loss': 0.7356, 'grad_norm': 5.574285507202148, 'learning_rate': 1.9200000000000003e-06, 'epoch': 2.71}\n",
      "{'loss': 0.7333, 'grad_norm': 5.382835388183594, 'learning_rate': 1.8933333333333333e-06, 'epoch': 2.72}\n",
      "{'loss': 0.73, 'grad_norm': 5.173391819000244, 'learning_rate': 1.8666666666666669e-06, 'epoch': 2.72}\n",
      "{'loss': 0.7604, 'grad_norm': 5.437048435211182, 'learning_rate': 1.8400000000000002e-06, 'epoch': 2.72}\n",
      "{'loss': 0.7359, 'grad_norm': 4.853786945343018, 'learning_rate': 1.8133333333333337e-06, 'epoch': 2.73}\n",
      "{'loss': 0.7344, 'grad_norm': 6.0624823570251465, 'learning_rate': 1.7866666666666668e-06, 'epoch': 2.73}\n",
      "{'loss': 0.7178, 'grad_norm': 9.24671745300293, 'learning_rate': 1.76e-06, 'epoch': 2.74}\n",
      "{'loss': 0.7276, 'grad_norm': 5.100444316864014, 'learning_rate': 1.7333333333333336e-06, 'epoch': 2.74}\n",
      "{'loss': 0.7139, 'grad_norm': 6.640913009643555, 'learning_rate': 1.7066666666666667e-06, 'epoch': 2.74}\n",
      "{'loss': 0.7282, 'grad_norm': 5.420538902282715, 'learning_rate': 1.6800000000000002e-06, 'epoch': 2.75}\n",
      "{'loss': 0.7336, 'grad_norm': 4.872603893280029, 'learning_rate': 1.6533333333333335e-06, 'epoch': 2.75}\n",
      "{'loss': 0.7368, 'grad_norm': 4.345909118652344, 'learning_rate': 1.6266666666666666e-06, 'epoch': 2.76}\n",
      "{'loss': 0.7108, 'grad_norm': 4.389644622802734, 'learning_rate': 1.6000000000000001e-06, 'epoch': 2.76}\n",
      "{'loss': 0.7311, 'grad_norm': 3.858518600463867, 'learning_rate': 1.5733333333333334e-06, 'epoch': 2.76}\n",
      "{'loss': 0.7077, 'grad_norm': 6.392899990081787, 'learning_rate': 1.546666666666667e-06, 'epoch': 2.77}\n",
      "{'loss': 0.7206, 'grad_norm': 7.391446590423584, 'learning_rate': 1.52e-06, 'epoch': 2.77}\n",
      "{'loss': 0.7054, 'grad_norm': 7.889089107513428, 'learning_rate': 1.4933333333333336e-06, 'epoch': 2.78}\n",
      "{'loss': 0.7153, 'grad_norm': 4.303645133972168, 'learning_rate': 1.4666666666666669e-06, 'epoch': 2.78}\n",
      "{'loss': 0.7442, 'grad_norm': 4.236725807189941, 'learning_rate': 1.44e-06, 'epoch': 2.78}\n",
      "{'loss': 0.7297, 'grad_norm': 4.568225860595703, 'learning_rate': 1.4133333333333335e-06, 'epoch': 2.79}\n",
      "{'loss': 0.7554, 'grad_norm': 5.487422943115234, 'learning_rate': 1.3866666666666668e-06, 'epoch': 2.79}\n",
      "{'loss': 0.7209, 'grad_norm': 6.103248596191406, 'learning_rate': 1.3600000000000001e-06, 'epoch': 2.8}\n",
      "{'loss': 0.7231, 'grad_norm': 4.729903697967529, 'learning_rate': 1.3333333333333334e-06, 'epoch': 2.8}\n",
      "{'loss': 0.7168, 'grad_norm': 3.3378851413726807, 'learning_rate': 1.3066666666666667e-06, 'epoch': 2.8}\n",
      "{'loss': 0.72, 'grad_norm': 6.4765191078186035, 'learning_rate': 1.28e-06, 'epoch': 2.81}\n",
      "{'loss': 0.7355, 'grad_norm': 4.799412250518799, 'learning_rate': 1.2533333333333333e-06, 'epoch': 2.81}\n",
      "{'loss': 0.7061, 'grad_norm': 4.901142120361328, 'learning_rate': 1.2266666666666666e-06, 'epoch': 2.82}\n",
      "{'loss': 0.7234, 'grad_norm': 5.2081451416015625, 'learning_rate': 1.2000000000000002e-06, 'epoch': 2.82}\n",
      "{'loss': 0.7231, 'grad_norm': 6.780765533447266, 'learning_rate': 1.1733333333333335e-06, 'epoch': 2.82}\n",
      "{'loss': 0.7336, 'grad_norm': 5.7305803298950195, 'learning_rate': 1.1466666666666668e-06, 'epoch': 2.83}\n",
      "{'loss': 0.73, 'grad_norm': 4.629865646362305, 'learning_rate': 1.12e-06, 'epoch': 2.83}\n",
      "{'loss': 0.6941, 'grad_norm': 4.762600421905518, 'learning_rate': 1.0933333333333334e-06, 'epoch': 2.84}\n",
      "{'loss': 0.715, 'grad_norm': 6.86764669418335, 'learning_rate': 1.066666666666667e-06, 'epoch': 2.84}\n",
      "{'loss': 0.7349, 'grad_norm': 3.659022331237793, 'learning_rate': 1.04e-06, 'epoch': 2.84}\n",
      "{'loss': 0.7242, 'grad_norm': 7.4379096031188965, 'learning_rate': 1.0133333333333333e-06, 'epoch': 2.85}\n",
      "{'loss': 0.7227, 'grad_norm': 4.050243377685547, 'learning_rate': 9.866666666666668e-07, 'epoch': 2.85}\n",
      "{'loss': 0.721, 'grad_norm': 5.484460830688477, 'learning_rate': 9.600000000000001e-07, 'epoch': 2.86}\n",
      "{'loss': 0.7106, 'grad_norm': 3.219128370285034, 'learning_rate': 9.333333333333334e-07, 'epoch': 2.86}\n",
      "{'loss': 0.7262, 'grad_norm': 5.958508491516113, 'learning_rate': 9.066666666666668e-07, 'epoch': 2.86}\n",
      "{'loss': 0.7287, 'grad_norm': 6.036090850830078, 'learning_rate': 8.8e-07, 'epoch': 2.87}\n",
      "{'loss': 0.7057, 'grad_norm': 6.265490531921387, 'learning_rate': 8.533333333333334e-07, 'epoch': 2.87}\n",
      "{'loss': 0.701, 'grad_norm': 7.4664692878723145, 'learning_rate': 8.266666666666668e-07, 'epoch': 2.88}\n",
      "{'loss': 0.7174, 'grad_norm': 5.3051252365112305, 'learning_rate': 8.000000000000001e-07, 'epoch': 2.88}\n",
      "{'loss': 0.6956, 'grad_norm': 4.722089767456055, 'learning_rate': 7.733333333333335e-07, 'epoch': 2.88}\n",
      "{'loss': 0.721, 'grad_norm': 4.817786693572998, 'learning_rate': 7.466666666666668e-07, 'epoch': 2.89}\n",
      "{'loss': 0.7212, 'grad_norm': 6.92243766784668, 'learning_rate': 7.2e-07, 'epoch': 2.89}\n",
      "{'loss': 0.7066, 'grad_norm': 3.583207845687866, 'learning_rate': 6.933333333333334e-07, 'epoch': 2.9}\n",
      "{'loss': 0.7257, 'grad_norm': 4.933687686920166, 'learning_rate': 6.666666666666667e-07, 'epoch': 2.9}\n",
      "{'loss': 0.7172, 'grad_norm': 3.615447759628296, 'learning_rate': 6.4e-07, 'epoch': 2.9}\n",
      "{'loss': 0.7006, 'grad_norm': 3.6404378414154053, 'learning_rate': 6.133333333333333e-07, 'epoch': 2.91}\n",
      "{'loss': 0.7228, 'grad_norm': 6.5926737785339355, 'learning_rate': 5.866666666666667e-07, 'epoch': 2.91}\n",
      "{'loss': 0.7096, 'grad_norm': 11.52585506439209, 'learning_rate': 5.6e-07, 'epoch': 2.92}\n",
      "{'loss': 0.7112, 'grad_norm': 4.2276506423950195, 'learning_rate': 5.333333333333335e-07, 'epoch': 2.92}\n",
      "{'loss': 0.6916, 'grad_norm': 5.3763532638549805, 'learning_rate': 5.066666666666667e-07, 'epoch': 2.92}\n",
      "{'loss': 0.7237, 'grad_norm': 7.927465438842773, 'learning_rate': 4.800000000000001e-07, 'epoch': 2.93}\n",
      "{'loss': 0.7165, 'grad_norm': 6.680356025695801, 'learning_rate': 4.533333333333334e-07, 'epoch': 2.93}\n",
      "{'loss': 0.7206, 'grad_norm': 4.823395252227783, 'learning_rate': 4.266666666666667e-07, 'epoch': 2.94}\n",
      "{'loss': 0.7102, 'grad_norm': 7.540846347808838, 'learning_rate': 4.0000000000000003e-07, 'epoch': 2.94}\n",
      "{'loss': 0.7471, 'grad_norm': 6.2830681800842285, 'learning_rate': 3.733333333333334e-07, 'epoch': 2.94}\n",
      "{'loss': 0.7169, 'grad_norm': 5.586771011352539, 'learning_rate': 3.466666666666667e-07, 'epoch': 2.95}\n",
      "{'loss': 0.7092, 'grad_norm': 6.533150672912598, 'learning_rate': 3.2e-07, 'epoch': 2.95}\n",
      "{'loss': 0.71, 'grad_norm': 6.795892715454102, 'learning_rate': 2.9333333333333337e-07, 'epoch': 2.96}\n",
      "{'loss': 0.7116, 'grad_norm': 7.228265762329102, 'learning_rate': 2.666666666666667e-07, 'epoch': 2.96}\n",
      "{'loss': 0.7072, 'grad_norm': 5.853085041046143, 'learning_rate': 2.4000000000000003e-07, 'epoch': 2.96}\n",
      "{'loss': 0.7192, 'grad_norm': 8.177291870117188, 'learning_rate': 2.1333333333333334e-07, 'epoch': 2.97}\n",
      "{'loss': 0.7221, 'grad_norm': 6.249195575714111, 'learning_rate': 1.866666666666667e-07, 'epoch': 2.97}\n",
      "{'loss': 0.7357, 'grad_norm': 7.082763671875, 'learning_rate': 1.6e-07, 'epoch': 2.98}\n",
      "{'loss': 0.7285, 'grad_norm': 5.826236248016357, 'learning_rate': 1.3333333333333336e-07, 'epoch': 2.98}\n",
      "{'loss': 0.7107, 'grad_norm': 3.9809646606445312, 'learning_rate': 1.0666666666666667e-07, 'epoch': 2.98}\n",
      "{'loss': 0.7171, 'grad_norm': 6.72377872467041, 'learning_rate': 8e-08, 'epoch': 2.99}\n",
      "{'loss': 0.745, 'grad_norm': 6.777355194091797, 'learning_rate': 5.3333333333333334e-08, 'epoch': 2.99}\n",
      "{'loss': 0.702, 'grad_norm': 3.853222131729126, 'learning_rate': 2.6666666666666667e-08, 'epoch': 3.0}\n",
      "{'loss': 0.7106, 'grad_norm': 4.968334197998047, 'learning_rate': 0.0, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/j/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6faafcee15804e3a85e2d2182f627848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4411280155181885, 'eval_bleu': 56.1403, 'eval_gen_len': 12.8662, 'eval_runtime': 10276.0708, 'eval_samples_per_second': 9.731, 'eval_steps_per_second': 1.216, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 206664.8716, 'train_samples_per_second': 14.516, 'train_steps_per_second': 1.815, 'train_loss': 1.2270930525716146, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=375000, training_loss=1.2270930525716146, metrics={'train_runtime': 206664.8716, 'train_samples_per_second': 14.516, 'train_steps_per_second': 1.815, 'total_flos': 3.93261829496832e+17, 'train_loss': 1.2270930525716146, 'epoch': 3.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"../../models/size-selection/{size}/\",\n",
    "    learning_rate=2e-5,\n",
    "    auto_find_batch_size=True,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True,\n",
    "    fp16=False,\n",
    "    push_to_hub=False,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    optim=\"adafactor\"\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset['train'],\n",
    "    eval_dataset=tokenized_eval_dataset['train'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
