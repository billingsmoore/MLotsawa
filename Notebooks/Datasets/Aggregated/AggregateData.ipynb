{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bo': 'འཕགས་པ་གསེར་གྱི་བྱེ་མ་ལྟ་བུ་ཞེས་བྱ་བ་ཐེག་པ་ཆེན་པོའི་མདོ།',\n",
       " 'en': 'The Noble Mahāyāna Sūtra Like Gold Dust',\n",
       " 'source_file': 'toh126',\n",
       " 'source': '84000',\n",
       " 'topic': None}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "sources = ['84000', 'Hopkins', 'GNOME', 'LotsawaHouse', 'NLLB', 'Tatoeba', 'TED2020']\n",
    "ds_list = []\n",
    "\n",
    "for source in sources:\n",
    "    ds = load_dataset(f'billingsmoore/{source}-bo-en', split='train')\n",
    "    ds = ds.add_column('source', [f'{source}']*len(ds))\n",
    "    ds_list.append(ds)\n",
    "\n",
    "ds = concatenate_datasets(ds_list)\n",
    "ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bo</th>\n",
       "      <th>en</th>\n",
       "      <th>source_file</th>\n",
       "      <th>source</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>འཕགས་པ་གསེར་གྱི་བྱེ་མ་ལྟ་བུ་ཞེས་བྱ་བ་ཐེག་པ་ཆེན...</td>\n",
       "      <td>The Noble Mahāyāna Sūtra Like Gold Dust</td>\n",
       "      <td>toh126</td>\n",
       "      <td>84000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>སངས་རྒྱས་དང་། བྱང་ཆུབ་སེམས་དཔའ་ཐམས་ཅད་ལ་ཕྱག་འཚ...</td>\n",
       "      <td>Homage to all buddhas and bodhisattvas.</td>\n",
       "      <td>toh126</td>\n",
       "      <td>84000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>འདི་སྐད་བདག་གིས་ཐོས་པ་དུས་གཅིག་ན།</td>\n",
       "      <td>Thus did I hear at one time.</td>\n",
       "      <td>toh126</td>\n",
       "      <td>84000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>བཅོམ་ལྡན་འདས་མཉན་དུ་ཡོད་པ་ན་རྒྱལ་བུ་རྒྱལ་བྱེད་...</td>\n",
       "      <td>The Blessed One was staying at Prince Jeta’s G...</td>\n",
       "      <td>toh126</td>\n",
       "      <td>84000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>དེ་ནས་ཚེ་དང་ལྡན་པ་ཀུན་དགའ་བོ་སྟན་ལས་ལངས་ཏེ་བླ་...</td>\n",
       "      <td>Venerable Ānanda rose from his seat, draped hi...</td>\n",
       "      <td>toh126</td>\n",
       "      <td>84000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  bo  \\\n",
       "0  འཕགས་པ་གསེར་གྱི་བྱེ་མ་ལྟ་བུ་ཞེས་བྱ་བ་ཐེག་པ་ཆེན...   \n",
       "1  སངས་རྒྱས་དང་། བྱང་ཆུབ་སེམས་དཔའ་ཐམས་ཅད་ལ་ཕྱག་འཚ...   \n",
       "2                  འདི་སྐད་བདག་གིས་ཐོས་པ་དུས་གཅིག་ན།   \n",
       "3  བཅོམ་ལྡན་འདས་མཉན་དུ་ཡོད་པ་ན་རྒྱལ་བུ་རྒྱལ་བྱེད་...   \n",
       "4  དེ་ནས་ཚེ་དང་ལྡན་པ་ཀུན་དགའ་བོ་སྟན་ལས་ལངས་ཏེ་བླ་...   \n",
       "\n",
       "                                                  en source_file source topic  \n",
       "0            The Noble Mahāyāna Sūtra Like Gold Dust      toh126  84000  None  \n",
       "1            Homage to all buddhas and bodhisattvas.      toh126  84000  None  \n",
       "2                       Thus did I hear at one time.      toh126  84000  None  \n",
       "3  The Blessed One was staying at Prince Jeta’s G...      toh126  84000  None  \n",
       "4  Venerable Ānanda rose from his seat, draped hi...      toh126  84000  None  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ds.to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "992332"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deduplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "885177"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset='en')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Regular expression to match emojis\n",
    "emoji_pattern = re.compile(\n",
    "    \"[\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "    \"\\U0001F300-\\U0001F5FF\"  # Symbols & Pictographs\n",
    "    \"\\U0001F680-\\U0001F6FF\"  # Transport & Map Symbols\n",
    "    \"\\U0001F1E0-\\U0001F1FF\"  # Flags (iOS)\n",
    "    \"]+\", \n",
    "    flags=re.UNICODE\n",
    ")\n",
    "\n",
    "# Remove emojis from both 'bo' and 'en' columns\n",
    "df['bo'] = df['bo'].str.replace(emoji_pattern, '', regex=True)\n",
    "df['en'] = df['en'].str.replace(emoji_pattern, '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Rows Whose English is Just Numbers or Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "885139"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regular expression to match rows with only numbers and punctuation\n",
    "df = df[~df['en'].str.fullmatch(r'[0-9\\W]+', na=False)]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Rows Whose English is Just Roman Numerals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "885137"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roman_numeral_pattern = r'^(?=[MDCLXVI])M{0,4}(CM|CD|D?C{0,3})(XC|XL|L?X{0,3})(IX|IV|V?I{0,3})\\.?$'\n",
    "\n",
    "# Remove rows where 'target' matches the pattern\n",
    "df = df[~df['en'].str.fullmatch(roman_numeral_pattern, na=False)]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Rows With Empty Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "885100"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[(df['bo'] != '') & (df['en'] != '')]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Rows With non-Tibetan characters in Tibetan or non-Latin characters in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "712321"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Match *obvious foreign scripts* inside Tibetan text\n",
    "latin_chars = re.compile(r'[A-Za-z]')\n",
    "hangul_chars = re.compile(r'[\\uAC00-\\uD7AF]')  # Korean Hangul\n",
    "cyrillic_chars = re.compile(r'[\\u0400-\\u04FF]')  # Cyrillic block\n",
    "# Add more scripts here if needed (e.g., Chinese: \\u4E00–\\u9FFF)\n",
    "\n",
    "def clean_for_check(text):\n",
    "    return str(text).replace('\\u00A0', ' ').replace('\\u200B', '').strip()\n",
    "\n",
    "def is_clean_tibetan(text):\n",
    "    cleaned = clean_for_check(text)\n",
    "    return not (latin_chars.search(cleaned) or hangul_chars.search(cleaned) or cyrillic_chars.search(cleaned))\n",
    "\n",
    "# For English: just exclude if it has **non-Latin letters**, keep punctuation, emoji, etc.\n",
    "non_latin_text = re.compile(r'[^\\x00-\\x7F]')  # Anything outside ASCII\n",
    "\n",
    "def is_clean_english(text):\n",
    "    cleaned = clean_for_check(text)\n",
    "    return not non_latin_text.search(cleaned)\n",
    "\n",
    "# Filter\n",
    "df_clean = df[df['bo'].apply(is_clean_tibetan)]# & df['en'].apply(is_clean_english)]\n",
    "len(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push to Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bo': 'འཕགས་པ་གསེར་གྱི་བྱེ་མ་ལྟ་བུ་ཞེས་བྱ་བ་ཐེག་པ་ཆེན་པོའི་མདོ།',\n",
       " 'en': 'The Noble Mahāyāna Sūtra Like Gold Dust',\n",
       " 'source_file': 'toh126',\n",
       " 'source': '84000',\n",
       " 'topic': None,\n",
       " '__index_level_0__': 0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "ds = Dataset.from_pandas(df)\n",
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bo': 'འཕགས་པ་གསེར་གྱི་བྱེ་མ་ལྟ་བུ་ཞེས་བྱ་བ་ཐེག་པ་ཆེན་པོའི་མདོ།',\n",
       " 'en': 'The Noble Mahāyāna Sūtra Like Gold Dust',\n",
       " 'source_file': 'toh126',\n",
       " 'source': '84000',\n",
       " 'topic': None}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds.remove_columns(['__index_level_0__'])\n",
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['bo', 'en', 'source_file', 'source', 'topic'],\n",
       "        num_rows: 796590\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['bo', 'en', 'source_file', 'source', 'topic'],\n",
       "        num_rows: 88510\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.train_test_split(.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "544da54200604f7490b93856e7689047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdcde2067bf84d48a97b4c90aa2703c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/886 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/billingsmoore/Aggregated-bo-en/commit/7caadb33397b0413da72fd82d79a8ad1febb9489', commit_message='Upload dataset', commit_description='', oid='7caadb33397b0413da72fd82d79a8ad1febb9489', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/billingsmoore/Aggregated-bo-en', endpoint='https://huggingface.co', repo_type='dataset', repo_id='billingsmoore/Aggregated-bo-en'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.push_to_hub('billingsmoore/Aggregated-bo-en')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
